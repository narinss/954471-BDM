{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T15:35:04.864965Z","iopub.execute_input":"2021-09-08T15:35:04.865415Z","iopub.status.idle":"2021-09-08T15:35:04.883490Z","shell.execute_reply.started":"2021-09-08T15:35:04.865315Z","shell.execute_reply":"2021-09-08T15:35:04.882287Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/credit-card-approval-prediction/credit_record.csv\n/kaggle/input/credit-card-approval-prediction/application_record.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('../input/credit-card-approval-prediction/application_record.csv',header = 0)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:04.885395Z","iopub.execute_input":"2021-09-08T15:35:04.885714Z","iopub.status.idle":"2021-09-08T15:35:06.314021Z","shell.execute_reply.started":"2021-09-08T15:35:04.885685Z","shell.execute_reply":"2021-09-08T15:35:06.313086Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                 ID   CNT_CHILDREN  AMT_INCOME_TOTAL     DAYS_BIRTH  \\\ncount  4.385570e+05  438557.000000      4.385570e+05  438557.000000   \nmean   6.022176e+06       0.427390      1.875243e+05  -15997.904649   \nstd    5.716370e+05       0.724882      1.100869e+05    4185.030007   \nmin    5.008804e+06       0.000000      2.610000e+04  -25201.000000   \n25%    5.609375e+06       0.000000      1.215000e+05  -19483.000000   \n50%    6.047745e+06       0.000000      1.607805e+05  -15630.000000   \n75%    6.456971e+06       1.000000      2.250000e+05  -12514.000000   \nmax    7.999952e+06      19.000000      6.750000e+06   -7489.000000   \n\n       DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE     FLAG_PHONE  \\\ncount  438557.000000    438557.0    438557.000000  438557.000000   \nmean    60563.675328         1.0         0.206133       0.287771   \nstd    138767.799647         0.0         0.404527       0.452724   \nmin    -17531.000000         1.0         0.000000       0.000000   \n25%     -3103.000000         1.0         0.000000       0.000000   \n50%     -1467.000000         1.0         0.000000       0.000000   \n75%      -371.000000         1.0         0.000000       1.000000   \nmax    365243.000000         1.0         1.000000       1.000000   \n\n          FLAG_EMAIL  CNT_FAM_MEMBERS  \ncount  438557.000000    438557.000000  \nmean        0.108207         2.194465  \nstd         0.310642         0.897207  \nmin         0.000000         1.000000  \n25%         0.000000         2.000000  \n50%         0.000000         2.000000  \n75%         0.000000         3.000000  \nmax         1.000000        20.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>DAYS_BIRTH</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>FLAG_MOBIL</th>\n      <th>FLAG_WORK_PHONE</th>\n      <th>FLAG_PHONE</th>\n      <th>FLAG_EMAIL</th>\n      <th>CNT_FAM_MEMBERS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.385570e+05</td>\n      <td>438557.000000</td>\n      <td>4.385570e+05</td>\n      <td>438557.000000</td>\n      <td>438557.000000</td>\n      <td>438557.0</td>\n      <td>438557.000000</td>\n      <td>438557.000000</td>\n      <td>438557.000000</td>\n      <td>438557.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6.022176e+06</td>\n      <td>0.427390</td>\n      <td>1.875243e+05</td>\n      <td>-15997.904649</td>\n      <td>60563.675328</td>\n      <td>1.0</td>\n      <td>0.206133</td>\n      <td>0.287771</td>\n      <td>0.108207</td>\n      <td>2.194465</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.716370e+05</td>\n      <td>0.724882</td>\n      <td>1.100869e+05</td>\n      <td>4185.030007</td>\n      <td>138767.799647</td>\n      <td>0.0</td>\n      <td>0.404527</td>\n      <td>0.452724</td>\n      <td>0.310642</td>\n      <td>0.897207</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.008804e+06</td>\n      <td>0.000000</td>\n      <td>2.610000e+04</td>\n      <td>-25201.000000</td>\n      <td>-17531.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.609375e+06</td>\n      <td>0.000000</td>\n      <td>1.215000e+05</td>\n      <td>-19483.000000</td>\n      <td>-3103.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6.047745e+06</td>\n      <td>0.000000</td>\n      <td>1.607805e+05</td>\n      <td>-15630.000000</td>\n      <td>-1467.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.456971e+06</td>\n      <td>1.000000</td>\n      <td>2.250000e+05</td>\n      <td>-12514.000000</td>\n      <td>-371.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.999952e+06</td>\n      <td>19.000000</td>\n      <td>6.750000e+06</td>\n      <td>-7489.000000</td>\n      <td>365243.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_label = pd.read_csv('../input/credit-card-approval-prediction/credit_record.csv',header = 0)\ndf_label","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:06.315559Z","iopub.execute_input":"2021-09-08T15:35:06.315825Z","iopub.status.idle":"2021-09-08T15:35:06.665170Z","shell.execute_reply.started":"2021-09-08T15:35:06.315800Z","shell.execute_reply":"2021-09-08T15:35:06.664449Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              ID  MONTHS_BALANCE STATUS\n0        5001711               0      X\n1        5001711              -1      0\n2        5001711              -2      0\n3        5001711              -3      0\n4        5001712               0      C\n...          ...             ...    ...\n1048570  5150487             -25      C\n1048571  5150487             -26      C\n1048572  5150487             -27      C\n1048573  5150487             -28      C\n1048574  5150487             -29      C\n\n[1048575 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>MONTHS_BALANCE</th>\n      <th>STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5001711</td>\n      <td>0</td>\n      <td>X</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5001711</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5001711</td>\n      <td>-2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5001711</td>\n      <td>-3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5001712</td>\n      <td>0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>5150487</td>\n      <td>-25</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>5150487</td>\n      <td>-26</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>5150487</td>\n      <td>-27</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>5150487</td>\n      <td>-28</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>5150487</td>\n      <td>-29</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>1048575 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_label.groupby('ID')['STATUS'].count()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:06.666663Z","iopub.execute_input":"2021-09-08T15:35:06.666944Z","iopub.status.idle":"2021-09-08T15:35:06.799917Z","shell.execute_reply.started":"2021-09-08T15:35:06.666918Z","shell.execute_reply":"2021-09-08T15:35:06.798838Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"ID\n5001711     4\n5001712    19\n5001713    22\n5001714    15\n5001715    60\n           ..\n5150482    18\n5150483    18\n5150484    13\n5150485     2\n5150487    30\nName: STATUS, Length: 45985, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_label['STATUS'], labels = pd.factorize(df_label['STATUS'])\nlabels","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:06.801432Z","iopub.execute_input":"2021-09-08T15:35:06.801744Z","iopub.status.idle":"2021-09-08T15:35:06.892949Z","shell.execute_reply.started":"2021-09-08T15:35:06.801714Z","shell.execute_reply":"2021-09-08T15:35:06.891969Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['X', '0', 'C', '1', '2', '3', '4', '5'], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df_label_clean = df_label[df_label['STATUS'] != 0]\ndf_label_clean","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:06.894085Z","iopub.execute_input":"2021-09-08T15:35:06.894402Z","iopub.status.idle":"2021-09-08T15:35:06.952670Z","shell.execute_reply.started":"2021-09-08T15:35:06.894372Z","shell.execute_reply":"2021-09-08T15:35:06.951809Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"              ID  MONTHS_BALANCE  STATUS\n1        5001711              -1       1\n2        5001711              -2       1\n3        5001711              -3       1\n4        5001712               0       2\n5        5001712              -1       2\n...          ...             ...     ...\n1048570  5150487             -25       2\n1048571  5150487             -26       2\n1048572  5150487             -27       2\n1048573  5150487             -28       2\n1048574  5150487             -29       2\n\n[839345 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>MONTHS_BALANCE</th>\n      <th>STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5001711</td>\n      <td>-1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5001711</td>\n      <td>-2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5001711</td>\n      <td>-3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5001712</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5001712</td>\n      <td>-1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>5150487</td>\n      <td>-25</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>5150487</td>\n      <td>-26</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>5150487</td>\n      <td>-27</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>5150487</td>\n      <td>-28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>5150487</td>\n      <td>-29</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>839345 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_label_clean['STATUS'][df_label['STATUS'] > 2] = 10\ndf_label_clean['STATUS'][df_label['STATUS'] <= 2] = 0","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:06.953664Z","iopub.execute_input":"2021-09-08T15:35:06.954063Z","iopub.status.idle":"2021-09-08T15:35:07.018071Z","shell.execute_reply.started":"2021-09-08T15:35:06.954034Z","shell.execute_reply":"2021-09-08T15:35:07.016979Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:992: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._where(~key, value, inplace=True)\n/opt/conda/lib/python3.7/site-packages/pandas/core/series.py:992: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._where(~key, value, inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"df_label_clean.groupby('STATUS')['STATUS'].count()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.021579Z","iopub.execute_input":"2021-09-08T15:35:07.022049Z","iopub.status.idle":"2021-09-08T15:35:07.044465Z","shell.execute_reply.started":"2021-09-08T15:35:07.022002Z","shell.execute_reply":"2021-09-08T15:35:07.043509Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"STATUS\n0     825151\n10     14194\nName: STATUS, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_label_clean","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.046135Z","iopub.execute_input":"2021-09-08T15:35:07.046451Z","iopub.status.idle":"2021-09-08T15:35:07.058144Z","shell.execute_reply.started":"2021-09-08T15:35:07.046416Z","shell.execute_reply":"2021-09-08T15:35:07.057414Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"              ID  MONTHS_BALANCE  STATUS\n1        5001711              -1       0\n2        5001711              -2       0\n3        5001711              -3       0\n4        5001712               0       0\n5        5001712              -1       0\n...          ...             ...     ...\n1048570  5150487             -25       0\n1048571  5150487             -26       0\n1048572  5150487             -27       0\n1048573  5150487             -28       0\n1048574  5150487             -29       0\n\n[839345 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>MONTHS_BALANCE</th>\n      <th>STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5001711</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5001711</td>\n      <td>-2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5001711</td>\n      <td>-3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5001712</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5001712</td>\n      <td>-1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>5150487</td>\n      <td>-25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>5150487</td>\n      <td>-26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>5150487</td>\n      <td>-27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>5150487</td>\n      <td>-28</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>5150487</td>\n      <td>-29</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>839345 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_label_group = df_label_clean.groupby('ID').mean()\ndf_label_group","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.059338Z","iopub.execute_input":"2021-09-08T15:35:07.059812Z","iopub.status.idle":"2021-09-08T15:35:07.106387Z","shell.execute_reply.started":"2021-09-08T15:35:07.059780Z","shell.execute_reply":"2021-09-08T15:35:07.105602Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         MONTHS_BALANCE    STATUS\nID                               \n5001711       -2.000000  0.000000\n5001712       -9.000000  0.000000\n5001717      -10.500000  0.000000\n5001718      -18.724138  0.689655\n5001719      -21.000000  0.000000\n...                 ...       ...\n5150480      -36.500000  0.000000\n5150482      -19.500000  0.000000\n5150484       -6.000000  0.000000\n5150485       -0.500000  0.000000\n5150487      -14.500000  0.000000\n\n[41449 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MONTHS_BALANCE</th>\n      <th>STATUS</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5001711</th>\n      <td>-2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5001712</th>\n      <td>-9.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5001717</th>\n      <td>-10.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5001718</th>\n      <td>-18.724138</td>\n      <td>0.689655</td>\n    </tr>\n    <tr>\n      <th>5001719</th>\n      <td>-21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5150480</th>\n      <td>-36.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5150482</th>\n      <td>-19.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5150484</th>\n      <td>-6.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5150485</th>\n      <td>-0.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5150487</th>\n      <td>-14.500000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>41449 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_label_group['STATUS'][df_label_group['STATUS'] > 0] = 1\ndf_label_group['STATUS'][df_label_group['STATUS'] <= 0] = 0\ndf_label_group.groupby('STATUS')['STATUS'].count()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.107662Z","iopub.execute_input":"2021-09-08T15:35:07.108117Z","iopub.status.idle":"2021-09-08T15:35:07.123871Z","shell.execute_reply.started":"2021-09-08T15:35:07.108087Z","shell.execute_reply":"2021-09-08T15:35:07.122641Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"STATUS\n0.0    36099\n1.0     5350\nName: STATUS, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"client_id = df_label_group.index.values\nclient_label = df_label_group['STATUS'].values","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.125474Z","iopub.execute_input":"2021-09-08T15:35:07.126311Z","iopub.status.idle":"2021-09-08T15:35:07.131555Z","shell.execute_reply.started":"2021-09-08T15:35:07.126260Z","shell.execute_reply":"2021-09-08T15:35:07.130333Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"client_id","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.132867Z","iopub.execute_input":"2021-09-08T15:35:07.133263Z","iopub.status.idle":"2021-09-08T15:35:07.149284Z","shell.execute_reply.started":"2021-09-08T15:35:07.133211Z","shell.execute_reply":"2021-09-08T15:35:07.148085Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([5001711, 5001712, 5001717, ..., 5150484, 5150485, 5150487])"},"metadata":{}}]},{"cell_type":"code","source":"client_label","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.150832Z","iopub.execute_input":"2021-09-08T15:35:07.151301Z","iopub.status.idle":"2021-09-08T15:35:07.164969Z","shell.execute_reply.started":"2021-09-08T15:35:07.151253Z","shell.execute_reply":"2021-09-08T15:35:07.164014Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., ..., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.166672Z","iopub.execute_input":"2021-09-08T15:35:07.167148Z","iopub.status.idle":"2021-09-08T15:35:07.522388Z","shell.execute_reply.started":"2021-09-08T15:35:07.167111Z","shell.execute_reply":"2021-09-08T15:35:07.521538Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"ID                          0\nCODE_GENDER                 0\nFLAG_OWN_CAR                0\nFLAG_OWN_REALTY             0\nCNT_CHILDREN                0\nAMT_INCOME_TOTAL            0\nNAME_INCOME_TYPE            0\nNAME_EDUCATION_TYPE         0\nNAME_FAMILY_STATUS          0\nNAME_HOUSING_TYPE           0\nDAYS_BIRTH                  0\nDAYS_EMPLOYED               0\nFLAG_MOBIL                  0\nFLAG_WORK_PHONE             0\nFLAG_PHONE                  0\nFLAG_EMAIL                  0\nOCCUPATION_TYPE        134203\nCNT_FAM_MEMBERS             0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.groupby('OCCUPATION_TYPE')['OCCUPATION_TYPE'].count()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.523565Z","iopub.execute_input":"2021-09-08T15:35:07.524009Z","iopub.status.idle":"2021-09-08T15:35:07.626066Z","shell.execute_reply.started":"2021-09-08T15:35:07.523962Z","shell.execute_reply":"2021-09-08T15:35:07.624940Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"OCCUPATION_TYPE\nAccountants              15985\nCleaning staff            5845\nCooking staff             8076\nCore staff               43007\nDrivers                  26090\nHR staff                   774\nHigh skill tech staff    17289\nIT staff                   604\nLaborers                 78240\nLow-skill Laborers        2140\nManagers                 35487\nMedicine staff           13520\nPrivate service staff     3456\nRealty agents             1041\nSales staff              41098\nSecretaries               2044\nSecurity staff            7993\nWaiters/barmen staff      1665\nName: OCCUPATION_TYPE, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_clean = df.dropna(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:07.627522Z","iopub.execute_input":"2021-09-08T15:35:07.627819Z","iopub.status.idle":"2021-09-08T15:35:08.015880Z","shell.execute_reply.started":"2021-09-08T15:35:07.627789Z","shell.execute_reply":"2021-09-08T15:35:08.014799Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_clean.isnull().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.017457Z","iopub.execute_input":"2021-09-08T15:35:08.017786Z","iopub.status.idle":"2021-09-08T15:35:08.268960Z","shell.execute_reply.started":"2021-09-08T15:35:08.017756Z","shell.execute_reply":"2021-09-08T15:35:08.267986Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"ID                     0\nCODE_GENDER            0\nFLAG_OWN_CAR           0\nFLAG_OWN_REALTY        0\nCNT_CHILDREN           0\nAMT_INCOME_TOTAL       0\nNAME_INCOME_TYPE       0\nNAME_EDUCATION_TYPE    0\nNAME_FAMILY_STATUS     0\nNAME_HOUSING_TYPE      0\nDAYS_BIRTH             0\nDAYS_EMPLOYED          0\nFLAG_MOBIL             0\nFLAG_WORK_PHONE        0\nFLAG_PHONE             0\nFLAG_EMAIL             0\nOCCUPATION_TYPE        0\nCNT_FAM_MEMBERS        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_clean_drop = df_clean.drop(['DAYS_BIRTH', 'FLAG_EMAIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_MOBIL','CODE_GENDER'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.270298Z","iopub.execute_input":"2021-09-08T15:35:08.270608Z","iopub.status.idle":"2021-09-08T15:35:08.298654Z","shell.execute_reply.started":"2021-09-08T15:35:08.270577Z","shell.execute_reply":"2021-09-08T15:35:08.297502Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"df_clean_drop.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.300396Z","iopub.execute_input":"2021-09-08T15:35:08.300931Z","iopub.status.idle":"2021-09-08T15:35:08.525385Z","shell.execute_reply.started":"2021-09-08T15:35:08.300832Z","shell.execute_reply":"2021-09-08T15:35:08.524256Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"ID                     False\nFLAG_OWN_CAR           False\nFLAG_OWN_REALTY        False\nCNT_CHILDREN           False\nAMT_INCOME_TOTAL       False\nNAME_INCOME_TYPE       False\nNAME_EDUCATION_TYPE    False\nNAME_FAMILY_STATUS     False\nNAME_HOUSING_TYPE      False\nDAYS_EMPLOYED          False\nOCCUPATION_TYPE        False\nCNT_FAM_MEMBERS        False\ndtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"df_clean_drop.dropna(axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.528255Z","iopub.execute_input":"2021-09-08T15:35:08.528944Z","iopub.status.idle":"2021-09-08T15:35:08.807572Z","shell.execute_reply.started":"2021-09-08T15:35:08.528905Z","shell.execute_reply":"2021-09-08T15:35:08.806549Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"             ID FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n2       5008806            Y               Y             0          112500.0   \n3       5008808            N               Y             0          270000.0   \n4       5008809            N               Y             0          270000.0   \n5       5008810            N               Y             0          270000.0   \n6       5008811            N               Y             0          270000.0   \n...         ...          ...             ...           ...               ...   \n438541  6837707            N               Y             0          202500.0   \n438548  6839936            Y               Y             1          135000.0   \n438553  6840222            N               N             0          103500.0   \n438554  6841878            N               N             0           54000.0   \n438556  6842885            N               Y             0          121500.0   \n\n            NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n2                    Working  Secondary / secondary special   \n3       Commercial associate  Secondary / secondary special   \n4       Commercial associate  Secondary / secondary special   \n5       Commercial associate  Secondary / secondary special   \n6       Commercial associate  Secondary / secondary special   \n...                      ...                            ...   \n438541               Working               Higher education   \n438548               Working  Secondary / secondary special   \n438553               Working  Secondary / secondary special   \n438554  Commercial associate               Higher education   \n438556               Working  Secondary / secondary special   \n\n          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_EMPLOYED  \\\n2                    Married  House / apartment          -1134   \n3       Single / not married  House / apartment          -3051   \n4       Single / not married  House / apartment          -3051   \n5       Single / not married  House / apartment          -3051   \n6       Single / not married  House / apartment          -3051   \n...                      ...                ...            ...   \n438541        Civil marriage  House / apartment          -2309   \n438548               Married  House / apartment          -2095   \n438553  Single / not married  House / apartment          -3007   \n438554  Single / not married       With parents           -372   \n438556               Married  House / apartment          -1201   \n\n       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n2       Security staff              2.0  \n3          Sales staff              1.0  \n4          Sales staff              1.0  \n5          Sales staff              1.0  \n6          Sales staff              1.0  \n...                ...              ...  \n438541        Laborers              2.0  \n438548        Laborers              3.0  \n438553        Laborers              1.0  \n438554     Sales staff              1.0  \n438556     Sales staff              2.0  \n\n[304354 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>FLAG_OWN_CAR</th>\n      <th>FLAG_OWN_REALTY</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>NAME_INCOME_TYPE</th>\n      <th>NAME_EDUCATION_TYPE</th>\n      <th>NAME_FAMILY_STATUS</th>\n      <th>NAME_HOUSING_TYPE</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>OCCUPATION_TYPE</th>\n      <th>CNT_FAM_MEMBERS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>5008806</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>112500.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>Married</td>\n      <td>House / apartment</td>\n      <td>-1134</td>\n      <td>Security staff</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5008808</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>Commercial associate</td>\n      <td>Secondary / secondary special</td>\n      <td>Single / not married</td>\n      <td>House / apartment</td>\n      <td>-3051</td>\n      <td>Sales staff</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5008809</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>Commercial associate</td>\n      <td>Secondary / secondary special</td>\n      <td>Single / not married</td>\n      <td>House / apartment</td>\n      <td>-3051</td>\n      <td>Sales staff</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5008810</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>Commercial associate</td>\n      <td>Secondary / secondary special</td>\n      <td>Single / not married</td>\n      <td>House / apartment</td>\n      <td>-3051</td>\n      <td>Sales staff</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5008811</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>Commercial associate</td>\n      <td>Secondary / secondary special</td>\n      <td>Single / not married</td>\n      <td>House / apartment</td>\n      <td>-3051</td>\n      <td>Sales staff</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>438541</th>\n      <td>6837707</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>Working</td>\n      <td>Higher education</td>\n      <td>Civil marriage</td>\n      <td>House / apartment</td>\n      <td>-2309</td>\n      <td>Laborers</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>438548</th>\n      <td>6839936</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>135000.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>Married</td>\n      <td>House / apartment</td>\n      <td>-2095</td>\n      <td>Laborers</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>438553</th>\n      <td>6840222</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>103500.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>Single / not married</td>\n      <td>House / apartment</td>\n      <td>-3007</td>\n      <td>Laborers</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>438554</th>\n      <td>6841878</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0</td>\n      <td>54000.0</td>\n      <td>Commercial associate</td>\n      <td>Higher education</td>\n      <td>Single / not married</td>\n      <td>With parents</td>\n      <td>-372</td>\n      <td>Sales staff</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>438556</th>\n      <td>6842885</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>Working</td>\n      <td>Secondary / secondary special</td>\n      <td>Married</td>\n      <td>House / apartment</td>\n      <td>-1201</td>\n      <td>Sales staff</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>304354 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_clean_drop.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.808898Z","iopub.execute_input":"2021-09-08T15:35:08.809197Z","iopub.status.idle":"2021-09-08T15:35:08.818193Z","shell.execute_reply.started":"2021-09-08T15:35:08.809167Z","shell.execute_reply":"2021-09-08T15:35:08.817122Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"ID                       int64\nFLAG_OWN_CAR            object\nFLAG_OWN_REALTY         object\nCNT_CHILDREN             int64\nAMT_INCOME_TOTAL       float64\nNAME_INCOME_TYPE        object\nNAME_EDUCATION_TYPE     object\nNAME_FAMILY_STATUS      object\nNAME_HOUSING_TYPE       object\nDAYS_EMPLOYED            int64\nOCCUPATION_TYPE         object\nCNT_FAM_MEMBERS        float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df_clean_drop['FLAG_OWN_CAR']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['FLAG_OWN_REALTY']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['NAME_INCOME_TYPE']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['NAME_EDUCATION_TYPE']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['NAME_FAMILY_STATUS']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['NAME_HOUSING_TYPE']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]\ndf_clean_drop['OCCUPATION_TYPE']= pd.factorize(df_clean_drop['OCCUPATION_TYPE'])[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:08.823575Z","iopub.execute_input":"2021-09-08T15:35:08.824006Z","iopub.status.idle":"2021-09-08T15:35:09.061749Z","shell.execute_reply.started":"2021-09-08T15:35:08.823975Z","shell.execute_reply":"2021-09-08T15:35:09.060952Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_clean_drop.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:09.063387Z","iopub.execute_input":"2021-09-08T15:35:09.063795Z","iopub.status.idle":"2021-09-08T15:35:09.070738Z","shell.execute_reply.started":"2021-09-08T15:35:09.063763Z","shell.execute_reply":"2021-09-08T15:35:09.069773Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"ID                       int64\nFLAG_OWN_CAR             int64\nFLAG_OWN_REALTY          int64\nCNT_CHILDREN             int64\nAMT_INCOME_TOTAL       float64\nNAME_INCOME_TYPE         int64\nNAME_EDUCATION_TYPE      int64\nNAME_FAMILY_STATUS       int64\nNAME_HOUSING_TYPE        int64\nDAYS_EMPLOYED            int64\nOCCUPATION_TYPE          int64\nCNT_FAM_MEMBERS        float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X_client_id= df_clean_drop['ID'].values\ndf_clean_drop = df_clean_drop.drop(['ID'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:09.071770Z","iopub.execute_input":"2021-09-08T15:35:09.072099Z","iopub.status.idle":"2021-09-08T15:35:09.114153Z","shell.execute_reply.started":"2021-09-08T15:35:09.072073Z","shell.execute_reply":"2021-09-08T15:35:09.113267Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X = df_clean_drop.values\nX.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:09.115492Z","iopub.execute_input":"2021-09-08T15:35:09.115781Z","iopub.status.idle":"2021-09-08T15:35:09.129188Z","shell.execute_reply.started":"2021-09-08T15:35:09.115755Z","shell.execute_reply":"2021-09-08T15:35:09.128263Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(304354, 11)"},"metadata":{}}]},{"cell_type":"code","source":"real_client_id = [item for item in X_client_id if item in client_id]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:09.130479Z","iopub.execute_input":"2021-09-08T15:35:09.130958Z","iopub.status.idle":"2021-09-08T15:35:16.226007Z","shell.execute_reply.started":"2021-09-08T15:35:09.130915Z","shell.execute_reply":"2021-09-08T15:35:16.225079Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(real_client_id)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:16.227271Z","iopub.execute_input":"2021-09-08T15:35:16.227774Z","iopub.status.idle":"2021-09-08T15:35:16.232945Z","shell.execute_reply.started":"2021-09-08T15:35:16.227742Z","shell.execute_reply":"2021-09-08T15:35:16.232084Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"22737"},"metadata":{}}]},{"cell_type":"code","source":"y = np.array([client_label[np.where(client_id == item)][0] for item in real_client_id])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:16.234086Z","iopub.execute_input":"2021-09-08T15:35:16.234555Z","iopub.status.idle":"2021-09-08T15:35:16.938669Z","shell.execute_reply.started":"2021-09-08T15:35:16.234515Z","shell.execute_reply":"2021-09-08T15:35:16.937622Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"X_final = [X[np.where(X_client_id == item), :][0] for item in real_client_id]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:16.939897Z","iopub.execute_input":"2021-09-08T15:35:16.940216Z","iopub.status.idle":"2021-09-08T15:35:21.768148Z","shell.execute_reply.started":"2021-09-08T15:35:16.940184Z","shell.execute_reply":"2021-09-08T15:35:21.767008Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"X_final[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.769588Z","iopub.execute_input":"2021-09-08T15:35:21.769896Z","iopub.status.idle":"2021-09-08T15:35:21.775403Z","shell.execute_reply.started":"2021-09-08T15:35:21.769868Z","shell.execute_reply":"2021-09-08T15:35:21.774510Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(1, 11)"},"metadata":{}}]},{"cell_type":"code","source":"X_real_final = np.vstack(X_final)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.776735Z","iopub.execute_input":"2021-09-08T15:35:21.777096Z","iopub.status.idle":"2021-09-08T15:35:21.818847Z","shell.execute_reply.started":"2021-09-08T15:35:21.777067Z","shell.execute_reply":"2021-09-08T15:35:21.817682Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"X_real_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.820493Z","iopub.execute_input":"2021-09-08T15:35:21.820806Z","iopub.status.idle":"2021-09-08T15:35:21.825763Z","shell.execute_reply.started":"2021-09-08T15:35:21.820778Z","shell.execute_reply":"2021-09-08T15:35:21.824802Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(22737, 11)"},"metadata":{}}]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.827191Z","iopub.execute_input":"2021-09-08T15:35:21.827595Z","iopub.status.idle":"2021-09-08T15:35:21.841532Z","shell.execute_reply.started":"2021-09-08T15:35:21.827560Z","shell.execute_reply":"2021-09-08T15:35:21.840256Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"22737"},"metadata":{}}]},{"cell_type":"code","source":"sum(y==0)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.842896Z","iopub.execute_input":"2021-09-08T15:35:21.843248Z","iopub.status.idle":"2021-09-08T15:35:21.943635Z","shell.execute_reply.started":"2021-09-08T15:35:21.843203Z","shell.execute_reply":"2021-09-08T15:35:21.942741Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"19648"},"metadata":{}}]},{"cell_type":"code","source":"sum(y==1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:21.944619Z","iopub.execute_input":"2021-09-08T15:35:21.945014Z","iopub.status.idle":"2021-09-08T15:35:22.048144Z","shell.execute_reply.started":"2021-09-08T15:35:21.944986Z","shell.execute_reply":"2021-09-08T15:35:22.046871Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"3089"},"metadata":{}}]},{"cell_type":"code","source":"3089/(19648+3089)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.049578Z","iopub.execute_input":"2021-09-08T15:35:22.049898Z","iopub.status.idle":"2021-09-08T15:35:22.061395Z","shell.execute_reply.started":"2021-09-08T15:35:22.049868Z","shell.execute_reply":"2021-09-08T15:35:22.060160Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"0.1358578528389849"},"metadata":{}}]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nsm = RandomUnderSampler(random_state=1)\nX_res, y_res = sm.fit_resample(X_real_final, y)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.062695Z","iopub.execute_input":"2021-09-08T15:35:22.063042Z","iopub.status.idle":"2021-09-08T15:35:22.455572Z","shell.execute_reply.started":"2021-09-08T15:35:22.063009Z","shell.execute_reply":"2021-09-08T15:35:22.454501Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"X_res.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.457153Z","iopub.execute_input":"2021-09-08T15:35:22.457598Z","iopub.status.idle":"2021-09-08T15:35:22.464961Z","shell.execute_reply.started":"2021-09-08T15:35:22.457555Z","shell.execute_reply":"2021-09-08T15:35:22.463804Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(6178, 11)"},"metadata":{}}]},{"cell_type":"code","source":"y_res.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.466582Z","iopub.execute_input":"2021-09-08T15:35:22.467008Z","iopub.status.idle":"2021-09-08T15:35:22.478591Z","shell.execute_reply.started":"2021-09-08T15:35:22.466968Z","shell.execute_reply":"2021-09-08T15:35:22.477563Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(6178,)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.479972Z","iopub.execute_input":"2021-09-08T15:35:22.480310Z","iopub.status.idle":"2021-09-08T15:35:22.491865Z","shell.execute_reply.started":"2021-09-08T15:35:22.480281Z","shell.execute_reply":"2021-09-08T15:35:22.490645Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.493332Z","iopub.execute_input":"2021-09-08T15:35:22.493774Z","iopub.status.idle":"2021-09-08T15:35:22.504478Z","shell.execute_reply.started":"2021-09-08T15:35:22.493743Z","shell.execute_reply":"2021-09-08T15:35:22.503354Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train)\nX_train_norm =  scaler.transform(X_train)\nX_val_norm = scaler.transform(X_val)\nX_test_norm = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:22.506304Z","iopub.execute_input":"2021-09-08T15:35:22.506814Z","iopub.status.idle":"2021-09-08T15:35:22.516219Z","shell.execute_reply.started":"2021-09-08T15:35:22.506770Z","shell.execute_reply":"2021-09-08T15:35:22.515243Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {'C': [1,2,3,4,5,6,7,8,16]}\nclf = GridSearchCV(LogisticRegression(random_state=0, solver='liblinear'),params, cv=10)\nclf.fit(X_train_norm, y_train)\nprint(\"Best params : \" + str(clf.best_params_))\nprint(\"10CV accuracy : \"+str(clf.best_score_*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:59:40.028812Z","iopub.execute_input":"2021-09-08T15:59:40.029179Z","iopub.status.idle":"2021-09-08T15:59:40.782005Z","shell.execute_reply.started":"2021-09-08T15:59:40.029147Z","shell.execute_reply":"2021-09-08T15:59:40.780853Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Best params : {'C': 1}\n10CV accuracy : 51.50511443549418\n","output_type":"stream"}]},{"cell_type":"code","source":"y_predict = clf.predict(X_test_norm)\nprint(\"Test accuracy : \"+str(sum(y_test == y_predict)/len(y_test)*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:59:43.926017Z","iopub.execute_input":"2021-09-08T15:59:43.926476Z","iopub.status.idle":"2021-09-08T15:59:43.949546Z","shell.execute_reply.started":"2021-09-08T15:59:43.926436Z","shell.execute_reply":"2021-09-08T15:59:43.948330Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Test accuracy : 53.07443365695793\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow==2.0.0-beta1\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:35:23.256408Z","iopub.execute_input":"2021-09-08T15:35:23.256884Z","iopub.status.idle":"2021-09-08T15:35:32.109242Z","shell.execute_reply.started":"2021-09-08T15:35:23.256844Z","shell.execute_reply":"2021-09-08T15:35:32.107892Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.0.0-beta1 in /opt/conda/lib/python3.7/site-packages (2.0.0b1)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.2.0)\nRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.19.5)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.12.1)\nRequirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.8.1)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.3.3)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.32.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.1.0)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.36.2)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.0.8)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.15.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.1.2)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (3.17.3)\nRequirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.14.0.dev2019060501)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (0.12.0)\nRequirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.0.0-beta1) (1.14.0a20190603)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.10.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (2.0.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.3.4)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (49.6.0.post20210108)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.4.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.4.1)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.compat.v1.reset_default_graph() # Clear Model\nnp.random.seed(1) # Fix Randomness\ntf.compat.v1.random.set_random_seed(1) # Fix Randomness\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Dense(512, activation='relu', input_shape=(11,)),\n  tf.keras.layers.Dense(256, activation='relu'),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(64, activation='relu'),\n  tf.keras.layers.Dense(32, activation='relu'),\n  tf.keras.layers.Dense(16, activation='relu'),\n  tf.keras.layers.Dense(8, activation='relu'),  \n  tf.keras.layers.Dense(4, activation='relu'),\n  tf.keras.layers.Dense(2, activation='relu'),\n  tf.keras.layers.Dense(1, activation='sigmoid')    \n])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:59:48.711981Z","iopub.execute_input":"2021-09-08T15:59:48.712676Z","iopub.status.idle":"2021-09-08T15:59:48.867938Z","shell.execute_reply.started":"2021-09-08T15:59:48.712615Z","shell.execute_reply":"2021-09-08T15:59:48.867012Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 512)               6144      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_5 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_6 (Dense)              (None, 8)                 136       \n_________________________________________________________________\ndense_7 (Dense)              (None, 4)                 36        \n_________________________________________________________________\ndense_8 (Dense)              (None, 2)                 10        \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 3         \n=================================================================\nTotal params: 181,417\nTrainable params: 181,417\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:59:55.473269Z","iopub.execute_input":"2021-09-08T15:59:55.473636Z","iopub.status.idle":"2021-09-08T15:59:55.539322Z","shell.execute_reply.started":"2021-09-08T15:59:55.473605Z","shell.execute_reply":"2021-09-08T15:59:55.538072Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"train_acc = list()\nval_acc = list()\nfor i in range(0,600):\n  history = model.fit(X_train_norm, y_train, epochs= 5, batch_size = 200, validation_data= (X_val_norm, y_val))\n  tmp_avg = np.mean(history.history['accuracy'])\n  tmp_avg_val = np.mean(history.history['val_accuracy'])\n  train_acc.append(tmp_avg)\n  val_acc.append(tmp_avg_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T15:59:59.591998Z","iopub.execute_input":"2021-09-08T15:59:59.592347Z","iopub.status.idle":"2021-09-08T16:07:05.245095Z","shell.execute_reply.started":"2021-09-08T15:59:59.592318Z","shell.execute_reply":"2021-09-08T16:07:05.244257Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Train on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 1s 180us/sample - loss: 0.6932 - accuracy: 0.4961 - val_loss: 0.6931 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 5/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6931 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.4904\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6932 - val_accuracy: 0.4934\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6931 - accuracy: 0.5105 - val_loss: 0.6932 - val_accuracy: 0.4975\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6930 - accuracy: 0.5072 - val_loss: 0.6934 - val_accuracy: 0.4995\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6931 - accuracy: 0.4966 - val_loss: 0.6932 - val_accuracy: 0.4833\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6930 - accuracy: 0.5128 - val_loss: 0.6935 - val_accuracy: 0.4995\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6931 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.5217\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6936 - val_accuracy: 0.5066\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6927 - accuracy: 0.5034 - val_loss: 0.6944 - val_accuracy: 0.5197\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6924 - accuracy: 0.5067 - val_loss: 0.6954 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6923 - accuracy: 0.5100 - val_loss: 0.6967 - val_accuracy: 0.4914\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6921 - accuracy: 0.5082 - val_loss: 0.6967 - val_accuracy: 0.4934\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6921 - accuracy: 0.5188 - val_loss: 0.6957 - val_accuracy: 0.4863\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6919 - accuracy: 0.5115 - val_loss: 0.6956 - val_accuracy: 0.4924\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6921 - accuracy: 0.4989 - val_loss: 0.6963 - val_accuracy: 0.4975\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6918 - accuracy: 0.5130 - val_loss: 0.6937 - val_accuracy: 0.4944\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6926 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.4934\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6921 - accuracy: 0.5095 - val_loss: 0.6945 - val_accuracy: 0.4985\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6920 - accuracy: 0.5118 - val_loss: 0.6981 - val_accuracy: 0.4924\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6930 - accuracy: 0.5065 - val_loss: 0.6933 - val_accuracy: 0.4985\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6925 - accuracy: 0.5125 - val_loss: 0.6933 - val_accuracy: 0.5076\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6922 - accuracy: 0.5133 - val_loss: 0.6942 - val_accuracy: 0.4944\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6921 - accuracy: 0.5054 - val_loss: 0.6952 - val_accuracy: 0.4954\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6920 - accuracy: 0.5130 - val_loss: 0.6952 - val_accuracy: 0.4995\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6918 - accuracy: 0.5100 - val_loss: 0.6975 - val_accuracy: 0.4914\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6916 - accuracy: 0.5108 - val_loss: 0.6973 - val_accuracy: 0.4954\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6915 - accuracy: 0.5156 - val_loss: 0.7013 - val_accuracy: 0.4944\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6915 - accuracy: 0.5135 - val_loss: 0.6978 - val_accuracy: 0.5025\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6972 - val_accuracy: 0.5106\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6915 - accuracy: 0.5158 - val_loss: 0.6981 - val_accuracy: 0.5046\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6938 - val_accuracy: 0.5126\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6942 - val_accuracy: 0.5116\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6946 - val_accuracy: 0.5116\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6911 - accuracy: 0.5163 - val_loss: 0.6954 - val_accuracy: 0.5076\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6957 - val_accuracy: 0.5066\nEpoch 2/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6908 - accuracy: 0.5188 - val_loss: 0.6968 - val_accuracy: 0.5096\nEpoch 3/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.6910 - accuracy: 0.5183 - val_loss: 0.6959 - val_accuracy: 0.5126\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6908 - accuracy: 0.5128 - val_loss: 0.6980 - val_accuracy: 0.5066\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6911 - accuracy: 0.5049 - val_loss: 0.7000 - val_accuracy: 0.5086\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6905 - accuracy: 0.5145 - val_loss: 0.7010 - val_accuracy: 0.5046\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6907 - accuracy: 0.5085 - val_loss: 0.7025 - val_accuracy: 0.5035\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6902 - accuracy: 0.5201 - val_loss: 0.7054 - val_accuracy: 0.5086\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6896 - accuracy: 0.5290 - val_loss: 0.7060 - val_accuracy: 0.5126\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6900 - accuracy: 0.5231 - val_loss: 0.7064 - val_accuracy: 0.5137\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6897 - accuracy: 0.5269 - val_loss: 0.7062 - val_accuracy: 0.5147\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6893 - accuracy: 0.5254 - val_loss: 0.7039 - val_accuracy: 0.5217\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6892 - accuracy: 0.5300 - val_loss: 0.7062 - val_accuracy: 0.5116\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6902 - accuracy: 0.5221 - val_loss: 0.7054 - val_accuracy: 0.5187\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6904 - accuracy: 0.5173 - val_loss: 0.7070 - val_accuracy: 0.5056\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6902 - accuracy: 0.5138 - val_loss: 0.7057 - val_accuracy: 0.5157\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6891 - accuracy: 0.5285 - val_loss: 0.7050 - val_accuracy: 0.5126\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6894 - accuracy: 0.5272 - val_loss: 0.7062 - val_accuracy: 0.5005\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6884 - accuracy: 0.5310 - val_loss: 0.6992 - val_accuracy: 0.5137\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6887 - accuracy: 0.5300 - val_loss: 0.7004 - val_accuracy: 0.5086\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6902 - accuracy: 0.5143 - val_loss: 0.6997 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6910 - accuracy: 0.5022 - val_loss: 0.7032 - val_accuracy: 0.5126\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6903 - accuracy: 0.5105 - val_loss: 0.7031 - val_accuracy: 0.5096\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6894 - accuracy: 0.5209 - val_loss: 0.7009 - val_accuracy: 0.5096\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6895 - accuracy: 0.5153 - val_loss: 0.7013 - val_accuracy: 0.5025\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6896 - accuracy: 0.5178 - val_loss: 0.7013 - val_accuracy: 0.5066\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6885 - accuracy: 0.5282 - val_loss: 0.7042 - val_accuracy: 0.5046\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6882 - accuracy: 0.5280 - val_loss: 0.7014 - val_accuracy: 0.5207\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6893 - accuracy: 0.5244 - val_loss: 0.7026 - val_accuracy: 0.5025\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6897 - accuracy: 0.5171 - val_loss: 0.7061 - val_accuracy: 0.4995\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6899 - accuracy: 0.5176 - val_loss: 0.7064 - val_accuracy: 0.5076\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6884 - accuracy: 0.5269 - val_loss: 0.7061 - val_accuracy: 0.5116\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6874 - accuracy: 0.5280 - val_loss: 0.7061 - val_accuracy: 0.5147\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6880 - accuracy: 0.5274 - val_loss: 0.7072 - val_accuracy: 0.5238\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6880 - accuracy: 0.5315 - val_loss: 0.7023 - val_accuracy: 0.5389\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6891 - accuracy: 0.5196 - val_loss: 0.7007 - val_accuracy: 0.5177\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6887 - accuracy: 0.5282 - val_loss: 0.6997 - val_accuracy: 0.5197\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6888 - accuracy: 0.5269 - val_loss: 0.6970 - val_accuracy: 0.5258\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6886 - accuracy: 0.5323 - val_loss: 0.6988 - val_accuracy: 0.5167\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6882 - accuracy: 0.5292 - val_loss: 0.7010 - val_accuracy: 0.5086\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6883 - accuracy: 0.5302 - val_loss: 0.7015 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6879 - accuracy: 0.5280 - val_loss: 0.7071 - val_accuracy: 0.5147\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6878 - accuracy: 0.5231 - val_loss: 0.7049 - val_accuracy: 0.5147\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6872 - accuracy: 0.5315 - val_loss: 0.7088 - val_accuracy: 0.5096\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6889 - accuracy: 0.5196 - val_loss: 0.7083 - val_accuracy: 0.5126\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6884 - accuracy: 0.5312 - val_loss: 0.7083 - val_accuracy: 0.5157\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6875 - accuracy: 0.5366 - val_loss: 0.7060 - val_accuracy: 0.5238\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6867 - accuracy: 0.5414 - val_loss: 0.7075 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6889 - accuracy: 0.5161 - val_loss: 0.7083 - val_accuracy: 0.4954\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6892 - accuracy: 0.5171 - val_loss: 0.7065 - val_accuracy: 0.5126\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6866 - accuracy: 0.5355 - val_loss: 0.7066 - val_accuracy: 0.5076\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6871 - accuracy: 0.5366 - val_loss: 0.7085 - val_accuracy: 0.5157\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6871 - accuracy: 0.5297 - val_loss: 0.7076 - val_accuracy: 0.5187\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6868 - accuracy: 0.5378 - val_loss: 0.7094 - val_accuracy: 0.5025\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6861 - accuracy: 0.5305 - val_loss: 0.7071 - val_accuracy: 0.5086\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6868 - accuracy: 0.5371 - val_loss: 0.7070 - val_accuracy: 0.5106\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6854 - accuracy: 0.5449 - val_loss: 0.7130 - val_accuracy: 0.5025\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6875 - accuracy: 0.5312 - val_loss: 0.7070 - val_accuracy: 0.5126\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6865 - accuracy: 0.5310 - val_loss: 0.7073 - val_accuracy: 0.5046\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6858 - accuracy: 0.5409 - val_loss: 0.7089 - val_accuracy: 0.4954\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6873 - accuracy: 0.5199 - val_loss: 0.7081 - val_accuracy: 0.5035\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6852 - accuracy: 0.5409 - val_loss: 0.7080 - val_accuracy: 0.4975\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6844 - accuracy: 0.5421 - val_loss: 0.7094 - val_accuracy: 0.5167\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6848 - accuracy: 0.5409 - val_loss: 0.7092 - val_accuracy: 0.4894\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6862 - accuracy: 0.5340 - val_loss: 0.7077 - val_accuracy: 0.5167\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6854 - accuracy: 0.5325 - val_loss: 0.7084 - val_accuracy: 0.4985\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6843 - accuracy: 0.5406 - val_loss: 0.7099 - val_accuracy: 0.5066\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6844 - accuracy: 0.5409 - val_loss: 0.7077 - val_accuracy: 0.5157\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6843 - accuracy: 0.5391 - val_loss: 0.7076 - val_accuracy: 0.5025\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6827 - accuracy: 0.5510 - val_loss: 0.7096 - val_accuracy: 0.5147\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6837 - accuracy: 0.5457 - val_loss: 0.7087 - val_accuracy: 0.4954\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6835 - accuracy: 0.5497 - val_loss: 0.7107 - val_accuracy: 0.5035\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6871 - accuracy: 0.5368 - val_loss: 0.7091 - val_accuracy: 0.4934\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6866 - accuracy: 0.5350 - val_loss: 0.7075 - val_accuracy: 0.5076\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6854 - accuracy: 0.5414 - val_loss: 0.7150 - val_accuracy: 0.5137\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6878 - accuracy: 0.5386 - val_loss: 0.7097 - val_accuracy: 0.4934\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6863 - accuracy: 0.5424 - val_loss: 0.7129 - val_accuracy: 0.4823\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6853 - accuracy: 0.5472 - val_loss: 0.7132 - val_accuracy: 0.5046\nEpoch 4/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6869 - accuracy: 0.5424 - val_loss: 0.7090 - val_accuracy: 0.4975\nEpoch 5/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.6850 - accuracy: 0.5426 - val_loss: 0.7145 - val_accuracy: 0.5096\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6841 - accuracy: 0.5553 - val_loss: 0.7156 - val_accuracy: 0.5015\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6841 - accuracy: 0.5500 - val_loss: 0.7115 - val_accuracy: 0.5126\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6841 - accuracy: 0.5490 - val_loss: 0.7136 - val_accuracy: 0.5015\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6841 - accuracy: 0.5492 - val_loss: 0.7144 - val_accuracy: 0.4965\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6850 - accuracy: 0.5414 - val_loss: 0.7128 - val_accuracy: 0.5238\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6850 - accuracy: 0.5426 - val_loss: 0.7128 - val_accuracy: 0.4995\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6837 - accuracy: 0.5398 - val_loss: 0.7140 - val_accuracy: 0.5015\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6821 - accuracy: 0.5517 - val_loss: 0.7134 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6819 - accuracy: 0.5517 - val_loss: 0.7128 - val_accuracy: 0.4954\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6820 - accuracy: 0.5497 - val_loss: 0.7174 - val_accuracy: 0.4985\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6837 - accuracy: 0.5436 - val_loss: 0.7137 - val_accuracy: 0.4954\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6820 - accuracy: 0.5527 - val_loss: 0.7162 - val_accuracy: 0.4975\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6813 - accuracy: 0.5596 - val_loss: 0.7194 - val_accuracy: 0.5025\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6810 - accuracy: 0.5490 - val_loss: 0.7261 - val_accuracy: 0.5066\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6810 - accuracy: 0.5545 - val_loss: 0.7203 - val_accuracy: 0.5035\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6809 - accuracy: 0.5467 - val_loss: 0.7210 - val_accuracy: 0.4975\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6804 - accuracy: 0.5533 - val_loss: 0.7193 - val_accuracy: 0.5015\nEpoch 3/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.6808 - accuracy: 0.5517 - val_loss: 0.7167 - val_accuracy: 0.4954\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.6813 - accuracy: 0.5510 - val_loss: 0.7182 - val_accuracy: 0.5137\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.6802 - accuracy: 0.5555 - val_loss: 0.7168 - val_accuracy: 0.5126\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6818 - accuracy: 0.5535 - val_loss: 0.7171 - val_accuracy: 0.5076\nEpoch 2/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.6837 - accuracy: 0.5446 - val_loss: 0.7152 - val_accuracy: 0.5005\nEpoch 3/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.6824 - accuracy: 0.5497 - val_loss: 0.7170 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6807 - accuracy: 0.5535 - val_loss: 0.7206 - val_accuracy: 0.5015\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6831 - accuracy: 0.5474 - val_loss: 0.7222 - val_accuracy: 0.5076\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6801 - accuracy: 0.5497 - val_loss: 0.7220 - val_accuracy: 0.4904\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6814 - accuracy: 0.5533 - val_loss: 0.7217 - val_accuracy: 0.5005\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6795 - accuracy: 0.5568 - val_loss: 0.7205 - val_accuracy: 0.5025\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6796 - accuracy: 0.5522 - val_loss: 0.7179 - val_accuracy: 0.4995\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6778 - accuracy: 0.5588 - val_loss: 0.7193 - val_accuracy: 0.5015\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6772 - accuracy: 0.5634 - val_loss: 0.7220 - val_accuracy: 0.5015\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6800 - accuracy: 0.5596 - val_loss: 0.7288 - val_accuracy: 0.5066\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6792 - accuracy: 0.5629 - val_loss: 0.7185 - val_accuracy: 0.5066\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6786 - accuracy: 0.5601 - val_loss: 0.7200 - val_accuracy: 0.5086\nEpoch 5/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.6769 - accuracy: 0.5568 - val_loss: 0.7176 - val_accuracy: 0.5066\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6784 - accuracy: 0.5608 - val_loss: 0.7199 - val_accuracy: 0.5177\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6754 - accuracy: 0.5689 - val_loss: 0.7332 - val_accuracy: 0.4934\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6783 - accuracy: 0.5570 - val_loss: 0.7212 - val_accuracy: 0.5106\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6770 - accuracy: 0.5629 - val_loss: 0.7364 - val_accuracy: 0.5035\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6800 - accuracy: 0.5565 - val_loss: 0.7187 - val_accuracy: 0.5137\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6788 - accuracy: 0.5667 - val_loss: 0.7185 - val_accuracy: 0.5076\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6774 - accuracy: 0.5654 - val_loss: 0.7237 - val_accuracy: 0.5086\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6769 - accuracy: 0.5636 - val_loss: 0.7257 - val_accuracy: 0.4995\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6764 - accuracy: 0.5593 - val_loss: 0.7251 - val_accuracy: 0.5086\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6771 - accuracy: 0.5684 - val_loss: 0.7179 - val_accuracy: 0.5076\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6792 - accuracy: 0.5601 - val_loss: 0.7235 - val_accuracy: 0.4954\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6789 - accuracy: 0.5517 - val_loss: 0.7240 - val_accuracy: 0.5278\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6789 - accuracy: 0.5548 - val_loss: 0.7210 - val_accuracy: 0.4954\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6746 - accuracy: 0.5674 - val_loss: 0.7305 - val_accuracy: 0.5086\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6761 - accuracy: 0.5682 - val_loss: 0.7190 - val_accuracy: 0.5116\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6746 - accuracy: 0.5753 - val_loss: 0.7240 - val_accuracy: 0.5177\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6779 - accuracy: 0.5634 - val_loss: 0.7380 - val_accuracy: 0.5066\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6779 - accuracy: 0.5606 - val_loss: 0.7245 - val_accuracy: 0.5137\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6738 - accuracy: 0.5730 - val_loss: 0.7290 - val_accuracy: 0.5025\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6753 - accuracy: 0.5687 - val_loss: 0.7362 - val_accuracy: 0.4843\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6774 - accuracy: 0.5631 - val_loss: 0.7231 - val_accuracy: 0.5217\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6757 - accuracy: 0.5697 - val_loss: 0.7238 - val_accuracy: 0.5197\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6760 - accuracy: 0.5778 - val_loss: 0.7232 - val_accuracy: 0.5308\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6742 - accuracy: 0.5750 - val_loss: 0.7212 - val_accuracy: 0.5157\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6738 - accuracy: 0.5732 - val_loss: 0.7272 - val_accuracy: 0.5066\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6717 - accuracy: 0.5801 - val_loss: 0.7266 - val_accuracy: 0.5147\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6750 - accuracy: 0.5717 - val_loss: 0.7317 - val_accuracy: 0.5025\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6780 - accuracy: 0.5613 - val_loss: 0.7300 - val_accuracy: 0.5137\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6771 - accuracy: 0.5710 - val_loss: 0.7093 - val_accuracy: 0.5056\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6743 - accuracy: 0.5725 - val_loss: 0.7293 - val_accuracy: 0.5116\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6727 - accuracy: 0.5755 - val_loss: 0.7337 - val_accuracy: 0.5116\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6742 - accuracy: 0.5745 - val_loss: 0.7327 - val_accuracy: 0.4985\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6766 - accuracy: 0.5674 - val_loss: 0.7201 - val_accuracy: 0.5228\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6710 - accuracy: 0.5753 - val_loss: 0.7243 - val_accuracy: 0.5116\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6711 - accuracy: 0.5856 - val_loss: 0.7214 - val_accuracy: 0.5116\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6715 - accuracy: 0.5889 - val_loss: 0.7285 - val_accuracy: 0.5238\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6712 - accuracy: 0.5742 - val_loss: 0.7279 - val_accuracy: 0.5207\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6727 - accuracy: 0.5816 - val_loss: 0.7239 - val_accuracy: 0.5197\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6742 - accuracy: 0.5785 - val_loss: 0.7252 - val_accuracy: 0.5157\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6754 - accuracy: 0.5684 - val_loss: 0.7215 - val_accuracy: 0.5167\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6737 - accuracy: 0.5710 - val_loss: 0.7204 - val_accuracy: 0.5258\nEpoch 2/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6734 - accuracy: 0.5773 - val_loss: 0.7269 - val_accuracy: 0.5288\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6738 - accuracy: 0.5765 - val_loss: 0.7260 - val_accuracy: 0.5248\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6721 - accuracy: 0.5763 - val_loss: 0.7226 - val_accuracy: 0.5187\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6673 - accuracy: 0.5834 - val_loss: 0.7297 - val_accuracy: 0.5228\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6674 - accuracy: 0.5849 - val_loss: 0.7252 - val_accuracy: 0.5288\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6665 - accuracy: 0.5965 - val_loss: 0.7289 - val_accuracy: 0.5329\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6712 - accuracy: 0.5770 - val_loss: 0.7211 - val_accuracy: 0.5349\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6700 - accuracy: 0.5796 - val_loss: 0.7221 - val_accuracy: 0.5329\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6653 - accuracy: 0.5813 - val_loss: 0.7255 - val_accuracy: 0.5288\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6682 - accuracy: 0.5821 - val_loss: 0.7268 - val_accuracy: 0.5399\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6660 - accuracy: 0.5914 - val_loss: 0.7295 - val_accuracy: 0.5308\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6645 - accuracy: 0.5925 - val_loss: 0.7239 - val_accuracy: 0.5288\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6670 - accuracy: 0.5849 - val_loss: 0.7293 - val_accuracy: 0.5147\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6639 - accuracy: 0.5927 - val_loss: 0.7415 - val_accuracy: 0.5440\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6681 - accuracy: 0.5803 - val_loss: 0.7294 - val_accuracy: 0.5389\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6663 - accuracy: 0.5841 - val_loss: 0.7365 - val_accuracy: 0.5339\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6686 - accuracy: 0.5874 - val_loss: 0.7356 - val_accuracy: 0.5187\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6786 - accuracy: 0.5596 - val_loss: 0.7233 - val_accuracy: 0.5197\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6709 - accuracy: 0.5834 - val_loss: 0.7259 - val_accuracy: 0.5157\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6625 - accuracy: 0.6013 - val_loss: 0.7274 - val_accuracy: 0.5238\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6658 - accuracy: 0.5823 - val_loss: 0.7317 - val_accuracy: 0.5288\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6668 - accuracy: 0.5791 - val_loss: 0.7205 - val_accuracy: 0.5369\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6643 - accuracy: 0.5892 - val_loss: 0.7306 - val_accuracy: 0.5228\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6651 - accuracy: 0.5887 - val_loss: 0.7261 - val_accuracy: 0.5086\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6637 - accuracy: 0.5914 - val_loss: 0.7272 - val_accuracy: 0.5308\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6661 - accuracy: 0.5818 - val_loss: 0.7163 - val_accuracy: 0.5349\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6588 - accuracy: 0.5935 - val_loss: 0.7346 - val_accuracy: 0.5268\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6593 - accuracy: 0.5950 - val_loss: 0.7202 - val_accuracy: 0.5430\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6631 - accuracy: 0.5892 - val_loss: 0.7224 - val_accuracy: 0.5359\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6601 - accuracy: 0.5995 - val_loss: 0.7271 - val_accuracy: 0.5511\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6577 - accuracy: 0.6016 - val_loss: 0.7299 - val_accuracy: 0.5238\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6620 - accuracy: 0.5947 - val_loss: 0.7370 - val_accuracy: 0.5228\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6656 - accuracy: 0.5947 - val_loss: 0.7290 - val_accuracy: 0.5359\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6618 - accuracy: 0.5902 - val_loss: 0.7190 - val_accuracy: 0.5420\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6585 - accuracy: 0.6061 - val_loss: 0.7306 - val_accuracy: 0.5460\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6621 - accuracy: 0.5854 - val_loss: 0.7226 - val_accuracy: 0.5339\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6631 - accuracy: 0.5947 - val_loss: 0.7329 - val_accuracy: 0.5228\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6683 - accuracy: 0.5882 - val_loss: 0.7162 - val_accuracy: 0.5410\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6613 - accuracy: 0.5922 - val_loss: 0.7332 - val_accuracy: 0.5349\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6630 - accuracy: 0.5879 - val_loss: 0.7207 - val_accuracy: 0.5430\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6563 - accuracy: 0.6056 - val_loss: 0.7262 - val_accuracy: 0.5410\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6614 - accuracy: 0.6001 - val_loss: 0.7382 - val_accuracy: 0.5420\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6600 - accuracy: 0.6001 - val_loss: 0.7386 - val_accuracy: 0.5278\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6605 - accuracy: 0.5945 - val_loss: 0.7238 - val_accuracy: 0.5349\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6580 - accuracy: 0.5955 - val_loss: 0.7237 - val_accuracy: 0.5470\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6543 - accuracy: 0.6028 - val_loss: 0.7214 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6544 - accuracy: 0.6056 - val_loss: 0.7173 - val_accuracy: 0.5490\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6527 - accuracy: 0.6102 - val_loss: 0.7269 - val_accuracy: 0.5339\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6617 - accuracy: 0.5897 - val_loss: 0.7266 - val_accuracy: 0.5389\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6584 - accuracy: 0.5942 - val_loss: 0.7433 - val_accuracy: 0.5116\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6564 - accuracy: 0.5945 - val_loss: 0.7288 - val_accuracy: 0.5349\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6564 - accuracy: 0.6071 - val_loss: 0.7318 - val_accuracy: 0.5501\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6566 - accuracy: 0.5980 - val_loss: 0.7239 - val_accuracy: 0.5521\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6489 - accuracy: 0.6087 - val_loss: 0.7175 - val_accuracy: 0.5501\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6586 - accuracy: 0.5922 - val_loss: 0.7229 - val_accuracy: 0.5420\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6534 - accuracy: 0.6061 - val_loss: 0.7195 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6554 - accuracy: 0.5980 - val_loss: 0.7408 - val_accuracy: 0.5379\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6552 - accuracy: 0.6023 - val_loss: 0.7288 - val_accuracy: 0.5410\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6594 - accuracy: 0.6061 - val_loss: 0.7252 - val_accuracy: 0.5369\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6628 - accuracy: 0.5874 - val_loss: 0.7265 - val_accuracy: 0.5359\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6562 - accuracy: 0.6038 - val_loss: 0.7165 - val_accuracy: 0.5410\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6545 - accuracy: 0.6016 - val_loss: 0.7237 - val_accuracy: 0.5329\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6557 - accuracy: 0.5985 - val_loss: 0.7247 - val_accuracy: 0.5369\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6564 - accuracy: 0.6018 - val_loss: 0.7217 - val_accuracy: 0.5501\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6483 - accuracy: 0.6140 - val_loss: 0.7385 - val_accuracy: 0.5420\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6539 - accuracy: 0.6087 - val_loss: 0.7189 - val_accuracy: 0.5551\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6541 - accuracy: 0.6092 - val_loss: 0.7190 - val_accuracy: 0.5470\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6524 - accuracy: 0.6036 - val_loss: 0.7254 - val_accuracy: 0.5420\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6506 - accuracy: 0.6051 - val_loss: 0.7192 - val_accuracy: 0.5571\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6479 - accuracy: 0.6122 - val_loss: 0.7240 - val_accuracy: 0.5480\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6477 - accuracy: 0.6127 - val_loss: 0.7247 - val_accuracy: 0.5551\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6455 - accuracy: 0.6119 - val_loss: 0.7178 - val_accuracy: 0.5420\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6445 - accuracy: 0.6165 - val_loss: 0.7289 - val_accuracy: 0.5329\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6501 - accuracy: 0.6087 - val_loss: 0.7341 - val_accuracy: 0.5410\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6601 - accuracy: 0.5892 - val_loss: 0.7197 - val_accuracy: 0.5420\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6476 - accuracy: 0.6109 - val_loss: 0.7286 - val_accuracy: 0.5490\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6462 - accuracy: 0.6223 - val_loss: 0.7225 - val_accuracy: 0.5490\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6486 - accuracy: 0.6112 - val_loss: 0.7241 - val_accuracy: 0.5319\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6458 - accuracy: 0.6132 - val_loss: 0.7261 - val_accuracy: 0.5450\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6403 - accuracy: 0.6231 - val_loss: 0.7248 - val_accuracy: 0.5511\nEpoch 2/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.6434 - accuracy: 0.6175 - val_loss: 0.7251 - val_accuracy: 0.5541\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6460 - accuracy: 0.6195 - val_loss: 0.7247 - val_accuracy: 0.5521\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6411 - accuracy: 0.6241 - val_loss: 0.7329 - val_accuracy: 0.5420\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6401 - accuracy: 0.6294 - val_loss: 0.7301 - val_accuracy: 0.5450\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6444 - accuracy: 0.6195 - val_loss: 0.7342 - val_accuracy: 0.5460\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6489 - accuracy: 0.6178 - val_loss: 0.7326 - val_accuracy: 0.5490\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6434 - accuracy: 0.6178 - val_loss: 0.7440 - val_accuracy: 0.5531\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6497 - accuracy: 0.6114 - val_loss: 0.7295 - val_accuracy: 0.5420\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6441 - accuracy: 0.6152 - val_loss: 0.7209 - val_accuracy: 0.5561\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6483 - accuracy: 0.6064 - val_loss: 0.7330 - val_accuracy: 0.5430\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6434 - accuracy: 0.6170 - val_loss: 0.7348 - val_accuracy: 0.5470\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6419 - accuracy: 0.6205 - val_loss: 0.7357 - val_accuracy: 0.5480\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6344 - accuracy: 0.6347 - val_loss: 0.7539 - val_accuracy: 0.5420\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6371 - accuracy: 0.6236 - val_loss: 0.7428 - val_accuracy: 0.5612\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6387 - accuracy: 0.6248 - val_loss: 0.7447 - val_accuracy: 0.5511\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6455 - accuracy: 0.6210 - val_loss: 0.7322 - val_accuracy: 0.5319\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6475 - accuracy: 0.6107 - val_loss: 0.7298 - val_accuracy: 0.5531\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6432 - accuracy: 0.6205 - val_loss: 0.7370 - val_accuracy: 0.5490\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6401 - accuracy: 0.6274 - val_loss: 0.7634 - val_accuracy: 0.5602\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6368 - accuracy: 0.6294 - val_loss: 0.7587 - val_accuracy: 0.5399\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6380 - accuracy: 0.6269 - val_loss: 0.7470 - val_accuracy: 0.5541\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6347 - accuracy: 0.6276 - val_loss: 0.7533 - val_accuracy: 0.5349\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6354 - accuracy: 0.6332 - val_loss: 0.7296 - val_accuracy: 0.5480\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6370 - accuracy: 0.6266 - val_loss: 0.7485 - val_accuracy: 0.5470\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6343 - accuracy: 0.6365 - val_loss: 0.7582 - val_accuracy: 0.5450\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6317 - accuracy: 0.6370 - val_loss: 0.7327 - val_accuracy: 0.5602\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6350 - accuracy: 0.6296 - val_loss: 0.7661 - val_accuracy: 0.5521\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6424 - accuracy: 0.6223 - val_loss: 0.7372 - val_accuracy: 0.5268\nEpoch 5/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6441 - accuracy: 0.6145 - val_loss: 0.7454 - val_accuracy: 0.5480\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6364 - accuracy: 0.6324 - val_loss: 0.7498 - val_accuracy: 0.5561\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6315 - accuracy: 0.6352 - val_loss: 0.7689 - val_accuracy: 0.5339\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6332 - accuracy: 0.6352 - val_loss: 0.7772 - val_accuracy: 0.5410\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6369 - accuracy: 0.6334 - val_loss: 0.7338 - val_accuracy: 0.5480\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6305 - accuracy: 0.6365 - val_loss: 0.7272 - val_accuracy: 0.5602\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6307 - accuracy: 0.6355 - val_loss: 0.7306 - val_accuracy: 0.5541\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6278 - accuracy: 0.6423 - val_loss: 0.7722 - val_accuracy: 0.5531\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6369 - accuracy: 0.6291 - val_loss: 0.7438 - val_accuracy: 0.5389\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6373 - accuracy: 0.6319 - val_loss: 0.7473 - val_accuracy: 0.5531\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6367 - accuracy: 0.6294 - val_loss: 0.7351 - val_accuracy: 0.5430\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6304 - accuracy: 0.6357 - val_loss: 0.7325 - val_accuracy: 0.5592\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6293 - accuracy: 0.6423 - val_loss: 0.7502 - val_accuracy: 0.5440\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6415 - accuracy: 0.6218 - val_loss: 0.7378 - val_accuracy: 0.5581\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6352 - accuracy: 0.6362 - val_loss: 0.7321 - val_accuracy: 0.5511\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6265 - accuracy: 0.6469 - val_loss: 0.7483 - val_accuracy: 0.5329\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6294 - accuracy: 0.6418 - val_loss: 0.7578 - val_accuracy: 0.5379\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6313 - accuracy: 0.6345 - val_loss: 0.7512 - val_accuracy: 0.5551\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6311 - accuracy: 0.6441 - val_loss: 0.7465 - val_accuracy: 0.5319\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6285 - accuracy: 0.6385 - val_loss: 0.7471 - val_accuracy: 0.5501\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6288 - accuracy: 0.6360 - val_loss: 0.7332 - val_accuracy: 0.5551\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6300 - accuracy: 0.6398 - val_loss: 0.7302 - val_accuracy: 0.5470\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6261 - accuracy: 0.6393 - val_loss: 0.7302 - val_accuracy: 0.5642\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6240 - accuracy: 0.6431 - val_loss: 0.7382 - val_accuracy: 0.5531\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6249 - accuracy: 0.6451 - val_loss: 0.7419 - val_accuracy: 0.5571\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6216 - accuracy: 0.6496 - val_loss: 0.7467 - val_accuracy: 0.5470\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6230 - accuracy: 0.6446 - val_loss: 0.7544 - val_accuracy: 0.5652\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6231 - accuracy: 0.6438 - val_loss: 0.7402 - val_accuracy: 0.5460\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6266 - accuracy: 0.6476 - val_loss: 0.7468 - val_accuracy: 0.5359\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6328 - accuracy: 0.6345 - val_loss: 0.7605 - val_accuracy: 0.5369\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6250 - accuracy: 0.6408 - val_loss: 0.7391 - val_accuracy: 0.5430\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6264 - accuracy: 0.6509 - val_loss: 0.7387 - val_accuracy: 0.5420\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6246 - accuracy: 0.6433 - val_loss: 0.7509 - val_accuracy: 0.5480\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6203 - accuracy: 0.6532 - val_loss: 0.7396 - val_accuracy: 0.5632\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6203 - accuracy: 0.6509 - val_loss: 0.7461 - val_accuracy: 0.5571\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6284 - accuracy: 0.6380 - val_loss: 0.7425 - val_accuracy: 0.5551\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6287 - accuracy: 0.6453 - val_loss: 0.7608 - val_accuracy: 0.5602\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6254 - accuracy: 0.6415 - val_loss: 0.7480 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6207 - accuracy: 0.6471 - val_loss: 0.7415 - val_accuracy: 0.5501\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6243 - accuracy: 0.6443 - val_loss: 0.7478 - val_accuracy: 0.5521\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6215 - accuracy: 0.6491 - val_loss: 0.7378 - val_accuracy: 0.5551\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6182 - accuracy: 0.6552 - val_loss: 0.7673 - val_accuracy: 0.5329\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6265 - accuracy: 0.6420 - val_loss: 0.7449 - val_accuracy: 0.5652\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6167 - accuracy: 0.6534 - val_loss: 0.7525 - val_accuracy: 0.5541\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6190 - accuracy: 0.6517 - val_loss: 0.7441 - val_accuracy: 0.5440\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6204 - accuracy: 0.6575 - val_loss: 0.7492 - val_accuracy: 0.5430\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6242 - accuracy: 0.6484 - val_loss: 0.7459 - val_accuracy: 0.5612\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6219 - accuracy: 0.6519 - val_loss: 0.7425 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6170 - accuracy: 0.6567 - val_loss: 0.7449 - val_accuracy: 0.5713\nEpoch 4/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6178 - accuracy: 0.6537 - val_loss: 0.7712 - val_accuracy: 0.5420\nEpoch 5/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6240 - accuracy: 0.6420 - val_loss: 0.7511 - val_accuracy: 0.5460\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6253 - accuracy: 0.6398 - val_loss: 0.7605 - val_accuracy: 0.5511\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6181 - accuracy: 0.6517 - val_loss: 0.7325 - val_accuracy: 0.5683\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6206 - accuracy: 0.6481 - val_loss: 0.7335 - val_accuracy: 0.5551\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6190 - accuracy: 0.6476 - val_loss: 0.7421 - val_accuracy: 0.5541\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6133 - accuracy: 0.6590 - val_loss: 0.7534 - val_accuracy: 0.5541\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6171 - accuracy: 0.6486 - val_loss: 0.7429 - val_accuracy: 0.5632\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6117 - accuracy: 0.6565 - val_loss: 0.7513 - val_accuracy: 0.5541\nEpoch 3/5\n3953/3953 [==============================] - 0s 47us/sample - loss: 0.6178 - accuracy: 0.6532 - val_loss: 0.7484 - val_accuracy: 0.5672\nEpoch 4/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.6211 - accuracy: 0.6549 - val_loss: 0.7397 - val_accuracy: 0.5592\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.6200 - accuracy: 0.6453 - val_loss: 0.7430 - val_accuracy: 0.5581\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.6178 - accuracy: 0.6466 - val_loss: 0.7580 - val_accuracy: 0.5308\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6159 - accuracy: 0.6549 - val_loss: 0.7492 - val_accuracy: 0.5531\nEpoch 3/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.6104 - accuracy: 0.6608 - val_loss: 0.7548 - val_accuracy: 0.5440\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6057 - accuracy: 0.6633 - val_loss: 0.7556 - val_accuracy: 0.5703\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6099 - accuracy: 0.6575 - val_loss: 0.7525 - val_accuracy: 0.5511\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6160 - accuracy: 0.6580 - val_loss: 0.7403 - val_accuracy: 0.5703\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6128 - accuracy: 0.6587 - val_loss: 0.7413 - val_accuracy: 0.5662\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6270 - accuracy: 0.6405 - val_loss: 0.7626 - val_accuracy: 0.5501\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6348 - accuracy: 0.6284 - val_loss: 0.7397 - val_accuracy: 0.5521\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6207 - accuracy: 0.6481 - val_loss: 0.7429 - val_accuracy: 0.5460\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6086 - accuracy: 0.6653 - val_loss: 0.7534 - val_accuracy: 0.5551\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6087 - accuracy: 0.6615 - val_loss: 0.7492 - val_accuracy: 0.5571\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6102 - accuracy: 0.6613 - val_loss: 0.7561 - val_accuracy: 0.5490\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6164 - accuracy: 0.6524 - val_loss: 0.7421 - val_accuracy: 0.5541\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6145 - accuracy: 0.6608 - val_loss: 0.7381 - val_accuracy: 0.5602\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6119 - accuracy: 0.6646 - val_loss: 0.7655 - val_accuracy: 0.5622\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6063 - accuracy: 0.6656 - val_loss: 0.7569 - val_accuracy: 0.5399\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6033 - accuracy: 0.6623 - val_loss: 0.7744 - val_accuracy: 0.5460\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6088 - accuracy: 0.6552 - val_loss: 0.7552 - val_accuracy: 0.5531\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6019 - accuracy: 0.6661 - val_loss: 0.7569 - val_accuracy: 0.5662\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6018 - accuracy: 0.6684 - val_loss: 0.7667 - val_accuracy: 0.5541\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6097 - accuracy: 0.6595 - val_loss: 0.7551 - val_accuracy: 0.5581\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6102 - accuracy: 0.6608 - val_loss: 0.7739 - val_accuracy: 0.5430\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6064 - accuracy: 0.6603 - val_loss: 0.7753 - val_accuracy: 0.5531\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6060 - accuracy: 0.6600 - val_loss: 0.7606 - val_accuracy: 0.5551\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.6012 - accuracy: 0.6716 - val_loss: 0.7651 - val_accuracy: 0.5521\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6090 - accuracy: 0.6663 - val_loss: 0.7547 - val_accuracy: 0.5430\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6055 - accuracy: 0.6671 - val_loss: 0.7584 - val_accuracy: 0.5683\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6016 - accuracy: 0.6643 - val_loss: 0.7992 - val_accuracy: 0.5581\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6095 - accuracy: 0.6610 - val_loss: 0.7673 - val_accuracy: 0.5420\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6203 - accuracy: 0.6496 - val_loss: 0.7472 - val_accuracy: 0.5581\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6058 - accuracy: 0.6684 - val_loss: 0.7524 - val_accuracy: 0.5592\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6083 - accuracy: 0.6661 - val_loss: 0.7446 - val_accuracy: 0.5652\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6096 - accuracy: 0.6565 - val_loss: 0.7477 - val_accuracy: 0.5592\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6047 - accuracy: 0.6671 - val_loss: 0.7782 - val_accuracy: 0.5571\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6027 - accuracy: 0.6656 - val_loss: 0.7512 - val_accuracy: 0.5531\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6039 - accuracy: 0.6620 - val_loss: 0.7659 - val_accuracy: 0.5602\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6059 - accuracy: 0.6641 - val_loss: 0.7751 - val_accuracy: 0.5592\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6052 - accuracy: 0.6646 - val_loss: 0.7559 - val_accuracy: 0.5672\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6029 - accuracy: 0.6704 - val_loss: 0.7775 - val_accuracy: 0.5571\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6060 - accuracy: 0.6709 - val_loss: 0.7629 - val_accuracy: 0.5622\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6012 - accuracy: 0.6678 - val_loss: 0.7653 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6026 - accuracy: 0.6646 - val_loss: 0.7388 - val_accuracy: 0.5683\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6059 - accuracy: 0.6646 - val_loss: 0.7700 - val_accuracy: 0.5511\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6146 - accuracy: 0.6539 - val_loss: 0.7498 - val_accuracy: 0.5511\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6079 - accuracy: 0.6658 - val_loss: 0.7530 - val_accuracy: 0.5602\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6118 - accuracy: 0.6658 - val_loss: 0.7768 - val_accuracy: 0.5561\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6080 - accuracy: 0.6575 - val_loss: 0.7552 - val_accuracy: 0.5622\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6014 - accuracy: 0.6671 - val_loss: 0.7641 - val_accuracy: 0.5501\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5979 - accuracy: 0.6739 - val_loss: 0.7668 - val_accuracy: 0.5784\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6028 - accuracy: 0.6648 - val_loss: 0.7709 - val_accuracy: 0.5571\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6062 - accuracy: 0.6625 - val_loss: 0.7462 - val_accuracy: 0.5571\nEpoch 3/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.6158 - accuracy: 0.6560 - val_loss: 0.7472 - val_accuracy: 0.5642\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.6158 - accuracy: 0.6529 - val_loss: 0.7580 - val_accuracy: 0.5541\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6175 - accuracy: 0.6562 - val_loss: 0.7494 - val_accuracy: 0.5581\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.6097 - accuracy: 0.6646 - val_loss: 0.7528 - val_accuracy: 0.5490\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6002 - accuracy: 0.6737 - val_loss: 0.7698 - val_accuracy: 0.5521\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5972 - accuracy: 0.6747 - val_loss: 0.7657 - val_accuracy: 0.5612\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5922 - accuracy: 0.6835 - val_loss: 0.7733 - val_accuracy: 0.5602\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6055 - accuracy: 0.6651 - val_loss: 0.7657 - val_accuracy: 0.5622\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5972 - accuracy: 0.6754 - val_loss: 0.7546 - val_accuracy: 0.5693\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5969 - accuracy: 0.6782 - val_loss: 0.7552 - val_accuracy: 0.5571\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5952 - accuracy: 0.6754 - val_loss: 0.7581 - val_accuracy: 0.5763\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5892 - accuracy: 0.6853 - val_loss: 0.7709 - val_accuracy: 0.5743\nEpoch 5/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5916 - accuracy: 0.6795 - val_loss: 0.7787 - val_accuracy: 0.5733\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5896 - accuracy: 0.6792 - val_loss: 0.7678 - val_accuracy: 0.5733\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5948 - accuracy: 0.6752 - val_loss: 0.7759 - val_accuracy: 0.5683\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5940 - accuracy: 0.6810 - val_loss: 0.7869 - val_accuracy: 0.5642\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5997 - accuracy: 0.6699 - val_loss: 0.7810 - val_accuracy: 0.5763\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5961 - accuracy: 0.6739 - val_loss: 0.8029 - val_accuracy: 0.5501\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5957 - accuracy: 0.6742 - val_loss: 0.7631 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5976 - accuracy: 0.6696 - val_loss: 0.7918 - val_accuracy: 0.5774\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5930 - accuracy: 0.6787 - val_loss: 0.7566 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5912 - accuracy: 0.6813 - val_loss: 0.7798 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6121 - accuracy: 0.6590 - val_loss: 0.8136 - val_accuracy: 0.5561\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5994 - accuracy: 0.6747 - val_loss: 0.7799 - val_accuracy: 0.5723\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5946 - accuracy: 0.6767 - val_loss: 0.7607 - val_accuracy: 0.5602\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6044 - accuracy: 0.6625 - val_loss: 0.7715 - val_accuracy: 0.5672\nEpoch 4/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5897 - accuracy: 0.6848 - val_loss: 0.7513 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5953 - accuracy: 0.6744 - val_loss: 0.7606 - val_accuracy: 0.5794\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5962 - accuracy: 0.6762 - val_loss: 0.7533 - val_accuracy: 0.5794\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5925 - accuracy: 0.6762 - val_loss: 0.7696 - val_accuracy: 0.5753\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5870 - accuracy: 0.6800 - val_loss: 0.7554 - val_accuracy: 0.5824\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5966 - accuracy: 0.6772 - val_loss: 0.7617 - val_accuracy: 0.5743\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5981 - accuracy: 0.6694 - val_loss: 0.7606 - val_accuracy: 0.5652\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.6016 - accuracy: 0.6678 - val_loss: 0.7934 - val_accuracy: 0.5592\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5962 - accuracy: 0.6747 - val_loss: 0.7921 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5952 - accuracy: 0.6866 - val_loss: 0.8301 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5996 - accuracy: 0.6891 - val_loss: 0.8286 - val_accuracy: 0.5683\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6042 - accuracy: 0.6757 - val_loss: 0.8336 - val_accuracy: 0.5662\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.6160 - accuracy: 0.6752 - val_loss: 0.7882 - val_accuracy: 0.5592\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.6094 - accuracy: 0.6653 - val_loss: 0.7634 - val_accuracy: 0.5723\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5980 - accuracy: 0.6744 - val_loss: 0.7774 - val_accuracy: 0.5844\nEpoch 4/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5963 - accuracy: 0.6818 - val_loss: 0.7883 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5921 - accuracy: 0.6843 - val_loss: 0.8016 - val_accuracy: 0.5713\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5915 - accuracy: 0.6797 - val_loss: 0.8014 - val_accuracy: 0.5784\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5878 - accuracy: 0.6792 - val_loss: 0.7963 - val_accuracy: 0.5784\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5966 - accuracy: 0.6767 - val_loss: 0.7869 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5898 - accuracy: 0.6805 - val_loss: 0.7667 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5864 - accuracy: 0.6850 - val_loss: 0.7885 - val_accuracy: 0.5733\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5916 - accuracy: 0.6800 - val_loss: 0.7580 - val_accuracy: 0.5602\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5952 - accuracy: 0.6704 - val_loss: 0.7749 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5835 - accuracy: 0.6868 - val_loss: 0.7617 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5928 - accuracy: 0.6772 - val_loss: 0.7781 - val_accuracy: 0.5632\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5826 - accuracy: 0.6906 - val_loss: 0.7835 - val_accuracy: 0.5763\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5800 - accuracy: 0.6888 - val_loss: 0.7814 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5851 - accuracy: 0.6825 - val_loss: 0.7782 - val_accuracy: 0.5672\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5912 - accuracy: 0.6777 - val_loss: 0.7933 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5940 - accuracy: 0.6787 - val_loss: 0.7594 - val_accuracy: 0.5632\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5839 - accuracy: 0.6843 - val_loss: 0.7858 - val_accuracy: 0.5784\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5929 - accuracy: 0.6797 - val_loss: 0.7737 - val_accuracy: 0.5763\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5886 - accuracy: 0.6843 - val_loss: 0.7866 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5836 - accuracy: 0.6896 - val_loss: 0.7965 - val_accuracy: 0.5723\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5867 - accuracy: 0.6830 - val_loss: 0.7759 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5841 - accuracy: 0.6845 - val_loss: 0.7808 - val_accuracy: 0.5814\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5780 - accuracy: 0.6899 - val_loss: 0.7899 - val_accuracy: 0.5753\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5879 - accuracy: 0.6823 - val_loss: 0.7794 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5866 - accuracy: 0.6780 - val_loss: 0.7952 - val_accuracy: 0.5824\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5857 - accuracy: 0.6828 - val_loss: 0.7689 - val_accuracy: 0.5753\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5896 - accuracy: 0.6830 - val_loss: 0.7905 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5865 - accuracy: 0.6835 - val_loss: 0.7673 - val_accuracy: 0.5794\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5795 - accuracy: 0.6896 - val_loss: 0.7920 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5784 - accuracy: 0.6906 - val_loss: 0.7717 - val_accuracy: 0.5693\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5825 - accuracy: 0.6858 - val_loss: 0.7917 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5785 - accuracy: 0.6906 - val_loss: 0.7849 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5985 - accuracy: 0.6689 - val_loss: 0.7874 - val_accuracy: 0.5662\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5861 - accuracy: 0.6858 - val_loss: 0.7927 - val_accuracy: 0.5672\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5825 - accuracy: 0.6866 - val_loss: 0.8108 - val_accuracy: 0.5723\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5862 - accuracy: 0.6802 - val_loss: 0.7836 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5836 - accuracy: 0.6866 - val_loss: 0.7927 - val_accuracy: 0.5774\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5833 - accuracy: 0.6863 - val_loss: 0.7946 - val_accuracy: 0.5763\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5867 - accuracy: 0.6843 - val_loss: 0.7779 - val_accuracy: 0.5723\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5846 - accuracy: 0.6843 - val_loss: 0.7819 - val_accuracy: 0.5703\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5808 - accuracy: 0.6888 - val_loss: 0.7661 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5795 - accuracy: 0.6881 - val_loss: 0.7642 - val_accuracy: 0.5824\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5804 - accuracy: 0.6886 - val_loss: 0.7875 - val_accuracy: 0.5743\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5807 - accuracy: 0.6901 - val_loss: 0.7922 - val_accuracy: 0.5733\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5790 - accuracy: 0.6929 - val_loss: 0.7792 - val_accuracy: 0.5804\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5832 - accuracy: 0.6881 - val_loss: 0.7733 - val_accuracy: 0.5642\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5882 - accuracy: 0.6815 - val_loss: 0.7897 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5871 - accuracy: 0.6818 - val_loss: 0.7938 - val_accuracy: 0.5713\nEpoch 2/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5886 - accuracy: 0.6800 - val_loss: 0.8064 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5818 - accuracy: 0.6861 - val_loss: 0.7948 - val_accuracy: 0.5763\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5767 - accuracy: 0.6901 - val_loss: 0.7734 - val_accuracy: 0.5824\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5813 - accuracy: 0.6893 - val_loss: 0.7876 - val_accuracy: 0.5774\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5783 - accuracy: 0.6893 - val_loss: 0.7890 - val_accuracy: 0.5693\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5825 - accuracy: 0.6858 - val_loss: 0.8075 - val_accuracy: 0.5602\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5844 - accuracy: 0.6883 - val_loss: 0.7821 - val_accuracy: 0.5683\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5919 - accuracy: 0.6807 - val_loss: 0.7750 - val_accuracy: 0.5794\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5826 - accuracy: 0.6883 - val_loss: 0.7768 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5819 - accuracy: 0.6886 - val_loss: 0.7936 - val_accuracy: 0.5824\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5838 - accuracy: 0.6891 - val_loss: 0.7787 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5800 - accuracy: 0.6944 - val_loss: 0.7760 - val_accuracy: 0.5743\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5750 - accuracy: 0.6934 - val_loss: 0.7680 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5748 - accuracy: 0.6926 - val_loss: 0.8117 - val_accuracy: 0.5713\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5761 - accuracy: 0.7000 - val_loss: 0.8022 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5783 - accuracy: 0.6949 - val_loss: 0.8051 - val_accuracy: 0.5774\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5801 - accuracy: 0.6906 - val_loss: 0.7685 - val_accuracy: 0.5733\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5708 - accuracy: 0.6944 - val_loss: 0.7933 - val_accuracy: 0.5784\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5663 - accuracy: 0.7025 - val_loss: 0.7969 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5663 - accuracy: 0.6982 - val_loss: 0.8015 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5697 - accuracy: 0.7028 - val_loss: 0.8116 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5806 - accuracy: 0.6942 - val_loss: 0.8004 - val_accuracy: 0.5743\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5778 - accuracy: 0.6937 - val_loss: 0.7936 - val_accuracy: 0.5763\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5748 - accuracy: 0.6904 - val_loss: 0.8451 - val_accuracy: 0.5703\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5816 - accuracy: 0.6876 - val_loss: 0.8117 - val_accuracy: 0.5774\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5712 - accuracy: 0.6980 - val_loss: 0.8001 - val_accuracy: 0.5804\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5659 - accuracy: 0.7017 - val_loss: 0.7821 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5676 - accuracy: 0.6980 - val_loss: 0.7674 - val_accuracy: 0.5824\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5819 - accuracy: 0.6840 - val_loss: 0.8392 - val_accuracy: 0.5713\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5991 - accuracy: 0.6754 - val_loss: 0.8050 - val_accuracy: 0.5804\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5893 - accuracy: 0.6853 - val_loss: 0.7723 - val_accuracy: 0.5865\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5832 - accuracy: 0.6848 - val_loss: 0.7980 - val_accuracy: 0.5763\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5816 - accuracy: 0.6904 - val_loss: 0.8106 - val_accuracy: 0.5794\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5843 - accuracy: 0.6820 - val_loss: 0.7845 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5884 - accuracy: 0.6893 - val_loss: 0.7655 - val_accuracy: 0.5814\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5773 - accuracy: 0.6931 - val_loss: 0.8042 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5662 - accuracy: 0.7028 - val_loss: 0.8048 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5674 - accuracy: 0.7060 - val_loss: 0.7980 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5712 - accuracy: 0.6974 - val_loss: 0.8095 - val_accuracy: 0.5723\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5753 - accuracy: 0.6942 - val_loss: 0.7974 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5711 - accuracy: 0.6947 - val_loss: 0.8029 - val_accuracy: 0.5774\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5732 - accuracy: 0.6967 - val_loss: 0.7994 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5795 - accuracy: 0.6914 - val_loss: 0.8093 - val_accuracy: 0.5592\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5876 - accuracy: 0.6866 - val_loss: 0.7816 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5793 - accuracy: 0.6888 - val_loss: 0.7847 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5760 - accuracy: 0.6947 - val_loss: 0.8189 - val_accuracy: 0.5834\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5757 - accuracy: 0.6914 - val_loss: 0.7691 - val_accuracy: 0.5844\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5826 - accuracy: 0.6853 - val_loss: 0.7792 - val_accuracy: 0.5753\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5771 - accuracy: 0.6954 - val_loss: 0.8194 - val_accuracy: 0.5602\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5767 - accuracy: 0.7005 - val_loss: 0.8205 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5694 - accuracy: 0.7017 - val_loss: 0.8241 - val_accuracy: 0.5693\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5731 - accuracy: 0.6919 - val_loss: 0.8053 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5715 - accuracy: 0.7000 - val_loss: 0.8246 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5648 - accuracy: 0.7076 - val_loss: 0.8226 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5635 - accuracy: 0.7076 - val_loss: 0.8093 - val_accuracy: 0.5794\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5672 - accuracy: 0.7005 - val_loss: 0.7901 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5634 - accuracy: 0.7050 - val_loss: 0.7986 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5644 - accuracy: 0.7048 - val_loss: 0.7823 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5634 - accuracy: 0.7073 - val_loss: 0.8112 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5732 - accuracy: 0.7010 - val_loss: 0.8260 - val_accuracy: 0.5693\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5673 - accuracy: 0.7055 - val_loss: 0.7919 - val_accuracy: 0.5703\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5631 - accuracy: 0.7081 - val_loss: 0.8245 - val_accuracy: 0.5642\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5667 - accuracy: 0.7078 - val_loss: 0.8131 - val_accuracy: 0.5723\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5588 - accuracy: 0.7088 - val_loss: 0.7896 - val_accuracy: 0.5774\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5695 - accuracy: 0.6982 - val_loss: 0.7911 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5732 - accuracy: 0.6982 - val_loss: 0.8273 - val_accuracy: 0.5652\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5754 - accuracy: 0.6997 - val_loss: 0.7743 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5807 - accuracy: 0.6947 - val_loss: 0.7829 - val_accuracy: 0.5814\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5757 - accuracy: 0.6919 - val_loss: 0.7758 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5789 - accuracy: 0.6871 - val_loss: 0.7774 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5680 - accuracy: 0.7007 - val_loss: 0.8261 - val_accuracy: 0.5763\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5647 - accuracy: 0.7076 - val_loss: 0.7901 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5683 - accuracy: 0.6985 - val_loss: 0.7845 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5624 - accuracy: 0.7116 - val_loss: 0.7828 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5619 - accuracy: 0.7071 - val_loss: 0.8070 - val_accuracy: 0.5824\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5667 - accuracy: 0.7028 - val_loss: 0.7999 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5713 - accuracy: 0.7010 - val_loss: 0.7854 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5671 - accuracy: 0.6974 - val_loss: 0.8120 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 47us/sample - loss: 0.5767 - accuracy: 0.6937 - val_loss: 0.8248 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5739 - accuracy: 0.6939 - val_loss: 0.7915 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5698 - accuracy: 0.6954 - val_loss: 0.7732 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.5613 - accuracy: 0.7101 - val_loss: 0.8214 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5837 - accuracy: 0.6881 - val_loss: 0.8026 - val_accuracy: 0.5895\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5730 - accuracy: 0.6985 - val_loss: 0.7792 - val_accuracy: 0.5804\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.5678 - accuracy: 0.6972 - val_loss: 0.8320 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5746 - accuracy: 0.6949 - val_loss: 0.7977 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5635 - accuracy: 0.7076 - val_loss: 0.8060 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5619 - accuracy: 0.7078 - val_loss: 0.8262 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5676 - accuracy: 0.7071 - val_loss: 0.8053 - val_accuracy: 0.5824\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5699 - accuracy: 0.7010 - val_loss: 0.8214 - val_accuracy: 0.5794\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5686 - accuracy: 0.6990 - val_loss: 0.8046 - val_accuracy: 0.5774\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5658 - accuracy: 0.6980 - val_loss: 0.8477 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5640 - accuracy: 0.7028 - val_loss: 0.7771 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5696 - accuracy: 0.7025 - val_loss: 0.8404 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5667 - accuracy: 0.6992 - val_loss: 0.8091 - val_accuracy: 0.5743\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5678 - accuracy: 0.7015 - val_loss: 0.8070 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5776 - accuracy: 0.6972 - val_loss: 0.8254 - val_accuracy: 0.5804\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5813 - accuracy: 0.6833 - val_loss: 0.8228 - val_accuracy: 0.5743\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5822 - accuracy: 0.6866 - val_loss: 0.8041 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5619 - accuracy: 0.7053 - val_loss: 0.8004 - val_accuracy: 0.5733\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5563 - accuracy: 0.7119 - val_loss: 0.7966 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5568 - accuracy: 0.7093 - val_loss: 0.8411 - val_accuracy: 0.5763\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5697 - accuracy: 0.6964 - val_loss: 0.8147 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5567 - accuracy: 0.7146 - val_loss: 0.8510 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5676 - accuracy: 0.7023 - val_loss: 0.8108 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5591 - accuracy: 0.7073 - val_loss: 0.8020 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5582 - accuracy: 0.7058 - val_loss: 0.8440 - val_accuracy: 0.5753\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5625 - accuracy: 0.7048 - val_loss: 0.8084 - val_accuracy: 0.5895\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5610 - accuracy: 0.7053 - val_loss: 0.8271 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5580 - accuracy: 0.7040 - val_loss: 0.8055 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5576 - accuracy: 0.7159 - val_loss: 0.8080 - val_accuracy: 0.5844\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5649 - accuracy: 0.7010 - val_loss: 0.8135 - val_accuracy: 0.5774\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5604 - accuracy: 0.7103 - val_loss: 0.7782 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5548 - accuracy: 0.7131 - val_loss: 0.8419 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5623 - accuracy: 0.7111 - val_loss: 0.8130 - val_accuracy: 0.5834\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5638 - accuracy: 0.7053 - val_loss: 0.8303 - val_accuracy: 0.5945\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5624 - accuracy: 0.7038 - val_loss: 0.8181 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5697 - accuracy: 0.6972 - val_loss: 0.8230 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5781 - accuracy: 0.6962 - val_loss: 0.8069 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5856 - accuracy: 0.6830 - val_loss: 0.7924 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5655 - accuracy: 0.7017 - val_loss: 0.7867 - val_accuracy: 0.5753\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5566 - accuracy: 0.7136 - val_loss: 0.7841 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5553 - accuracy: 0.7114 - val_loss: 0.8296 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5528 - accuracy: 0.7187 - val_loss: 0.8534 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5610 - accuracy: 0.7040 - val_loss: 0.8095 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5575 - accuracy: 0.7093 - val_loss: 0.8111 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5577 - accuracy: 0.7083 - val_loss: 0.8548 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5565 - accuracy: 0.7045 - val_loss: 0.8132 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5538 - accuracy: 0.7162 - val_loss: 0.8274 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5551 - accuracy: 0.7121 - val_loss: 0.8674 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5617 - accuracy: 0.7063 - val_loss: 0.8512 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5582 - accuracy: 0.7111 - val_loss: 0.8148 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5661 - accuracy: 0.6982 - val_loss: 0.8451 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5692 - accuracy: 0.6992 - val_loss: 0.8166 - val_accuracy: 0.5774\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5584 - accuracy: 0.7076 - val_loss: 0.8315 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5515 - accuracy: 0.7152 - val_loss: 0.8188 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5591 - accuracy: 0.7098 - val_loss: 0.8174 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5598 - accuracy: 0.7078 - val_loss: 0.8071 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5539 - accuracy: 0.7093 - val_loss: 0.8504 - val_accuracy: 0.5824\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5514 - accuracy: 0.7121 - val_loss: 0.8580 - val_accuracy: 0.5774\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5691 - accuracy: 0.6987 - val_loss: 0.8399 - val_accuracy: 0.5784\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5632 - accuracy: 0.7048 - val_loss: 0.7862 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5645 - accuracy: 0.7129 - val_loss: 0.8546 - val_accuracy: 0.5723\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5678 - accuracy: 0.6997 - val_loss: 0.8243 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5616 - accuracy: 0.7066 - val_loss: 0.8080 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5602 - accuracy: 0.7050 - val_loss: 0.8036 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5591 - accuracy: 0.7055 - val_loss: 0.8130 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5527 - accuracy: 0.7134 - val_loss: 0.8169 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5521 - accuracy: 0.7101 - val_loss: 0.8369 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5575 - accuracy: 0.7076 - val_loss: 0.8298 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5569 - accuracy: 0.7098 - val_loss: 0.8240 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5583 - accuracy: 0.7043 - val_loss: 0.8293 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5529 - accuracy: 0.7144 - val_loss: 0.8500 - val_accuracy: 0.5824\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5539 - accuracy: 0.7111 - val_loss: 0.8275 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5563 - accuracy: 0.7116 - val_loss: 0.8341 - val_accuracy: 0.5844\nEpoch 2/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5716 - accuracy: 0.6969 - val_loss: 0.8302 - val_accuracy: 0.5844\nEpoch 3/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5734 - accuracy: 0.6926 - val_loss: 0.8065 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5734 - accuracy: 0.6957 - val_loss: 0.8280 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5554 - accuracy: 0.7121 - val_loss: 0.8004 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5460 - accuracy: 0.7207 - val_loss: 0.8156 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5511 - accuracy: 0.7139 - val_loss: 0.7897 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5540 - accuracy: 0.7152 - val_loss: 0.8427 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5594 - accuracy: 0.7038 - val_loss: 0.8215 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5563 - accuracy: 0.7152 - val_loss: 0.8337 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5549 - accuracy: 0.7119 - val_loss: 0.7957 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5485 - accuracy: 0.7210 - val_loss: 0.8451 - val_accuracy: 0.5763\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5554 - accuracy: 0.7103 - val_loss: 0.8132 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5499 - accuracy: 0.7114 - val_loss: 0.8239 - val_accuracy: 0.5865\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5702 - accuracy: 0.6969 - val_loss: 0.8177 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5595 - accuracy: 0.7106 - val_loss: 0.8398 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5519 - accuracy: 0.7141 - val_loss: 0.8443 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5497 - accuracy: 0.7157 - val_loss: 0.8068 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5522 - accuracy: 0.7124 - val_loss: 0.8341 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5670 - accuracy: 0.6967 - val_loss: 0.8513 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5645 - accuracy: 0.7053 - val_loss: 0.8322 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5647 - accuracy: 0.7010 - val_loss: 0.8064 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5527 - accuracy: 0.7131 - val_loss: 0.8119 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5598 - accuracy: 0.7086 - val_loss: 0.8379 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5622 - accuracy: 0.7053 - val_loss: 0.8416 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5656 - accuracy: 0.7030 - val_loss: 0.7873 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5569 - accuracy: 0.7131 - val_loss: 0.8257 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5613 - accuracy: 0.7040 - val_loss: 0.8438 - val_accuracy: 0.5784\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5555 - accuracy: 0.7096 - val_loss: 0.8045 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5562 - accuracy: 0.7144 - val_loss: 0.8393 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5618 - accuracy: 0.7071 - val_loss: 0.8720 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5665 - accuracy: 0.7091 - val_loss: 0.8388 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5602 - accuracy: 0.7103 - val_loss: 0.8179 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5586 - accuracy: 0.7103 - val_loss: 0.8067 - val_accuracy: 0.5814\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5512 - accuracy: 0.7154 - val_loss: 0.8305 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5477 - accuracy: 0.7281 - val_loss: 0.8087 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5487 - accuracy: 0.7154 - val_loss: 0.8186 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5444 - accuracy: 0.7172 - val_loss: 0.8327 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5428 - accuracy: 0.7202 - val_loss: 0.8425 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5452 - accuracy: 0.7205 - val_loss: 0.8621 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5486 - accuracy: 0.7192 - val_loss: 0.8574 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5529 - accuracy: 0.7083 - val_loss: 0.8288 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5527 - accuracy: 0.7101 - val_loss: 0.8703 - val_accuracy: 0.5774\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5609 - accuracy: 0.7068 - val_loss: 0.8887 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5658 - accuracy: 0.7028 - val_loss: 0.8481 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5475 - accuracy: 0.7263 - val_loss: 0.8575 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5475 - accuracy: 0.7212 - val_loss: 0.8597 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5449 - accuracy: 0.7260 - val_loss: 0.8392 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5451 - accuracy: 0.7212 - val_loss: 0.8262 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5405 - accuracy: 0.7222 - val_loss: 0.8859 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5549 - accuracy: 0.7126 - val_loss: 0.8234 - val_accuracy: 0.5774\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5515 - accuracy: 0.7187 - val_loss: 0.8409 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5603 - accuracy: 0.7060 - val_loss: 0.8400 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5481 - accuracy: 0.7197 - val_loss: 0.8426 - val_accuracy: 0.5713\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5519 - accuracy: 0.7159 - val_loss: 0.8136 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5524 - accuracy: 0.7134 - val_loss: 0.8779 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5724 - accuracy: 0.7144 - val_loss: 0.8880 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5648 - accuracy: 0.7086 - val_loss: 0.8249 - val_accuracy: 0.5804\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5554 - accuracy: 0.7149 - val_loss: 0.8501 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5447 - accuracy: 0.7169 - val_loss: 0.9175 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5558 - accuracy: 0.7101 - val_loss: 0.8804 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5643 - accuracy: 0.7081 - val_loss: 0.8403 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5535 - accuracy: 0.7114 - val_loss: 0.8840 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5737 - accuracy: 0.7103 - val_loss: 0.8673 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5626 - accuracy: 0.7106 - val_loss: 0.8333 - val_accuracy: 0.5794\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5557 - accuracy: 0.7116 - val_loss: 0.8172 - val_accuracy: 0.5784\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5520 - accuracy: 0.7154 - val_loss: 0.8092 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5497 - accuracy: 0.7116 - val_loss: 0.8663 - val_accuracy: 0.5753\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5647 - accuracy: 0.7035 - val_loss: 0.8479 - val_accuracy: 0.5844\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5606 - accuracy: 0.7076 - val_loss: 0.8850 - val_accuracy: 0.5844\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5675 - accuracy: 0.7043 - val_loss: 0.8406 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5498 - accuracy: 0.7162 - val_loss: 0.8091 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5525 - accuracy: 0.7126 - val_loss: 0.8197 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5532 - accuracy: 0.7172 - val_loss: 0.8458 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5420 - accuracy: 0.7238 - val_loss: 0.8444 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5460 - accuracy: 0.7240 - val_loss: 0.8851 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5401 - accuracy: 0.7283 - val_loss: 0.8717 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5364 - accuracy: 0.7275 - val_loss: 0.8599 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5371 - accuracy: 0.7344 - val_loss: 0.9103 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5459 - accuracy: 0.7260 - val_loss: 0.8305 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.5433 - accuracy: 0.7270 - val_loss: 0.8582 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5463 - accuracy: 0.7192 - val_loss: 0.8576 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5459 - accuracy: 0.7207 - val_loss: 0.8874 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5477 - accuracy: 0.7174 - val_loss: 0.8810 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5459 - accuracy: 0.7227 - val_loss: 0.8624 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5452 - accuracy: 0.7227 - val_loss: 0.8812 - val_accuracy: 0.5784\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5581 - accuracy: 0.7152 - val_loss: 0.8734 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5459 - accuracy: 0.7235 - val_loss: 0.8762 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5375 - accuracy: 0.7313 - val_loss: 0.8507 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5585 - accuracy: 0.7131 - val_loss: 0.8563 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5600 - accuracy: 0.7096 - val_loss: 0.8809 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5433 - accuracy: 0.7220 - val_loss: 0.8332 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5459 - accuracy: 0.7217 - val_loss: 0.8747 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5412 - accuracy: 0.7248 - val_loss: 0.8555 - val_accuracy: 0.5844\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5495 - accuracy: 0.7157 - val_loss: 0.8925 - val_accuracy: 0.5794\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5437 - accuracy: 0.7281 - val_loss: 0.8806 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5555 - accuracy: 0.7152 - val_loss: 0.8814 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5518 - accuracy: 0.7159 - val_loss: 0.8549 - val_accuracy: 0.5713\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5522 - accuracy: 0.7260 - val_loss: 0.8224 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5463 - accuracy: 0.7227 - val_loss: 0.8960 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5456 - accuracy: 0.7240 - val_loss: 0.8756 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5433 - accuracy: 0.7212 - val_loss: 0.8707 - val_accuracy: 0.5804\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5455 - accuracy: 0.7258 - val_loss: 0.8569 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5458 - accuracy: 0.7210 - val_loss: 0.8647 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5416 - accuracy: 0.7265 - val_loss: 0.8836 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5476 - accuracy: 0.7162 - val_loss: 0.8149 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5516 - accuracy: 0.7154 - val_loss: 0.8712 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5496 - accuracy: 0.7210 - val_loss: 0.8513 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5737 - accuracy: 0.7020 - val_loss: 0.9070 - val_accuracy: 0.5794\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5553 - accuracy: 0.7152 - val_loss: 0.8760 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5383 - accuracy: 0.7232 - val_loss: 0.8757 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5429 - accuracy: 0.7281 - val_loss: 0.8579 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5402 - accuracy: 0.7281 - val_loss: 0.8709 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5375 - accuracy: 0.7296 - val_loss: 0.8759 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5591 - accuracy: 0.7126 - val_loss: 0.9160 - val_accuracy: 0.5743\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5628 - accuracy: 0.7114 - val_loss: 0.8206 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5496 - accuracy: 0.7184 - val_loss: 0.8475 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5395 - accuracy: 0.7308 - val_loss: 0.8204 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5481 - accuracy: 0.7220 - val_loss: 0.8496 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5483 - accuracy: 0.7164 - val_loss: 0.8385 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5456 - accuracy: 0.7240 - val_loss: 0.8535 - val_accuracy: 0.5733\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5428 - accuracy: 0.7230 - val_loss: 0.8410 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5358 - accuracy: 0.7331 - val_loss: 0.8536 - val_accuracy: 0.5824\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5442 - accuracy: 0.7222 - val_loss: 0.8164 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5372 - accuracy: 0.7316 - val_loss: 0.8286 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5535 - accuracy: 0.7139 - val_loss: 0.8563 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5503 - accuracy: 0.7192 - val_loss: 0.8606 - val_accuracy: 0.5763\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5423 - accuracy: 0.7225 - val_loss: 0.8639 - val_accuracy: 0.5763\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5378 - accuracy: 0.7301 - val_loss: 0.8490 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5464 - accuracy: 0.7245 - val_loss: 0.8416 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5359 - accuracy: 0.7359 - val_loss: 0.8773 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5375 - accuracy: 0.7303 - val_loss: 0.8694 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5361 - accuracy: 0.7311 - val_loss: 0.8725 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5398 - accuracy: 0.7286 - val_loss: 0.8946 - val_accuracy: 0.5865\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5457 - accuracy: 0.7253 - val_loss: 0.8694 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5405 - accuracy: 0.7253 - val_loss: 0.8609 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5396 - accuracy: 0.7293 - val_loss: 0.8788 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5310 - accuracy: 0.7344 - val_loss: 0.8684 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5258 - accuracy: 0.7387 - val_loss: 0.8818 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5431 - accuracy: 0.7245 - val_loss: 0.9113 - val_accuracy: 0.5814\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5468 - accuracy: 0.7238 - val_loss: 0.8910 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5504 - accuracy: 0.7205 - val_loss: 0.8872 - val_accuracy: 0.5733\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5636 - accuracy: 0.7078 - val_loss: 0.8993 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5444 - accuracy: 0.7270 - val_loss: 0.9092 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5426 - accuracy: 0.7268 - val_loss: 0.8518 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5475 - accuracy: 0.7263 - val_loss: 0.8466 - val_accuracy: 0.5784\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5473 - accuracy: 0.7225 - val_loss: 0.8455 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5319 - accuracy: 0.7339 - val_loss: 0.8784 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5300 - accuracy: 0.7367 - val_loss: 0.8945 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5283 - accuracy: 0.7394 - val_loss: 0.9021 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5448 - accuracy: 0.7210 - val_loss: 0.8848 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5462 - accuracy: 0.7200 - val_loss: 0.8682 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5349 - accuracy: 0.7387 - val_loss: 0.8695 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5345 - accuracy: 0.7316 - val_loss: 0.9263 - val_accuracy: 0.5865\nEpoch 5/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5448 - accuracy: 0.7278 - val_loss: 0.8739 - val_accuracy: 0.5743\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.5484 - accuracy: 0.7238 - val_loss: 0.8863 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.5356 - accuracy: 0.7270 - val_loss: 0.8944 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 57us/sample - loss: 0.5332 - accuracy: 0.7356 - val_loss: 0.8763 - val_accuracy: 0.5784\nEpoch 4/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5370 - accuracy: 0.7313 - val_loss: 0.8945 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.5356 - accuracy: 0.7291 - val_loss: 0.9244 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.5433 - accuracy: 0.7212 - val_loss: 0.9127 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5416 - accuracy: 0.7217 - val_loss: 0.9243 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5430 - accuracy: 0.7250 - val_loss: 0.9055 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5420 - accuracy: 0.7169 - val_loss: 0.8748 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5318 - accuracy: 0.7382 - val_loss: 0.9026 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5323 - accuracy: 0.7334 - val_loss: 0.8821 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5368 - accuracy: 0.7283 - val_loss: 0.9019 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5364 - accuracy: 0.7334 - val_loss: 0.9116 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5583 - accuracy: 0.7169 - val_loss: 0.8279 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5505 - accuracy: 0.7232 - val_loss: 0.8602 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5453 - accuracy: 0.7210 - val_loss: 0.8723 - val_accuracy: 0.5824\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5436 - accuracy: 0.7301 - val_loss: 0.8517 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5436 - accuracy: 0.7278 - val_loss: 0.8487 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5369 - accuracy: 0.7296 - val_loss: 0.8686 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5406 - accuracy: 0.7288 - val_loss: 0.9005 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5294 - accuracy: 0.7377 - val_loss: 0.9032 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5346 - accuracy: 0.7293 - val_loss: 0.8775 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5343 - accuracy: 0.7329 - val_loss: 0.8773 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5343 - accuracy: 0.7384 - val_loss: 0.8711 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5411 - accuracy: 0.7273 - val_loss: 0.9214 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5398 - accuracy: 0.7303 - val_loss: 0.8814 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5299 - accuracy: 0.7374 - val_loss: 0.8598 - val_accuracy: 0.5834\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5366 - accuracy: 0.7336 - val_loss: 0.9109 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5324 - accuracy: 0.7389 - val_loss: 0.8689 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5377 - accuracy: 0.7311 - val_loss: 0.9059 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5314 - accuracy: 0.7379 - val_loss: 0.9079 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5352 - accuracy: 0.7331 - val_loss: 0.8699 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5319 - accuracy: 0.7351 - val_loss: 0.8652 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5428 - accuracy: 0.7210 - val_loss: 0.9176 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5351 - accuracy: 0.7308 - val_loss: 0.8868 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5381 - accuracy: 0.7278 - val_loss: 0.8884 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5307 - accuracy: 0.7374 - val_loss: 0.9310 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5277 - accuracy: 0.7397 - val_loss: 0.8537 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5280 - accuracy: 0.7435 - val_loss: 0.9253 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5345 - accuracy: 0.7316 - val_loss: 0.8457 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5372 - accuracy: 0.7329 - val_loss: 0.8987 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5437 - accuracy: 0.7258 - val_loss: 0.9058 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5488 - accuracy: 0.7202 - val_loss: 0.8884 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5364 - accuracy: 0.7281 - val_loss: 0.8306 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5409 - accuracy: 0.7250 - val_loss: 0.8485 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5404 - accuracy: 0.7230 - val_loss: 0.8602 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5541 - accuracy: 0.7129 - val_loss: 0.8418 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5374 - accuracy: 0.7281 - val_loss: 0.8748 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5428 - accuracy: 0.7227 - val_loss: 0.8421 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5368 - accuracy: 0.7278 - val_loss: 0.8510 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5312 - accuracy: 0.7311 - val_loss: 0.8770 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5345 - accuracy: 0.7273 - val_loss: 0.8485 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5357 - accuracy: 0.7275 - val_loss: 0.8068 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5399 - accuracy: 0.7225 - val_loss: 0.8605 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5405 - accuracy: 0.7222 - val_loss: 0.8047 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5402 - accuracy: 0.7273 - val_loss: 0.8795 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5319 - accuracy: 0.7379 - val_loss: 0.8817 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5339 - accuracy: 0.7260 - val_loss: 0.8925 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5324 - accuracy: 0.7339 - val_loss: 0.8843 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5302 - accuracy: 0.7326 - val_loss: 0.8921 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5347 - accuracy: 0.7298 - val_loss: 0.9004 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5248 - accuracy: 0.7367 - val_loss: 0.8699 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5448 - accuracy: 0.7227 - val_loss: 0.8905 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5430 - accuracy: 0.7248 - val_loss: 0.8866 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5381 - accuracy: 0.7281 - val_loss: 0.8908 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5270 - accuracy: 0.7364 - val_loss: 0.9159 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5224 - accuracy: 0.7425 - val_loss: 0.9075 - val_accuracy: 0.5774\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5368 - accuracy: 0.7291 - val_loss: 0.9134 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5420 - accuracy: 0.7215 - val_loss: 0.8822 - val_accuracy: 0.5743\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5551 - accuracy: 0.7126 - val_loss: 0.8577 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5716 - accuracy: 0.6980 - val_loss: 0.8453 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5443 - accuracy: 0.7230 - val_loss: 0.8858 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5300 - accuracy: 0.7321 - val_loss: 0.8802 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5369 - accuracy: 0.7278 - val_loss: 0.8659 - val_accuracy: 0.5814\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5315 - accuracy: 0.7308 - val_loss: 0.8809 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5331 - accuracy: 0.7301 - val_loss: 0.8881 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5305 - accuracy: 0.7270 - val_loss: 0.8964 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5283 - accuracy: 0.7344 - val_loss: 0.9176 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5263 - accuracy: 0.7367 - val_loss: 0.8935 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5369 - accuracy: 0.7260 - val_loss: 0.8507 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.5311 - accuracy: 0.7324 - val_loss: 0.9331 - val_accuracy: 0.5844\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.5220 - accuracy: 0.7432 - val_loss: 0.8999 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5373 - accuracy: 0.7296 - val_loss: 0.9160 - val_accuracy: 0.5753\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5480 - accuracy: 0.7172 - val_loss: 0.9392 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5314 - accuracy: 0.7275 - val_loss: 0.8832 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5260 - accuracy: 0.7329 - val_loss: 0.9131 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5310 - accuracy: 0.7334 - val_loss: 0.8851 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5392 - accuracy: 0.7222 - val_loss: 0.8737 - val_accuracy: 0.5713\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5375 - accuracy: 0.7250 - val_loss: 0.8536 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5400 - accuracy: 0.7210 - val_loss: 0.8896 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5435 - accuracy: 0.7205 - val_loss: 0.8593 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5284 - accuracy: 0.7324 - val_loss: 0.8701 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5324 - accuracy: 0.7346 - val_loss: 0.9097 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5400 - accuracy: 0.7200 - val_loss: 0.9124 - val_accuracy: 0.5844\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5283 - accuracy: 0.7415 - val_loss: 0.8514 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5234 - accuracy: 0.7430 - val_loss: 0.8712 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5266 - accuracy: 0.7356 - val_loss: 0.8666 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5230 - accuracy: 0.7369 - val_loss: 0.8788 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5333 - accuracy: 0.7200 - val_loss: 0.8851 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5373 - accuracy: 0.7286 - val_loss: 0.9053 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5277 - accuracy: 0.7354 - val_loss: 0.9052 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5236 - accuracy: 0.7420 - val_loss: 0.9290 - val_accuracy: 0.5794\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5246 - accuracy: 0.7389 - val_loss: 0.8867 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5333 - accuracy: 0.7303 - val_loss: 0.9312 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5260 - accuracy: 0.7356 - val_loss: 0.9459 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5246 - accuracy: 0.7321 - val_loss: 0.9320 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5211 - accuracy: 0.7349 - val_loss: 0.9003 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5246 - accuracy: 0.7351 - val_loss: 0.9099 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5351 - accuracy: 0.7301 - val_loss: 0.9035 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5301 - accuracy: 0.7349 - val_loss: 0.9069 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5417 - accuracy: 0.7265 - val_loss: 0.9091 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5389 - accuracy: 0.7275 - val_loss: 0.9233 - val_accuracy: 0.5763\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5547 - accuracy: 0.7152 - val_loss: 0.9291 - val_accuracy: 0.5703\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5516 - accuracy: 0.7177 - val_loss: 0.8891 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5488 - accuracy: 0.7189 - val_loss: 0.8917 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5348 - accuracy: 0.7268 - val_loss: 0.8959 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5215 - accuracy: 0.7405 - val_loss: 0.8668 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5193 - accuracy: 0.7374 - val_loss: 0.9033 - val_accuracy: 0.5895\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5215 - accuracy: 0.7425 - val_loss: 0.8822 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5189 - accuracy: 0.7407 - val_loss: 0.9269 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5265 - accuracy: 0.7364 - val_loss: 0.8702 - val_accuracy: 0.5804\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5392 - accuracy: 0.7258 - val_loss: 0.8655 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5342 - accuracy: 0.7303 - val_loss: 0.9029 - val_accuracy: 0.5662\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5308 - accuracy: 0.7308 - val_loss: 0.8963 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5180 - accuracy: 0.7415 - val_loss: 0.8692 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5400 - accuracy: 0.7235 - val_loss: 0.8931 - val_accuracy: 0.5854\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5290 - accuracy: 0.7341 - val_loss: 0.9223 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5270 - accuracy: 0.7329 - val_loss: 0.8713 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5182 - accuracy: 0.7407 - val_loss: 0.8458 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5119 - accuracy: 0.7468 - val_loss: 0.9036 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5137 - accuracy: 0.7485 - val_loss: 0.8897 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5169 - accuracy: 0.7399 - val_loss: 0.9282 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5273 - accuracy: 0.7311 - val_loss: 0.9207 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5324 - accuracy: 0.7281 - val_loss: 0.8475 - val_accuracy: 0.5865\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5515 - accuracy: 0.7134 - val_loss: 0.8823 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5394 - accuracy: 0.7222 - val_loss: 0.8764 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5277 - accuracy: 0.7311 - val_loss: 0.8877 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5176 - accuracy: 0.7435 - val_loss: 0.8898 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5128 - accuracy: 0.7442 - val_loss: 0.8953 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5196 - accuracy: 0.7394 - val_loss: 0.8729 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5211 - accuracy: 0.7351 - val_loss: 0.8770 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5318 - accuracy: 0.7293 - val_loss: 0.8961 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5300 - accuracy: 0.7384 - val_loss: 0.9312 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5228 - accuracy: 0.7341 - val_loss: 0.9306 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5337 - accuracy: 0.7265 - val_loss: 0.9361 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5180 - accuracy: 0.7453 - val_loss: 0.8951 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5213 - accuracy: 0.7387 - val_loss: 0.9424 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5195 - accuracy: 0.7367 - val_loss: 0.9381 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5210 - accuracy: 0.7399 - val_loss: 0.8830 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5155 - accuracy: 0.7407 - val_loss: 0.8800 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5269 - accuracy: 0.7402 - val_loss: 0.9462 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5322 - accuracy: 0.7311 - val_loss: 0.8962 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5216 - accuracy: 0.7405 - val_loss: 0.8971 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5129 - accuracy: 0.7475 - val_loss: 0.9127 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5139 - accuracy: 0.7455 - val_loss: 0.9036 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5163 - accuracy: 0.7458 - val_loss: 0.9446 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5275 - accuracy: 0.7344 - val_loss: 0.8969 - val_accuracy: 0.5834\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5234 - accuracy: 0.7356 - val_loss: 0.8880 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5263 - accuracy: 0.7341 - val_loss: 0.9045 - val_accuracy: 0.5895\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5230 - accuracy: 0.7339 - val_loss: 0.8606 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5315 - accuracy: 0.7341 - val_loss: 0.9083 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5251 - accuracy: 0.7405 - val_loss: 0.9078 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5207 - accuracy: 0.7364 - val_loss: 0.9372 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5228 - accuracy: 0.7377 - val_loss: 0.8863 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5182 - accuracy: 0.7430 - val_loss: 0.9304 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5215 - accuracy: 0.7389 - val_loss: 0.8922 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5292 - accuracy: 0.7318 - val_loss: 0.9277 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5328 - accuracy: 0.7283 - val_loss: 0.9301 - val_accuracy: 0.5824\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5397 - accuracy: 0.7238 - val_loss: 0.8893 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5228 - accuracy: 0.7382 - val_loss: 0.9092 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5250 - accuracy: 0.7367 - val_loss: 0.9002 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5165 - accuracy: 0.7458 - val_loss: 0.9172 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5162 - accuracy: 0.7425 - val_loss: 0.9433 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5214 - accuracy: 0.7415 - val_loss: 0.9154 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5137 - accuracy: 0.7493 - val_loss: 0.9171 - val_accuracy: 0.5774\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5185 - accuracy: 0.7392 - val_loss: 0.8913 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5190 - accuracy: 0.7420 - val_loss: 0.8986 - val_accuracy: 0.5945\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5227 - accuracy: 0.7407 - val_loss: 0.9131 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5203 - accuracy: 0.7359 - val_loss: 0.9016 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5190 - accuracy: 0.7397 - val_loss: 0.9119 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5181 - accuracy: 0.7460 - val_loss: 0.8939 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5260 - accuracy: 0.7382 - val_loss: 0.9260 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5268 - accuracy: 0.7278 - val_loss: 0.9295 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5196 - accuracy: 0.7394 - val_loss: 0.9061 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5157 - accuracy: 0.7437 - val_loss: 0.9436 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5129 - accuracy: 0.7455 - val_loss: 0.9122 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5229 - accuracy: 0.7417 - val_loss: 0.9564 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.5306 - accuracy: 0.7367 - val_loss: 0.9451 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5335 - accuracy: 0.7258 - val_loss: 0.9258 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5296 - accuracy: 0.7318 - val_loss: 0.9373 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5330 - accuracy: 0.7308 - val_loss: 0.8755 - val_accuracy: 0.5774\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5230 - accuracy: 0.7351 - val_loss: 0.8926 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5181 - accuracy: 0.7389 - val_loss: 0.9306 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5173 - accuracy: 0.7405 - val_loss: 0.8956 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5245 - accuracy: 0.7374 - val_loss: 0.8908 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5321 - accuracy: 0.7367 - val_loss: 0.8983 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5625 - accuracy: 0.7202 - val_loss: 0.8637 - val_accuracy: 0.5713\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5540 - accuracy: 0.7093 - val_loss: 0.8601 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5475 - accuracy: 0.7207 - val_loss: 0.8452 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5145 - accuracy: 0.7463 - val_loss: 0.8539 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5174 - accuracy: 0.7430 - val_loss: 0.9040 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5220 - accuracy: 0.7402 - val_loss: 0.8908 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5204 - accuracy: 0.7382 - val_loss: 0.8872 - val_accuracy: 0.5875\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5083 - accuracy: 0.7488 - val_loss: 0.9301 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5156 - accuracy: 0.7448 - val_loss: 0.9259 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5117 - accuracy: 0.7437 - val_loss: 0.9489 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5165 - accuracy: 0.7422 - val_loss: 0.9045 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5113 - accuracy: 0.7442 - val_loss: 0.8806 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5137 - accuracy: 0.7397 - val_loss: 0.9136 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5151 - accuracy: 0.7458 - val_loss: 0.9222 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5138 - accuracy: 0.7460 - val_loss: 0.8681 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5156 - accuracy: 0.7367 - val_loss: 0.9184 - val_accuracy: 0.5834\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5129 - accuracy: 0.7485 - val_loss: 0.9074 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5208 - accuracy: 0.7387 - val_loss: 0.9899 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5173 - accuracy: 0.7387 - val_loss: 0.9107 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5278 - accuracy: 0.7336 - val_loss: 0.8960 - val_accuracy: 0.5672\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5220 - accuracy: 0.7394 - val_loss: 0.8880 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5112 - accuracy: 0.7458 - val_loss: 0.9233 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5258 - accuracy: 0.7399 - val_loss: 0.8945 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5174 - accuracy: 0.7392 - val_loss: 0.9449 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5149 - accuracy: 0.7460 - val_loss: 0.9615 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5085 - accuracy: 0.7518 - val_loss: 0.8817 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5133 - accuracy: 0.7432 - val_loss: 0.9612 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5158 - accuracy: 0.7437 - val_loss: 0.9489 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5214 - accuracy: 0.7374 - val_loss: 0.9299 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5221 - accuracy: 0.7324 - val_loss: 0.9763 - val_accuracy: 0.5592\nEpoch 2/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.5350 - accuracy: 0.7270 - val_loss: 0.9017 - val_accuracy: 0.5733\nEpoch 3/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5320 - accuracy: 0.7278 - val_loss: 0.8545 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5205 - accuracy: 0.7361 - val_loss: 0.8657 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5117 - accuracy: 0.7470 - val_loss: 0.9185 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5185 - accuracy: 0.7382 - val_loss: 0.9233 - val_accuracy: 0.5824\nEpoch 2/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.5119 - accuracy: 0.7445 - val_loss: 0.9260 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5155 - accuracy: 0.7460 - val_loss: 0.9302 - val_accuracy: 0.5824\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5124 - accuracy: 0.7458 - val_loss: 0.9105 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5227 - accuracy: 0.7331 - val_loss: 0.9390 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5194 - accuracy: 0.7407 - val_loss: 0.9111 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5134 - accuracy: 0.7468 - val_loss: 0.9318 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5102 - accuracy: 0.7460 - val_loss: 0.8928 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5107 - accuracy: 0.7485 - val_loss: 0.9101 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5143 - accuracy: 0.7422 - val_loss: 0.9266 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5057 - accuracy: 0.7465 - val_loss: 0.8885 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5084 - accuracy: 0.7485 - val_loss: 0.9127 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5102 - accuracy: 0.7498 - val_loss: 0.9190 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5178 - accuracy: 0.7387 - val_loss: 0.9789 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5196 - accuracy: 0.7392 - val_loss: 0.9578 - val_accuracy: 0.5834\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5298 - accuracy: 0.7339 - val_loss: 0.9357 - val_accuracy: 0.5834\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5321 - accuracy: 0.7361 - val_loss: 0.9267 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5184 - accuracy: 0.7392 - val_loss: 0.8759 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5154 - accuracy: 0.7364 - val_loss: 0.9082 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5120 - accuracy: 0.7458 - val_loss: 0.9230 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5160 - accuracy: 0.7407 - val_loss: 0.9313 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5201 - accuracy: 0.7410 - val_loss: 0.9223 - val_accuracy: 0.5865\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5233 - accuracy: 0.7407 - val_loss: 0.9076 - val_accuracy: 0.5895\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5239 - accuracy: 0.7349 - val_loss: 0.9121 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5200 - accuracy: 0.7364 - val_loss: 0.9249 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5166 - accuracy: 0.7389 - val_loss: 0.9008 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5124 - accuracy: 0.7407 - val_loss: 0.9059 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5058 - accuracy: 0.7511 - val_loss: 0.9005 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5105 - accuracy: 0.7498 - val_loss: 0.8808 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5057 - accuracy: 0.7493 - val_loss: 0.9342 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5206 - accuracy: 0.7374 - val_loss: 0.8893 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5091 - accuracy: 0.7435 - val_loss: 0.8792 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5064 - accuracy: 0.7506 - val_loss: 0.9076 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5207 - accuracy: 0.7389 - val_loss: 0.9453 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5139 - accuracy: 0.7450 - val_loss: 0.9323 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5107 - accuracy: 0.7501 - val_loss: 0.9854 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5092 - accuracy: 0.7455 - val_loss: 0.9450 - val_accuracy: 0.5844\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5072 - accuracy: 0.7493 - val_loss: 0.8822 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5172 - accuracy: 0.7407 - val_loss: 0.9633 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5175 - accuracy: 0.7405 - val_loss: 0.9238 - val_accuracy: 0.5794\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5436 - accuracy: 0.7275 - val_loss: 0.8559 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5274 - accuracy: 0.7382 - val_loss: 0.9088 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5083 - accuracy: 0.7491 - val_loss: 0.9559 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5058 - accuracy: 0.7501 - val_loss: 0.9373 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5015 - accuracy: 0.7589 - val_loss: 0.9061 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5127 - accuracy: 0.7483 - val_loss: 0.9356 - val_accuracy: 0.5794\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5197 - accuracy: 0.7379 - val_loss: 0.9240 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5153 - accuracy: 0.7450 - val_loss: 0.9276 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5101 - accuracy: 0.7463 - val_loss: 0.9377 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5066 - accuracy: 0.7528 - val_loss: 0.9069 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5052 - accuracy: 0.7483 - val_loss: 0.9420 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5074 - accuracy: 0.7521 - val_loss: 0.8891 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5123 - accuracy: 0.7473 - val_loss: 0.9487 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5032 - accuracy: 0.7508 - val_loss: 0.8988 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5095 - accuracy: 0.7503 - val_loss: 0.9249 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5110 - accuracy: 0.7455 - val_loss: 0.9337 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5197 - accuracy: 0.7422 - val_loss: 0.9140 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5272 - accuracy: 0.7359 - val_loss: 0.9254 - val_accuracy: 0.5794\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5253 - accuracy: 0.7359 - val_loss: 0.9203 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5185 - accuracy: 0.7432 - val_loss: 0.8739 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5319 - accuracy: 0.7270 - val_loss: 0.8816 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5156 - accuracy: 0.7455 - val_loss: 0.9417 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5021 - accuracy: 0.7551 - val_loss: 0.9109 - val_accuracy: 0.5844\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5192 - accuracy: 0.7420 - val_loss: 0.8922 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5211 - accuracy: 0.7374 - val_loss: 0.9429 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5261 - accuracy: 0.7374 - val_loss: 0.9618 - val_accuracy: 0.5804\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5108 - accuracy: 0.7503 - val_loss: 0.8968 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5223 - accuracy: 0.7372 - val_loss: 0.8966 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5210 - accuracy: 0.7389 - val_loss: 0.8914 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5137 - accuracy: 0.7430 - val_loss: 0.9338 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5076 - accuracy: 0.7491 - val_loss: 0.8840 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5136 - accuracy: 0.7455 - val_loss: 0.9434 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5371 - accuracy: 0.7326 - val_loss: 0.9585 - val_accuracy: 0.5784\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5151 - accuracy: 0.7425 - val_loss: 0.9486 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5143 - accuracy: 0.7440 - val_loss: 0.9338 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5150 - accuracy: 0.7475 - val_loss: 0.9679 - val_accuracy: 0.5753\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5181 - accuracy: 0.7397 - val_loss: 0.9664 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5126 - accuracy: 0.7432 - val_loss: 0.9056 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5069 - accuracy: 0.7496 - val_loss: 0.9430 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5034 - accuracy: 0.7513 - val_loss: 0.9214 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4986 - accuracy: 0.7511 - val_loss: 0.9270 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5010 - accuracy: 0.7536 - val_loss: 0.9482 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5145 - accuracy: 0.7483 - val_loss: 0.9283 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5094 - accuracy: 0.7455 - val_loss: 0.9181 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4983 - accuracy: 0.7539 - val_loss: 0.9304 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5020 - accuracy: 0.7536 - val_loss: 0.9555 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5372 - accuracy: 0.7301 - val_loss: 0.9953 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.5289 - accuracy: 0.7369 - val_loss: 0.9068 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.9651 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5130 - accuracy: 0.7453 - val_loss: 0.9440 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5088 - accuracy: 0.7437 - val_loss: 0.9099 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5132 - accuracy: 0.7455 - val_loss: 0.9830 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5148 - accuracy: 0.7415 - val_loss: 0.9402 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5077 - accuracy: 0.7483 - val_loss: 0.9411 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5091 - accuracy: 0.7480 - val_loss: 0.9395 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5034 - accuracy: 0.7544 - val_loss: 0.9523 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5057 - accuracy: 0.7516 - val_loss: 0.9086 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5161 - accuracy: 0.7389 - val_loss: 0.9575 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5159 - accuracy: 0.7432 - val_loss: 0.9463 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5198 - accuracy: 0.7374 - val_loss: 0.9427 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5126 - accuracy: 0.7412 - val_loss: 0.9950 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5219 - accuracy: 0.7435 - val_loss: 0.9021 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5082 - accuracy: 0.7536 - val_loss: 0.9582 - val_accuracy: 0.5834\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5121 - accuracy: 0.7448 - val_loss: 0.9362 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5153 - accuracy: 0.7417 - val_loss: 0.9760 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5135 - accuracy: 0.7485 - val_loss: 0.9734 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5224 - accuracy: 0.7359 - val_loss: 0.9175 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5220 - accuracy: 0.7354 - val_loss: 0.8800 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5118 - accuracy: 0.7541 - val_loss: 0.9790 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5031 - accuracy: 0.7582 - val_loss: 0.9214 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5060 - accuracy: 0.7526 - val_loss: 0.9293 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5010 - accuracy: 0.7544 - val_loss: 0.9317 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5070 - accuracy: 0.7518 - val_loss: 0.9318 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5095 - accuracy: 0.7503 - val_loss: 0.9215 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5040 - accuracy: 0.7574 - val_loss: 0.9372 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5001 - accuracy: 0.7526 - val_loss: 0.9471 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5034 - accuracy: 0.7501 - val_loss: 0.9445 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5045 - accuracy: 0.7549 - val_loss: 0.8977 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5045 - accuracy: 0.7518 - val_loss: 1.0003 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5047 - accuracy: 0.7546 - val_loss: 0.9781 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5098 - accuracy: 0.7407 - val_loss: 0.9770 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5139 - accuracy: 0.7448 - val_loss: 0.9082 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5087 - accuracy: 0.7508 - val_loss: 0.9125 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5006 - accuracy: 0.7574 - val_loss: 0.9318 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5024 - accuracy: 0.7521 - val_loss: 0.9542 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5021 - accuracy: 0.7508 - val_loss: 0.9276 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4955 - accuracy: 0.7594 - val_loss: 0.9841 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5061 - accuracy: 0.7501 - val_loss: 0.9687 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5149 - accuracy: 0.7468 - val_loss: 1.0173 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5170 - accuracy: 0.7402 - val_loss: 0.9473 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5051 - accuracy: 0.7531 - val_loss: 0.9952 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5146 - accuracy: 0.7440 - val_loss: 0.9649 - val_accuracy: 0.5875\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5170 - accuracy: 0.7430 - val_loss: 0.9154 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5073 - accuracy: 0.7455 - val_loss: 0.9438 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5114 - accuracy: 0.7455 - val_loss: 0.9745 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5043 - accuracy: 0.7544 - val_loss: 0.9526 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5150 - accuracy: 0.7427 - val_loss: 0.9559 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5019 - accuracy: 0.7541 - val_loss: 0.9766 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4964 - accuracy: 0.7544 - val_loss: 0.9282 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4969 - accuracy: 0.7577 - val_loss: 0.9059 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5140 - accuracy: 0.7437 - val_loss: 0.9319 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5320 - accuracy: 0.7344 - val_loss: 0.8783 - val_accuracy: 0.5713\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5173 - accuracy: 0.7399 - val_loss: 0.9001 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5105 - accuracy: 0.7455 - val_loss: 0.9370 - val_accuracy: 0.5895\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5053 - accuracy: 0.7546 - val_loss: 0.9726 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4958 - accuracy: 0.7554 - val_loss: 1.0152 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5175 - accuracy: 0.7415 - val_loss: 0.9946 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5141 - accuracy: 0.7498 - val_loss: 0.9447 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5112 - accuracy: 0.7473 - val_loss: 0.9130 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5042 - accuracy: 0.7503 - val_loss: 0.9330 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5112 - accuracy: 0.7372 - val_loss: 0.8833 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5126 - accuracy: 0.7440 - val_loss: 0.9491 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5008 - accuracy: 0.7523 - val_loss: 0.8942 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5029 - accuracy: 0.7516 - val_loss: 0.9230 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5060 - accuracy: 0.7516 - val_loss: 0.9484 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5176 - accuracy: 0.7420 - val_loss: 0.9315 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5133 - accuracy: 0.7442 - val_loss: 0.9426 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5083 - accuracy: 0.7465 - val_loss: 0.9111 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.5001 - accuracy: 0.7564 - val_loss: 0.9192 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4958 - accuracy: 0.7582 - val_loss: 0.9185 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4963 - accuracy: 0.7579 - val_loss: 0.9118 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5011 - accuracy: 0.7528 - val_loss: 0.9639 - val_accuracy: 0.5824\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4988 - accuracy: 0.7559 - val_loss: 0.9641 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4987 - accuracy: 0.7587 - val_loss: 0.9413 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5144 - accuracy: 0.7422 - val_loss: 0.9264 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4993 - accuracy: 0.7511 - val_loss: 0.9350 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4981 - accuracy: 0.7531 - val_loss: 0.9159 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5038 - accuracy: 0.7539 - val_loss: 0.9642 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5013 - accuracy: 0.7571 - val_loss: 0.9445 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4944 - accuracy: 0.7620 - val_loss: 0.9164 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4978 - accuracy: 0.7584 - val_loss: 0.9311 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5106 - accuracy: 0.7516 - val_loss: 0.8934 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5078 - accuracy: 0.7470 - val_loss: 0.9888 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4995 - accuracy: 0.7587 - val_loss: 0.9043 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5007 - accuracy: 0.7483 - val_loss: 0.9741 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5015 - accuracy: 0.7541 - val_loss: 0.9317 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5056 - accuracy: 0.7478 - val_loss: 0.9504 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4995 - accuracy: 0.7564 - val_loss: 0.9789 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5053 - accuracy: 0.7478 - val_loss: 0.9616 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5025 - accuracy: 0.7561 - val_loss: 0.9066 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5058 - accuracy: 0.7485 - val_loss: 0.9179 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5128 - accuracy: 0.7498 - val_loss: 0.9577 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5015 - accuracy: 0.7607 - val_loss: 0.9500 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4932 - accuracy: 0.7556 - val_loss: 0.9911 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5017 - accuracy: 0.7506 - val_loss: 0.9802 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4992 - accuracy: 0.7584 - val_loss: 0.9308 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4966 - accuracy: 0.7582 - val_loss: 0.9758 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4929 - accuracy: 0.7571 - val_loss: 0.9291 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4979 - accuracy: 0.7569 - val_loss: 0.9063 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5022 - accuracy: 0.7511 - val_loss: 1.0363 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5332 - accuracy: 0.7308 - val_loss: 0.9264 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5291 - accuracy: 0.7356 - val_loss: 0.8874 - val_accuracy: 0.5834\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5176 - accuracy: 0.7420 - val_loss: 0.9290 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4986 - accuracy: 0.7571 - val_loss: 0.9502 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4966 - accuracy: 0.7579 - val_loss: 0.9189 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4948 - accuracy: 0.7604 - val_loss: 0.9843 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5077 - accuracy: 0.7526 - val_loss: 0.9749 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5114 - accuracy: 0.7442 - val_loss: 0.8974 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5096 - accuracy: 0.7478 - val_loss: 0.9175 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4972 - accuracy: 0.7551 - val_loss: 0.9407 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4939 - accuracy: 0.7579 - val_loss: 0.9479 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4981 - accuracy: 0.7602 - val_loss: 0.9192 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5012 - accuracy: 0.7554 - val_loss: 0.9483 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5114 - accuracy: 0.7463 - val_loss: 0.9441 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5277 - accuracy: 0.7513 - val_loss: 1.0227 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5199 - accuracy: 0.7534 - val_loss: 0.9582 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5088 - accuracy: 0.7498 - val_loss: 0.9362 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4987 - accuracy: 0.7539 - val_loss: 0.9720 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4966 - accuracy: 0.7614 - val_loss: 0.9616 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4984 - accuracy: 0.7556 - val_loss: 0.9261 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4996 - accuracy: 0.7541 - val_loss: 0.9422 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4973 - accuracy: 0.7574 - val_loss: 0.9504 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4878 - accuracy: 0.7657 - val_loss: 0.9347 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4949 - accuracy: 0.7554 - val_loss: 0.9796 - val_accuracy: 0.5774\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5182 - accuracy: 0.7399 - val_loss: 0.9963 - val_accuracy: 0.5824\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5447 - accuracy: 0.7258 - val_loss: 0.9650 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5199 - accuracy: 0.7369 - val_loss: 0.9358 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.9069 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5014 - accuracy: 0.7531 - val_loss: 0.9707 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4980 - accuracy: 0.7518 - val_loss: 1.0214 - val_accuracy: 0.5784\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5097 - accuracy: 0.7516 - val_loss: 0.9525 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5059 - accuracy: 0.7579 - val_loss: 0.9220 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5019 - accuracy: 0.7571 - val_loss: 0.9934 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5018 - accuracy: 0.7518 - val_loss: 0.9320 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5054 - accuracy: 0.7485 - val_loss: 1.0627 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5032 - accuracy: 0.7511 - val_loss: 0.9652 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 46us/sample - loss: 0.4948 - accuracy: 0.7635 - val_loss: 0.9789 - val_accuracy: 0.5945\nEpoch 3/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4919 - accuracy: 0.7612 - val_loss: 1.0221 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.5145 - accuracy: 0.7430 - val_loss: 1.0136 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5405 - accuracy: 0.7265 - val_loss: 0.9250 - val_accuracy: 0.5763\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5283 - accuracy: 0.7367 - val_loss: 0.9165 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.5046 - accuracy: 0.7554 - val_loss: 0.9462 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4937 - accuracy: 0.7668 - val_loss: 1.0064 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4870 - accuracy: 0.7647 - val_loss: 1.0107 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4857 - accuracy: 0.7683 - val_loss: 0.9810 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4961 - accuracy: 0.7546 - val_loss: 0.9906 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4947 - accuracy: 0.7607 - val_loss: 0.9157 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5040 - accuracy: 0.7518 - val_loss: 0.9965 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4944 - accuracy: 0.7620 - val_loss: 0.9611 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5019 - accuracy: 0.7584 - val_loss: 1.0066 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5085 - accuracy: 0.7475 - val_loss: 0.9499 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4951 - accuracy: 0.7571 - val_loss: 0.9893 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4921 - accuracy: 0.7589 - val_loss: 1.0061 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.5005 - accuracy: 0.7604 - val_loss: 0.9506 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.5058 - accuracy: 0.7513 - val_loss: 0.9699 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4992 - accuracy: 0.7584 - val_loss: 0.9844 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5298 - accuracy: 0.7331 - val_loss: 0.9390 - val_accuracy: 0.5723\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5134 - accuracy: 0.7420 - val_loss: 0.9285 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4956 - accuracy: 0.7577 - val_loss: 0.9469 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5008 - accuracy: 0.7508 - val_loss: 0.9905 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4962 - accuracy: 0.7551 - val_loss: 0.9853 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4997 - accuracy: 0.7521 - val_loss: 0.9792 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4995 - accuracy: 0.7554 - val_loss: 0.9779 - val_accuracy: 0.5885\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4916 - accuracy: 0.7597 - val_loss: 1.0029 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4969 - accuracy: 0.7556 - val_loss: 0.9830 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4933 - accuracy: 0.7594 - val_loss: 0.9653 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5040 - accuracy: 0.7478 - val_loss: 0.9514 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5038 - accuracy: 0.7569 - val_loss: 0.9111 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5054 - accuracy: 0.7528 - val_loss: 0.9165 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5012 - accuracy: 0.7546 - val_loss: 0.9749 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4963 - accuracy: 0.7597 - val_loss: 0.9311 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4944 - accuracy: 0.7569 - val_loss: 0.9289 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4964 - accuracy: 0.7592 - val_loss: 0.9116 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4946 - accuracy: 0.7554 - val_loss: 0.9213 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4872 - accuracy: 0.7642 - val_loss: 0.9296 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4814 - accuracy: 0.7685 - val_loss: 0.9697 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4909 - accuracy: 0.7617 - val_loss: 0.9612 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4930 - accuracy: 0.7630 - val_loss: 0.9293 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5085 - accuracy: 0.7453 - val_loss: 0.9613 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5360 - accuracy: 0.7301 - val_loss: 0.9275 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5309 - accuracy: 0.7394 - val_loss: 0.9477 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5019 - accuracy: 0.7551 - val_loss: 0.9721 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4894 - accuracy: 0.7637 - val_loss: 0.9479 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4832 - accuracy: 0.7680 - val_loss: 0.9487 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4809 - accuracy: 0.7685 - val_loss: 0.9637 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4915 - accuracy: 0.7602 - val_loss: 0.9698 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4861 - accuracy: 0.7688 - val_loss: 0.9411 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4877 - accuracy: 0.7617 - val_loss: 0.9552 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4866 - accuracy: 0.7617 - val_loss: 0.9575 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4936 - accuracy: 0.7564 - val_loss: 0.9841 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5099 - accuracy: 0.7473 - val_loss: 0.9404 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4975 - accuracy: 0.7614 - val_loss: 0.9747 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4929 - accuracy: 0.7642 - val_loss: 0.9370 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4853 - accuracy: 0.7660 - val_loss: 0.9865 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4973 - accuracy: 0.7516 - val_loss: 0.9277 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5096 - accuracy: 0.7465 - val_loss: 0.9611 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4985 - accuracy: 0.7551 - val_loss: 0.9529 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4916 - accuracy: 0.7625 - val_loss: 0.9292 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4896 - accuracy: 0.7655 - val_loss: 1.0298 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5010 - accuracy: 0.7516 - val_loss: 0.9974 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4935 - accuracy: 0.7589 - val_loss: 0.9743 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5022 - accuracy: 0.7536 - val_loss: 0.9486 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4981 - accuracy: 0.7589 - val_loss: 0.9215 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5028 - accuracy: 0.7491 - val_loss: 0.9387 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4939 - accuracy: 0.7592 - val_loss: 0.9452 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4974 - accuracy: 0.7566 - val_loss: 0.9317 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4933 - accuracy: 0.7582 - val_loss: 0.9702 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4971 - accuracy: 0.7592 - val_loss: 0.9647 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4954 - accuracy: 0.7650 - val_loss: 0.9362 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4922 - accuracy: 0.7569 - val_loss: 0.9670 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5014 - accuracy: 0.7554 - val_loss: 0.9866 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5080 - accuracy: 0.7491 - val_loss: 0.9681 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4945 - accuracy: 0.7577 - val_loss: 0.9606 - val_accuracy: 0.6249\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4837 - accuracy: 0.7660 - val_loss: 0.9689 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4922 - accuracy: 0.7614 - val_loss: 0.9287 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4953 - accuracy: 0.7589 - val_loss: 0.9454 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5008 - accuracy: 0.7531 - val_loss: 0.9293 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5007 - accuracy: 0.7539 - val_loss: 1.0082 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5072 - accuracy: 0.7491 - val_loss: 1.0228 - val_accuracy: 0.5925\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4970 - accuracy: 0.7579 - val_loss: 0.9613 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4848 - accuracy: 0.7617 - val_loss: 0.9725 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4860 - accuracy: 0.7675 - val_loss: 1.0698 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5035 - accuracy: 0.7488 - val_loss: 0.9480 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4967 - accuracy: 0.7584 - val_loss: 0.9940 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4933 - accuracy: 0.7587 - val_loss: 0.9758 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4896 - accuracy: 0.7622 - val_loss: 0.9542 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4896 - accuracy: 0.7614 - val_loss: 1.0127 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4916 - accuracy: 0.7587 - val_loss: 1.0047 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4840 - accuracy: 0.7645 - val_loss: 0.9635 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4825 - accuracy: 0.7657 - val_loss: 0.9314 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4854 - accuracy: 0.7617 - val_loss: 1.0291 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4917 - accuracy: 0.7617 - val_loss: 1.0071 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4916 - accuracy: 0.7637 - val_loss: 0.9859 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4835 - accuracy: 0.7683 - val_loss: 1.0337 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4930 - accuracy: 0.7614 - val_loss: 0.9501 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4868 - accuracy: 0.7675 - val_loss: 0.9756 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4808 - accuracy: 0.7645 - val_loss: 1.0621 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4853 - accuracy: 0.7635 - val_loss: 0.9793 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4873 - accuracy: 0.7650 - val_loss: 1.0216 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4856 - accuracy: 0.7650 - val_loss: 1.0154 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4891 - accuracy: 0.7620 - val_loss: 1.0231 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4834 - accuracy: 0.7673 - val_loss: 1.0587 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4829 - accuracy: 0.7695 - val_loss: 1.0232 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4740 - accuracy: 0.7731 - val_loss: 1.0266 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4802 - accuracy: 0.7652 - val_loss: 0.9814 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4733 - accuracy: 0.7713 - val_loss: 1.0258 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4863 - accuracy: 0.7640 - val_loss: 0.9580 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4889 - accuracy: 0.7650 - val_loss: 1.0263 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4938 - accuracy: 0.7564 - val_loss: 0.9472 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4971 - accuracy: 0.7577 - val_loss: 1.0087 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4996 - accuracy: 0.7488 - val_loss: 1.0615 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4939 - accuracy: 0.7574 - val_loss: 1.0100 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5091 - accuracy: 0.7468 - val_loss: 0.9939 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5061 - accuracy: 0.7493 - val_loss: 0.9485 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5052 - accuracy: 0.7539 - val_loss: 0.9874 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4951 - accuracy: 0.7597 - val_loss: 0.9626 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4927 - accuracy: 0.7609 - val_loss: 0.9220 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4895 - accuracy: 0.7614 - val_loss: 0.9508 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4901 - accuracy: 0.7609 - val_loss: 0.9760 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4906 - accuracy: 0.7652 - val_loss: 1.0194 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4749 - accuracy: 0.7695 - val_loss: 1.0270 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4763 - accuracy: 0.7693 - val_loss: 1.0755 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4784 - accuracy: 0.7683 - val_loss: 1.0233 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4979 - accuracy: 0.7536 - val_loss: 1.0323 - val_accuracy: 0.5865\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4974 - accuracy: 0.7602 - val_loss: 1.0351 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4880 - accuracy: 0.7612 - val_loss: 1.0006 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4849 - accuracy: 0.7688 - val_loss: 0.9993 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4843 - accuracy: 0.7650 - val_loss: 1.0478 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4877 - accuracy: 0.7640 - val_loss: 0.9550 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4884 - accuracy: 0.7637 - val_loss: 0.9690 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4907 - accuracy: 0.7620 - val_loss: 0.9350 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4873 - accuracy: 0.7668 - val_loss: 0.9744 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4991 - accuracy: 0.7579 - val_loss: 0.9402 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5068 - accuracy: 0.7559 - val_loss: 0.9603 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.5129 - accuracy: 0.7546 - val_loss: 0.8907 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5126 - accuracy: 0.7470 - val_loss: 0.9127 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4919 - accuracy: 0.7614 - val_loss: 0.9670 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4960 - accuracy: 0.7554 - val_loss: 1.0059 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4986 - accuracy: 0.7592 - val_loss: 0.9838 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4927 - accuracy: 0.7594 - val_loss: 0.9483 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.5026 - accuracy: 0.7521 - val_loss: 0.9306 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4885 - accuracy: 0.7627 - val_loss: 0.9579 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4868 - accuracy: 0.7665 - val_loss: 0.9772 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4904 - accuracy: 0.7647 - val_loss: 1.0187 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4812 - accuracy: 0.7668 - val_loss: 0.9149 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4998 - accuracy: 0.7549 - val_loss: 1.0012 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4826 - accuracy: 0.7655 - val_loss: 0.9973 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4799 - accuracy: 0.7690 - val_loss: 1.0174 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4710 - accuracy: 0.7741 - val_loss: 1.0009 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4790 - accuracy: 0.7733 - val_loss: 1.0166 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4857 - accuracy: 0.7685 - val_loss: 1.0328 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4909 - accuracy: 0.7675 - val_loss: 1.0014 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4954 - accuracy: 0.7614 - val_loss: 0.9705 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4926 - accuracy: 0.7609 - val_loss: 1.0263 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4884 - accuracy: 0.7642 - val_loss: 1.0317 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4927 - accuracy: 0.7609 - val_loss: 0.9881 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4948 - accuracy: 0.7587 - val_loss: 1.0434 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4888 - accuracy: 0.7673 - val_loss: 0.9876 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4812 - accuracy: 0.7683 - val_loss: 1.0371 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4759 - accuracy: 0.7733 - val_loss: 1.0337 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4759 - accuracy: 0.7733 - val_loss: 0.9850 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4957 - accuracy: 0.7650 - val_loss: 1.0575 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4853 - accuracy: 0.7665 - val_loss: 1.0895 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4887 - accuracy: 0.7660 - val_loss: 0.9678 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4914 - accuracy: 0.7612 - val_loss: 0.9908 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4917 - accuracy: 0.7665 - val_loss: 0.9851 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4896 - accuracy: 0.7655 - val_loss: 1.0378 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4938 - accuracy: 0.7602 - val_loss: 1.0267 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5034 - accuracy: 0.7599 - val_loss: 1.0624 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4984 - accuracy: 0.7577 - val_loss: 1.0357 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4932 - accuracy: 0.7592 - val_loss: 1.0260 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5000 - accuracy: 0.7602 - val_loss: 1.0288 - val_accuracy: 0.5854\nEpoch 3/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4988 - accuracy: 0.7637 - val_loss: 1.0709 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4898 - accuracy: 0.7665 - val_loss: 1.0232 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4764 - accuracy: 0.7751 - val_loss: 1.0194 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4877 - accuracy: 0.7680 - val_loss: 1.0464 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4921 - accuracy: 0.7650 - val_loss: 0.9785 - val_accuracy: 0.5784\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4862 - accuracy: 0.7637 - val_loss: 0.9648 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4945 - accuracy: 0.7632 - val_loss: 1.0584 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4944 - accuracy: 0.7592 - val_loss: 1.0707 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4795 - accuracy: 0.7711 - val_loss: 1.0035 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4915 - accuracy: 0.7632 - val_loss: 1.0611 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4995 - accuracy: 0.7541 - val_loss: 0.9799 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4831 - accuracy: 0.7695 - val_loss: 1.0099 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4953 - accuracy: 0.7630 - val_loss: 0.9062 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4794 - accuracy: 0.7713 - val_loss: 1.0283 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4832 - accuracy: 0.7741 - val_loss: 0.9936 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4923 - accuracy: 0.7592 - val_loss: 1.0097 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4870 - accuracy: 0.7675 - val_loss: 0.9969 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4738 - accuracy: 0.7751 - val_loss: 1.0151 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4806 - accuracy: 0.7718 - val_loss: 1.0141 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4818 - accuracy: 0.7733 - val_loss: 1.0305 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4801 - accuracy: 0.7708 - val_loss: 1.0112 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4832 - accuracy: 0.7718 - val_loss: 1.0155 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4838 - accuracy: 0.7690 - val_loss: 0.9993 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4805 - accuracy: 0.7721 - val_loss: 1.0123 - val_accuracy: 0.6259\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4897 - accuracy: 0.7663 - val_loss: 1.0291 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4829 - accuracy: 0.7700 - val_loss: 1.0495 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4843 - accuracy: 0.7695 - val_loss: 1.0510 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4809 - accuracy: 0.7718 - val_loss: 1.0155 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4937 - accuracy: 0.7577 - val_loss: 1.0074 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4946 - accuracy: 0.7602 - val_loss: 1.0186 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4816 - accuracy: 0.7683 - val_loss: 0.9882 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4778 - accuracy: 0.7731 - val_loss: 0.9616 - val_accuracy: 0.6218\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4821 - accuracy: 0.7690 - val_loss: 1.0523 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4848 - accuracy: 0.7657 - val_loss: 1.0672 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4856 - accuracy: 0.7695 - val_loss: 1.0598 - val_accuracy: 0.5945\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4864 - accuracy: 0.7670 - val_loss: 1.0486 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4865 - accuracy: 0.7637 - val_loss: 1.0290 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4750 - accuracy: 0.7756 - val_loss: 1.0896 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4849 - accuracy: 0.7718 - val_loss: 1.0498 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4787 - accuracy: 0.7706 - val_loss: 1.0797 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4782 - accuracy: 0.7751 - val_loss: 1.1015 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4766 - accuracy: 0.7743 - val_loss: 1.0692 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4709 - accuracy: 0.7786 - val_loss: 1.0517 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4661 - accuracy: 0.7814 - val_loss: 1.0501 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4738 - accuracy: 0.7756 - val_loss: 1.0627 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4881 - accuracy: 0.7668 - val_loss: 1.1001 - val_accuracy: 0.5854\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4814 - accuracy: 0.7700 - val_loss: 1.0193 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4793 - accuracy: 0.7749 - val_loss: 1.1052 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4943 - accuracy: 0.7655 - val_loss: 1.0091 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5103 - accuracy: 0.7485 - val_loss: 1.0361 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4981 - accuracy: 0.7594 - val_loss: 1.0291 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4970 - accuracy: 0.7574 - val_loss: 0.9866 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4911 - accuracy: 0.7680 - val_loss: 1.0172 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4928 - accuracy: 0.7632 - val_loss: 1.0555 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4873 - accuracy: 0.7685 - val_loss: 1.0227 - val_accuracy: 0.5865\nEpoch 3/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4681 - accuracy: 0.7764 - val_loss: 1.0436 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4722 - accuracy: 0.7797 - val_loss: 1.0500 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4694 - accuracy: 0.7814 - val_loss: 1.0422 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4802 - accuracy: 0.7693 - val_loss: 1.0609 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4743 - accuracy: 0.7716 - val_loss: 1.0215 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4736 - accuracy: 0.7756 - val_loss: 1.0306 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4769 - accuracy: 0.7708 - val_loss: 1.0394 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4772 - accuracy: 0.7640 - val_loss: 1.0225 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4997 - accuracy: 0.7551 - val_loss: 0.9760 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5060 - accuracy: 0.7566 - val_loss: 1.0203 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4834 - accuracy: 0.7668 - val_loss: 1.0210 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5042 - accuracy: 0.7544 - val_loss: 1.0360 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5141 - accuracy: 0.7468 - val_loss: 0.9656 - val_accuracy: 0.5683\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5111 - accuracy: 0.7480 - val_loss: 1.0000 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4803 - accuracy: 0.7678 - val_loss: 1.0392 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4777 - accuracy: 0.7736 - val_loss: 1.0302 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4823 - accuracy: 0.7690 - val_loss: 0.9489 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4904 - accuracy: 0.7640 - val_loss: 0.9823 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4810 - accuracy: 0.7703 - val_loss: 1.0305 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4731 - accuracy: 0.7802 - val_loss: 1.0218 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4690 - accuracy: 0.7743 - val_loss: 1.0098 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4671 - accuracy: 0.7824 - val_loss: 1.0058 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4721 - accuracy: 0.7764 - val_loss: 1.0169 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4822 - accuracy: 0.7673 - val_loss: 1.0810 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4781 - accuracy: 0.7713 - val_loss: 1.0344 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4784 - accuracy: 0.7700 - val_loss: 1.0189 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4934 - accuracy: 0.7630 - val_loss: 0.9679 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4919 - accuracy: 0.7612 - val_loss: 0.9650 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4828 - accuracy: 0.7657 - val_loss: 1.0481 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4803 - accuracy: 0.7718 - val_loss: 1.0216 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4821 - accuracy: 0.7698 - val_loss: 1.0145 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5040 - accuracy: 0.7579 - val_loss: 0.9713 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4931 - accuracy: 0.7592 - val_loss: 1.0940 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4799 - accuracy: 0.7690 - val_loss: 1.0610 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.9840 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4717 - accuracy: 0.7764 - val_loss: 1.0398 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4774 - accuracy: 0.7708 - val_loss: 1.0189 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4766 - accuracy: 0.7711 - val_loss: 1.0779 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4856 - accuracy: 0.7700 - val_loss: 1.0420 - val_accuracy: 0.5865\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4818 - accuracy: 0.7693 - val_loss: 1.0193 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4772 - accuracy: 0.7713 - val_loss: 1.0523 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4729 - accuracy: 0.7738 - val_loss: 1.0847 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4735 - accuracy: 0.7721 - val_loss: 1.1377 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4836 - accuracy: 0.7706 - val_loss: 1.0052 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5055 - accuracy: 0.7518 - val_loss: 0.9735 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5031 - accuracy: 0.7541 - val_loss: 0.9764 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4839 - accuracy: 0.7700 - val_loss: 0.9659 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4790 - accuracy: 0.7754 - val_loss: 1.0448 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4804 - accuracy: 0.7690 - val_loss: 1.0637 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4800 - accuracy: 0.7706 - val_loss: 1.0748 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4719 - accuracy: 0.7769 - val_loss: 0.9930 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4734 - accuracy: 0.7743 - val_loss: 1.0700 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4706 - accuracy: 0.7774 - val_loss: 1.0520 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4742 - accuracy: 0.7718 - val_loss: 1.1233 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4703 - accuracy: 0.7802 - val_loss: 1.0792 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4640 - accuracy: 0.7797 - val_loss: 1.0840 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4832 - accuracy: 0.7703 - val_loss: 1.0579 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4860 - accuracy: 0.7700 - val_loss: 1.0111 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4943 - accuracy: 0.7645 - val_loss: 1.0142 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4812 - accuracy: 0.7680 - val_loss: 1.0200 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4896 - accuracy: 0.7690 - val_loss: 1.0963 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4951 - accuracy: 0.7630 - val_loss: 1.0603 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4849 - accuracy: 0.7688 - val_loss: 1.0490 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4787 - accuracy: 0.7733 - val_loss: 1.0265 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4794 - accuracy: 0.7718 - val_loss: 0.9806 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4783 - accuracy: 0.7721 - val_loss: 1.0504 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4709 - accuracy: 0.7786 - val_loss: 1.0321 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4710 - accuracy: 0.7779 - val_loss: 1.1455 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5109 - accuracy: 0.7544 - val_loss: 1.0129 - val_accuracy: 0.5804\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5338 - accuracy: 0.7412 - val_loss: 0.9874 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4915 - accuracy: 0.7640 - val_loss: 0.9588 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4780 - accuracy: 0.7771 - val_loss: 1.0221 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4770 - accuracy: 0.7688 - val_loss: 1.0312 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4705 - accuracy: 0.7756 - val_loss: 1.0947 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4709 - accuracy: 0.7756 - val_loss: 1.0829 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4679 - accuracy: 0.7769 - val_loss: 1.1256 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4675 - accuracy: 0.7824 - val_loss: 1.0498 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4696 - accuracy: 0.7731 - val_loss: 1.0716 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4796 - accuracy: 0.7668 - val_loss: 1.0323 - val_accuracy: 0.5824\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4850 - accuracy: 0.7647 - val_loss: 1.0825 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4814 - accuracy: 0.7721 - val_loss: 1.0258 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4889 - accuracy: 0.7647 - val_loss: 1.0380 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4864 - accuracy: 0.7645 - val_loss: 0.9828 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4925 - accuracy: 0.7635 - val_loss: 0.9645 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4971 - accuracy: 0.7647 - val_loss: 0.9652 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4864 - accuracy: 0.7698 - val_loss: 1.0985 - val_accuracy: 0.5784\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4891 - accuracy: 0.7635 - val_loss: 1.0584 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4810 - accuracy: 0.7693 - val_loss: 1.0602 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4752 - accuracy: 0.7721 - val_loss: 1.0773 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4738 - accuracy: 0.7723 - val_loss: 1.0836 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4774 - accuracy: 0.7731 - val_loss: 1.0715 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4830 - accuracy: 0.7675 - val_loss: 1.0773 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4797 - accuracy: 0.7703 - val_loss: 1.0398 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4733 - accuracy: 0.7746 - val_loss: 1.0503 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4643 - accuracy: 0.7809 - val_loss: 1.0450 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4624 - accuracy: 0.7807 - val_loss: 1.0228 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4680 - accuracy: 0.7837 - val_loss: 1.0539 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4690 - accuracy: 0.7792 - val_loss: 1.0682 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4829 - accuracy: 0.7683 - val_loss: 1.0852 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4653 - accuracy: 0.7789 - val_loss: 1.0774 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4648 - accuracy: 0.7814 - val_loss: 1.0828 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4670 - accuracy: 0.7794 - val_loss: 1.0176 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4785 - accuracy: 0.7726 - val_loss: 1.1176 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4770 - accuracy: 0.7731 - val_loss: 1.1392 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4798 - accuracy: 0.7670 - val_loss: 1.1224 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4852 - accuracy: 0.7665 - val_loss: 1.0516 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4876 - accuracy: 0.7642 - val_loss: 1.0023 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4813 - accuracy: 0.7741 - val_loss: 1.1017 - val_accuracy: 0.5875\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4940 - accuracy: 0.7609 - val_loss: 1.0442 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4824 - accuracy: 0.7693 - val_loss: 1.1136 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4723 - accuracy: 0.7776 - val_loss: 1.0759 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4940 - accuracy: 0.7637 - val_loss: 1.0303 - val_accuracy: 0.5844\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5169 - accuracy: 0.7501 - val_loss: 1.0329 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4900 - accuracy: 0.7652 - val_loss: 1.0415 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4840 - accuracy: 0.7678 - val_loss: 1.0492 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4662 - accuracy: 0.7771 - val_loss: 1.0993 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4614 - accuracy: 0.7855 - val_loss: 1.0865 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4730 - accuracy: 0.7728 - val_loss: 1.0731 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4650 - accuracy: 0.7822 - val_loss: 1.0645 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4653 - accuracy: 0.7797 - val_loss: 1.0414 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4648 - accuracy: 0.7827 - val_loss: 1.0896 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4613 - accuracy: 0.7789 - val_loss: 1.0629 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4595 - accuracy: 0.7873 - val_loss: 1.0913 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4570 - accuracy: 0.7829 - val_loss: 1.1143 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4642 - accuracy: 0.7799 - val_loss: 1.0782 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4651 - accuracy: 0.7822 - val_loss: 1.0616 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4790 - accuracy: 0.7675 - val_loss: 1.0661 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4706 - accuracy: 0.7743 - val_loss: 1.0456 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4741 - accuracy: 0.7784 - val_loss: 1.1093 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4805 - accuracy: 0.7657 - val_loss: 1.1188 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4704 - accuracy: 0.7771 - val_loss: 1.0566 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4667 - accuracy: 0.7774 - val_loss: 1.0720 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4684 - accuracy: 0.7779 - val_loss: 1.0561 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4746 - accuracy: 0.7756 - val_loss: 1.0550 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4812 - accuracy: 0.7723 - val_loss: 1.0888 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4717 - accuracy: 0.7738 - val_loss: 1.0891 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4774 - accuracy: 0.7776 - val_loss: 1.1138 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4753 - accuracy: 0.7759 - val_loss: 1.1068 - val_accuracy: 0.6218\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4798 - accuracy: 0.7670 - val_loss: 0.9967 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4816 - accuracy: 0.7670 - val_loss: 1.0405 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4749 - accuracy: 0.7781 - val_loss: 1.0299 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4890 - accuracy: 0.7609 - val_loss: 1.0153 - val_accuracy: 0.5875\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5076 - accuracy: 0.7485 - val_loss: 1.1321 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4914 - accuracy: 0.7617 - val_loss: 1.0887 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4869 - accuracy: 0.7751 - val_loss: 1.0232 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4711 - accuracy: 0.7771 - val_loss: 1.0099 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4694 - accuracy: 0.7728 - val_loss: 1.0398 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4620 - accuracy: 0.7829 - val_loss: 1.0445 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4649 - accuracy: 0.7792 - val_loss: 1.0619 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4599 - accuracy: 0.7819 - val_loss: 1.0370 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4602 - accuracy: 0.7873 - val_loss: 1.0606 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4611 - accuracy: 0.7792 - val_loss: 1.0526 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4646 - accuracy: 0.7776 - val_loss: 1.0990 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4793 - accuracy: 0.7668 - val_loss: 1.1306 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4991 - accuracy: 0.7539 - val_loss: 1.0489 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4832 - accuracy: 0.7647 - val_loss: 1.1180 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4782 - accuracy: 0.7688 - val_loss: 1.1188 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4723 - accuracy: 0.7733 - val_loss: 1.1144 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4711 - accuracy: 0.7756 - val_loss: 1.0509 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4773 - accuracy: 0.7678 - val_loss: 0.9956 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4653 - accuracy: 0.7797 - val_loss: 1.0293 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4831 - accuracy: 0.7655 - val_loss: 1.0537 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4754 - accuracy: 0.7716 - val_loss: 1.0261 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4766 - accuracy: 0.7706 - val_loss: 1.0693 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4683 - accuracy: 0.7751 - val_loss: 1.0706 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4828 - accuracy: 0.7663 - val_loss: 1.0459 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4760 - accuracy: 0.7781 - val_loss: 1.0555 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4630 - accuracy: 0.7812 - val_loss: 1.1061 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4573 - accuracy: 0.7888 - val_loss: 1.1046 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4578 - accuracy: 0.7832 - val_loss: 1.0393 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4658 - accuracy: 0.7769 - val_loss: 1.0471 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4693 - accuracy: 0.7728 - val_loss: 1.0343 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4755 - accuracy: 0.7726 - val_loss: 1.0229 - val_accuracy: 0.5905\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4710 - accuracy: 0.7728 - val_loss: 1.0496 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4554 - accuracy: 0.7847 - val_loss: 1.0574 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4592 - accuracy: 0.7827 - val_loss: 1.1367 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4573 - accuracy: 0.7865 - val_loss: 1.1076 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4647 - accuracy: 0.7802 - val_loss: 1.0382 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4695 - accuracy: 0.7754 - val_loss: 1.1434 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4717 - accuracy: 0.7792 - val_loss: 1.1068 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4663 - accuracy: 0.7794 - val_loss: 1.0486 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4594 - accuracy: 0.7837 - val_loss: 1.1099 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4826 - accuracy: 0.7660 - val_loss: 1.0813 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4759 - accuracy: 0.7683 - val_loss: 1.1140 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4843 - accuracy: 0.7637 - val_loss: 1.0457 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4841 - accuracy: 0.7665 - val_loss: 0.9903 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4800 - accuracy: 0.7693 - val_loss: 0.9748 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4892 - accuracy: 0.7584 - val_loss: 1.0333 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4845 - accuracy: 0.7647 - val_loss: 1.1297 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4732 - accuracy: 0.7746 - val_loss: 1.0291 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4664 - accuracy: 0.7713 - val_loss: 1.0601 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4666 - accuracy: 0.7721 - val_loss: 1.0400 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4732 - accuracy: 0.7738 - val_loss: 1.0414 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4768 - accuracy: 0.7700 - val_loss: 1.0731 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4685 - accuracy: 0.7766 - val_loss: 1.0515 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4674 - accuracy: 0.7779 - val_loss: 1.1028 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4608 - accuracy: 0.7840 - val_loss: 1.0691 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4587 - accuracy: 0.7802 - val_loss: 1.1112 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4559 - accuracy: 0.7875 - val_loss: 1.0765 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4600 - accuracy: 0.7814 - val_loss: 1.1420 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4581 - accuracy: 0.7857 - val_loss: 1.0864 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4635 - accuracy: 0.7786 - val_loss: 1.1142 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4603 - accuracy: 0.7827 - val_loss: 1.0825 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4524 - accuracy: 0.7870 - val_loss: 1.0654 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4583 - accuracy: 0.7822 - val_loss: 1.0991 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4630 - accuracy: 0.7814 - val_loss: 1.1100 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4560 - accuracy: 0.7855 - val_loss: 1.1280 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4742 - accuracy: 0.7711 - val_loss: 1.0976 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4633 - accuracy: 0.7797 - val_loss: 1.1389 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4615 - accuracy: 0.7822 - val_loss: 1.1324 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4668 - accuracy: 0.7779 - val_loss: 1.0798 - val_accuracy: 0.5804\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4634 - accuracy: 0.7819 - val_loss: 1.1295 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4847 - accuracy: 0.7627 - val_loss: 1.0943 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4898 - accuracy: 0.7640 - val_loss: 1.0836 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4609 - accuracy: 0.7822 - val_loss: 1.1025 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4656 - accuracy: 0.7784 - val_loss: 1.0891 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4707 - accuracy: 0.7731 - val_loss: 1.0962 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4780 - accuracy: 0.7749 - val_loss: 1.0653 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4968 - accuracy: 0.7592 - val_loss: 1.1112 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4618 - accuracy: 0.7814 - val_loss: 1.1008 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4695 - accuracy: 0.7741 - val_loss: 1.0930 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4781 - accuracy: 0.7685 - val_loss: 1.0507 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4852 - accuracy: 0.7597 - val_loss: 1.0802 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 49us/sample - loss: 0.4719 - accuracy: 0.7759 - val_loss: 1.1108 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4639 - accuracy: 0.7829 - val_loss: 1.1056 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4630 - accuracy: 0.7862 - val_loss: 1.0702 - val_accuracy: 0.5895\nEpoch 4/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4651 - accuracy: 0.7706 - val_loss: 1.1023 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4617 - accuracy: 0.7852 - val_loss: 1.0099 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4664 - accuracy: 0.7802 - val_loss: 1.0900 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4693 - accuracy: 0.7733 - val_loss: 1.1218 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4681 - accuracy: 0.7749 - val_loss: 1.0905 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4656 - accuracy: 0.7799 - val_loss: 1.0831 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4633 - accuracy: 0.7809 - val_loss: 1.1353 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4718 - accuracy: 0.7761 - val_loss: 1.0890 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4726 - accuracy: 0.7728 - val_loss: 1.0668 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4682 - accuracy: 0.7792 - val_loss: 1.1242 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4653 - accuracy: 0.7776 - val_loss: 1.1640 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4615 - accuracy: 0.7761 - val_loss: 1.0975 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4735 - accuracy: 0.7743 - val_loss: 1.1496 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4736 - accuracy: 0.7756 - val_loss: 1.1509 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4664 - accuracy: 0.7792 - val_loss: 1.0975 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4645 - accuracy: 0.7751 - val_loss: 1.0652 - val_accuracy: 0.6218\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4627 - accuracy: 0.7802 - val_loss: 1.0403 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4639 - accuracy: 0.7824 - val_loss: 1.0488 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4725 - accuracy: 0.7738 - val_loss: 1.0778 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4756 - accuracy: 0.7726 - val_loss: 1.0608 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4831 - accuracy: 0.7642 - val_loss: 1.0591 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4673 - accuracy: 0.7769 - val_loss: 1.0090 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4546 - accuracy: 0.7847 - val_loss: 1.1573 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4661 - accuracy: 0.7799 - val_loss: 1.1493 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4671 - accuracy: 0.7812 - val_loss: 1.0906 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4625 - accuracy: 0.7779 - val_loss: 1.0576 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4792 - accuracy: 0.7708 - val_loss: 1.0394 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4938 - accuracy: 0.7577 - val_loss: 1.0333 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4744 - accuracy: 0.7713 - val_loss: 1.0655 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4609 - accuracy: 0.7845 - val_loss: 1.0719 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4609 - accuracy: 0.7789 - val_loss: 1.0742 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4527 - accuracy: 0.7832 - val_loss: 1.0887 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4574 - accuracy: 0.7814 - val_loss: 1.0857 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4601 - accuracy: 0.7822 - val_loss: 1.1489 - val_accuracy: 0.5844\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4633 - accuracy: 0.7736 - val_loss: 1.0966 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4729 - accuracy: 0.7738 - val_loss: 1.0892 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4576 - accuracy: 0.7832 - val_loss: 1.1333 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4746 - accuracy: 0.7695 - val_loss: 1.1348 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4746 - accuracy: 0.7738 - val_loss: 1.0935 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4656 - accuracy: 0.7764 - val_loss: 1.1105 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4617 - accuracy: 0.7812 - val_loss: 1.0633 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4552 - accuracy: 0.7857 - val_loss: 1.1133 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4561 - accuracy: 0.7845 - val_loss: 1.1096 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4628 - accuracy: 0.7781 - val_loss: 1.0123 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4676 - accuracy: 0.7797 - val_loss: 1.0757 - val_accuracy: 0.5905\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4613 - accuracy: 0.7824 - val_loss: 1.1093 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4619 - accuracy: 0.7784 - val_loss: 1.0560 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4718 - accuracy: 0.7711 - val_loss: 1.1473 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4682 - accuracy: 0.7731 - val_loss: 1.1561 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4519 - accuracy: 0.7817 - val_loss: 1.1403 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4526 - accuracy: 0.7865 - val_loss: 1.1126 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4603 - accuracy: 0.7837 - val_loss: 1.1683 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4763 - accuracy: 0.7716 - val_loss: 1.1556 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4700 - accuracy: 0.7754 - val_loss: 1.1225 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4714 - accuracy: 0.7736 - val_loss: 1.0575 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4763 - accuracy: 0.7769 - val_loss: 1.1043 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4671 - accuracy: 0.7751 - val_loss: 1.0834 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4644 - accuracy: 0.7761 - val_loss: 1.1100 - val_accuracy: 0.5875\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4782 - accuracy: 0.7698 - val_loss: 1.0869 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4651 - accuracy: 0.7738 - val_loss: 1.1278 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4675 - accuracy: 0.7759 - val_loss: 1.1319 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4684 - accuracy: 0.7756 - val_loss: 1.0717 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4775 - accuracy: 0.7690 - val_loss: 1.0729 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4682 - accuracy: 0.7781 - val_loss: 1.0534 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4520 - accuracy: 0.7878 - val_loss: 1.1524 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4581 - accuracy: 0.7867 - val_loss: 1.1414 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4594 - accuracy: 0.7832 - val_loss: 1.0535 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4595 - accuracy: 0.7832 - val_loss: 1.1002 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4574 - accuracy: 0.7807 - val_loss: 1.0977 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4757 - accuracy: 0.7693 - val_loss: 1.1476 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4622 - accuracy: 0.7802 - val_loss: 1.1227 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4582 - accuracy: 0.7819 - val_loss: 1.0837 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4569 - accuracy: 0.7837 - val_loss: 1.1083 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4593 - accuracy: 0.7835 - val_loss: 1.1384 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4626 - accuracy: 0.7812 - val_loss: 1.1017 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4668 - accuracy: 0.7766 - val_loss: 1.1269 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4727 - accuracy: 0.7690 - val_loss: 1.1130 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4675 - accuracy: 0.7764 - val_loss: 1.0519 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4655 - accuracy: 0.7809 - val_loss: 1.0671 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4916 - accuracy: 0.7607 - val_loss: 1.0069 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5017 - accuracy: 0.7523 - val_loss: 1.0318 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4847 - accuracy: 0.7685 - val_loss: 1.1283 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4650 - accuracy: 0.7759 - val_loss: 1.0671 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4616 - accuracy: 0.7766 - val_loss: 1.0729 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4601 - accuracy: 0.7789 - val_loss: 1.0366 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4543 - accuracy: 0.7812 - val_loss: 1.0692 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4581 - accuracy: 0.7832 - val_loss: 1.0257 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4726 - accuracy: 0.7746 - val_loss: 1.1007 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4635 - accuracy: 0.7807 - val_loss: 1.1234 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4703 - accuracy: 0.7731 - val_loss: 1.0245 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4734 - accuracy: 0.7731 - val_loss: 1.0821 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4618 - accuracy: 0.7789 - val_loss: 1.0899 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4548 - accuracy: 0.7847 - val_loss: 1.0615 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4510 - accuracy: 0.7900 - val_loss: 1.0987 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4532 - accuracy: 0.7832 - val_loss: 1.0609 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4513 - accuracy: 0.7873 - val_loss: 1.1001 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4645 - accuracy: 0.7797 - val_loss: 1.0713 - val_accuracy: 0.6259\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4555 - accuracy: 0.7781 - val_loss: 1.1279 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4564 - accuracy: 0.7817 - val_loss: 1.0342 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4523 - accuracy: 0.7898 - val_loss: 1.1031 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4697 - accuracy: 0.7761 - val_loss: 1.0946 - val_accuracy: 0.6188\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4683 - accuracy: 0.7802 - val_loss: 1.0165 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4841 - accuracy: 0.7678 - val_loss: 1.1173 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4752 - accuracy: 0.7731 - val_loss: 1.0761 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4698 - accuracy: 0.7776 - val_loss: 1.0929 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4685 - accuracy: 0.7754 - val_loss: 0.9992 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4592 - accuracy: 0.7835 - val_loss: 1.0741 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4524 - accuracy: 0.7807 - val_loss: 1.0681 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4489 - accuracy: 0.7850 - val_loss: 1.0753 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4457 - accuracy: 0.7855 - val_loss: 1.0668 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4442 - accuracy: 0.7895 - val_loss: 1.1212 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4542 - accuracy: 0.7837 - val_loss: 1.0665 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4530 - accuracy: 0.7850 - val_loss: 1.1346 - val_accuracy: 0.6239\nEpoch 2/5\n3953/3953 [==============================] - 0s 32us/sample - loss: 0.4573 - accuracy: 0.7829 - val_loss: 1.0874 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4556 - accuracy: 0.7837 - val_loss: 1.1271 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4585 - accuracy: 0.7847 - val_loss: 1.0345 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4551 - accuracy: 0.7797 - val_loss: 1.0958 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4523 - accuracy: 0.7885 - val_loss: 1.0716 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4559 - accuracy: 0.7840 - val_loss: 1.1074 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4660 - accuracy: 0.7774 - val_loss: 1.0087 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4615 - accuracy: 0.7797 - val_loss: 1.0795 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4592 - accuracy: 0.7809 - val_loss: 1.0491 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4535 - accuracy: 0.7845 - val_loss: 1.1567 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4597 - accuracy: 0.7832 - val_loss: 1.1172 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4551 - accuracy: 0.7814 - val_loss: 1.0846 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4551 - accuracy: 0.7842 - val_loss: 1.0986 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4543 - accuracy: 0.7852 - val_loss: 1.1182 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4492 - accuracy: 0.7855 - val_loss: 1.0968 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4619 - accuracy: 0.7781 - val_loss: 1.1152 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4699 - accuracy: 0.7731 - val_loss: 1.1342 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4596 - accuracy: 0.7837 - val_loss: 1.0822 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4520 - accuracy: 0.7862 - val_loss: 1.0962 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4581 - accuracy: 0.7835 - val_loss: 1.0441 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4678 - accuracy: 0.7764 - val_loss: 1.0647 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4681 - accuracy: 0.7829 - val_loss: 1.0814 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4507 - accuracy: 0.7850 - val_loss: 1.1422 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4634 - accuracy: 0.7776 - val_loss: 1.1114 - val_accuracy: 0.6188\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4588 - accuracy: 0.7794 - val_loss: 1.0992 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4834 - accuracy: 0.7642 - val_loss: 1.1144 - val_accuracy: 0.5723\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.5102 - accuracy: 0.7498 - val_loss: 1.0177 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4914 - accuracy: 0.7650 - val_loss: 0.9853 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4847 - accuracy: 0.7622 - val_loss: 1.0708 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4648 - accuracy: 0.7776 - val_loss: 1.0604 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4541 - accuracy: 0.7860 - val_loss: 1.0773 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4529 - accuracy: 0.7873 - val_loss: 1.1283 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4704 - accuracy: 0.7736 - val_loss: 1.0921 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4754 - accuracy: 0.7698 - val_loss: 1.1382 - val_accuracy: 0.5895\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4805 - accuracy: 0.7703 - val_loss: 1.0732 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4536 - accuracy: 0.7847 - val_loss: 1.1577 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4490 - accuracy: 0.7883 - val_loss: 1.1103 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4516 - accuracy: 0.7888 - val_loss: 1.1016 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4521 - accuracy: 0.7835 - val_loss: 1.0903 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4567 - accuracy: 0.7797 - val_loss: 1.0766 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4566 - accuracy: 0.7860 - val_loss: 1.1059 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4516 - accuracy: 0.7845 - val_loss: 1.0981 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4559 - accuracy: 0.7852 - val_loss: 1.1260 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4514 - accuracy: 0.7875 - val_loss: 1.1082 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4501 - accuracy: 0.7867 - val_loss: 1.1188 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4516 - accuracy: 0.7867 - val_loss: 1.1007 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4503 - accuracy: 0.7878 - val_loss: 1.0617 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4532 - accuracy: 0.7883 - val_loss: 1.1433 - val_accuracy: 0.6188\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4562 - accuracy: 0.7802 - val_loss: 1.0582 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4527 - accuracy: 0.7855 - val_loss: 1.1439 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4504 - accuracy: 0.7862 - val_loss: 1.1087 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4513 - accuracy: 0.7880 - val_loss: 1.1244 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4573 - accuracy: 0.7903 - val_loss: 1.1624 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4557 - accuracy: 0.7850 - val_loss: 1.1506 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4504 - accuracy: 0.7845 - val_loss: 1.1449 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4455 - accuracy: 0.7923 - val_loss: 1.1498 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4488 - accuracy: 0.7883 - val_loss: 1.0962 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4541 - accuracy: 0.7807 - val_loss: 1.1481 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4541 - accuracy: 0.7875 - val_loss: 1.1807 - val_accuracy: 0.5885\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4631 - accuracy: 0.7802 - val_loss: 1.0956 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4585 - accuracy: 0.7817 - val_loss: 1.1093 - val_accuracy: 0.6188\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4480 - accuracy: 0.7893 - val_loss: 1.1683 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4555 - accuracy: 0.7786 - val_loss: 1.1081 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4518 - accuracy: 0.7857 - val_loss: 1.0950 - val_accuracy: 0.6239\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4531 - accuracy: 0.7845 - val_loss: 1.1249 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4553 - accuracy: 0.7842 - val_loss: 1.1637 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4565 - accuracy: 0.7817 - val_loss: 1.1720 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4574 - accuracy: 0.7809 - val_loss: 1.1005 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4607 - accuracy: 0.7776 - val_loss: 1.1119 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4505 - accuracy: 0.7873 - val_loss: 1.1311 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4451 - accuracy: 0.7900 - val_loss: 1.0899 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4442 - accuracy: 0.7903 - val_loss: 1.1303 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4448 - accuracy: 0.7878 - val_loss: 1.1128 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4439 - accuracy: 0.7943 - val_loss: 1.1811 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4474 - accuracy: 0.7913 - val_loss: 1.1009 - val_accuracy: 0.6239\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4896 - accuracy: 0.7680 - val_loss: 1.1922 - val_accuracy: 0.5966\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4743 - accuracy: 0.7706 - val_loss: 1.1339 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4830 - accuracy: 0.7708 - val_loss: 1.1051 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4737 - accuracy: 0.7700 - val_loss: 1.0713 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4679 - accuracy: 0.7776 - val_loss: 1.0835 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4621 - accuracy: 0.7799 - val_loss: 1.1359 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4552 - accuracy: 0.7878 - val_loss: 1.0866 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4554 - accuracy: 0.7842 - val_loss: 1.1073 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4650 - accuracy: 0.7802 - val_loss: 1.0395 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4727 - accuracy: 0.7733 - val_loss: 1.1136 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4678 - accuracy: 0.7731 - val_loss: 1.1000 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4589 - accuracy: 0.7814 - val_loss: 1.0874 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4470 - accuracy: 0.7870 - val_loss: 1.1272 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4498 - accuracy: 0.7918 - val_loss: 1.1148 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4496 - accuracy: 0.7895 - val_loss: 1.0905 - val_accuracy: 0.5915\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4508 - accuracy: 0.7880 - val_loss: 1.1169 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4524 - accuracy: 0.7870 - val_loss: 1.0880 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4452 - accuracy: 0.7938 - val_loss: 1.0961 - val_accuracy: 0.6239\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4488 - accuracy: 0.7895 - val_loss: 1.1384 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4621 - accuracy: 0.7809 - val_loss: 1.0965 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4582 - accuracy: 0.7804 - val_loss: 1.1341 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4560 - accuracy: 0.7827 - val_loss: 1.1083 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4461 - accuracy: 0.7900 - val_loss: 1.1793 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4552 - accuracy: 0.7837 - val_loss: 1.1307 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4487 - accuracy: 0.7921 - val_loss: 1.1168 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4439 - accuracy: 0.7895 - val_loss: 1.1490 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4534 - accuracy: 0.7842 - val_loss: 1.0976 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4723 - accuracy: 0.7703 - val_loss: 1.1226 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4667 - accuracy: 0.7809 - val_loss: 1.1126 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4809 - accuracy: 0.7690 - val_loss: 1.1074 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4737 - accuracy: 0.7759 - val_loss: 1.0539 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4559 - accuracy: 0.7835 - val_loss: 1.0561 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4570 - accuracy: 0.7817 - val_loss: 1.0407 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4487 - accuracy: 0.7878 - val_loss: 1.1199 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4451 - accuracy: 0.7875 - val_loss: 1.1103 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4642 - accuracy: 0.7736 - val_loss: 1.0394 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4723 - accuracy: 0.7756 - val_loss: 1.1089 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4540 - accuracy: 0.7842 - val_loss: 1.0822 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4498 - accuracy: 0.7878 - val_loss: 1.0735 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4403 - accuracy: 0.7951 - val_loss: 1.1581 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4508 - accuracy: 0.7875 - val_loss: 1.1289 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4461 - accuracy: 0.7964 - val_loss: 1.1273 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4529 - accuracy: 0.7802 - val_loss: 1.1706 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4516 - accuracy: 0.7880 - val_loss: 1.0961 - val_accuracy: 0.6239\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4523 - accuracy: 0.7799 - val_loss: 1.0655 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4534 - accuracy: 0.7900 - val_loss: 1.1068 - val_accuracy: 0.6218\nEpoch 3/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4462 - accuracy: 0.7850 - val_loss: 1.1001 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4534 - accuracy: 0.7822 - val_loss: 1.0781 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4551 - accuracy: 0.7827 - val_loss: 1.1079 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4523 - accuracy: 0.7847 - val_loss: 1.1244 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4557 - accuracy: 0.7814 - val_loss: 1.1192 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4749 - accuracy: 0.7774 - val_loss: 1.1092 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4530 - accuracy: 0.7847 - val_loss: 1.0906 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4484 - accuracy: 0.7865 - val_loss: 1.0719 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4593 - accuracy: 0.7817 - val_loss: 1.0811 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4637 - accuracy: 0.7789 - val_loss: 1.0902 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4490 - accuracy: 0.7870 - val_loss: 1.1096 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4613 - accuracy: 0.7812 - val_loss: 1.0581 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4594 - accuracy: 0.7809 - val_loss: 1.0740 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4576 - accuracy: 0.7824 - val_loss: 1.0458 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4805 - accuracy: 0.7680 - val_loss: 1.1253 - val_accuracy: 0.5885\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4780 - accuracy: 0.7647 - val_loss: 1.0257 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4587 - accuracy: 0.7792 - val_loss: 1.0652 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4575 - accuracy: 0.7837 - val_loss: 1.0711 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4500 - accuracy: 0.7840 - val_loss: 1.0570 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4445 - accuracy: 0.7928 - val_loss: 1.1284 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4626 - accuracy: 0.7809 - val_loss: 1.1783 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4491 - accuracy: 0.7910 - val_loss: 1.1236 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4475 - accuracy: 0.7918 - val_loss: 1.0923 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4479 - accuracy: 0.7931 - val_loss: 1.0487 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4516 - accuracy: 0.7842 - val_loss: 1.1235 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4510 - accuracy: 0.7898 - val_loss: 1.1334 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4541 - accuracy: 0.7847 - val_loss: 1.0933 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4662 - accuracy: 0.7824 - val_loss: 1.0797 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4519 - accuracy: 0.7873 - val_loss: 1.1604 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4549 - accuracy: 0.7845 - val_loss: 1.1892 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4679 - accuracy: 0.7761 - val_loss: 1.1513 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4581 - accuracy: 0.7779 - val_loss: 1.1304 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4456 - accuracy: 0.7895 - val_loss: 1.1764 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4519 - accuracy: 0.7873 - val_loss: 1.1403 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4495 - accuracy: 0.7857 - val_loss: 1.1624 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4464 - accuracy: 0.7908 - val_loss: 1.1245 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4468 - accuracy: 0.7873 - val_loss: 1.2067 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4513 - accuracy: 0.7913 - val_loss: 1.1532 - val_accuracy: 0.6218\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4512 - accuracy: 0.7900 - val_loss: 1.1702 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4600 - accuracy: 0.7857 - val_loss: 1.1698 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4530 - accuracy: 0.7840 - val_loss: 1.1108 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4464 - accuracy: 0.7916 - val_loss: 1.1634 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4443 - accuracy: 0.7936 - val_loss: 1.1568 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4593 - accuracy: 0.7845 - val_loss: 1.1193 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4525 - accuracy: 0.7850 - val_loss: 1.1258 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4536 - accuracy: 0.7885 - val_loss: 1.1670 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4690 - accuracy: 0.7756 - val_loss: 1.0518 - val_accuracy: 0.5854\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4769 - accuracy: 0.7680 - val_loss: 1.0787 - val_accuracy: 0.5865\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4673 - accuracy: 0.7743 - val_loss: 1.0844 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4538 - accuracy: 0.7873 - val_loss: 1.0950 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4508 - accuracy: 0.7842 - val_loss: 1.1968 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4452 - accuracy: 0.7898 - val_loss: 1.1518 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4380 - accuracy: 0.7931 - val_loss: 1.1229 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4403 - accuracy: 0.7933 - val_loss: 1.2159 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4465 - accuracy: 0.7908 - val_loss: 1.1979 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4529 - accuracy: 0.7850 - val_loss: 1.1321 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4512 - accuracy: 0.7918 - val_loss: 1.1090 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4482 - accuracy: 0.7867 - val_loss: 1.1793 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4426 - accuracy: 0.7938 - val_loss: 1.0934 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4646 - accuracy: 0.7751 - val_loss: 1.1748 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4944 - accuracy: 0.7602 - val_loss: 1.0687 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4880 - accuracy: 0.7657 - val_loss: 1.0551 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5088 - accuracy: 0.7455 - val_loss: 1.0310 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4680 - accuracy: 0.7766 - val_loss: 1.0236 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4482 - accuracy: 0.7873 - val_loss: 1.1300 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4489 - accuracy: 0.7878 - val_loss: 1.1099 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4493 - accuracy: 0.7895 - val_loss: 1.0796 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4561 - accuracy: 0.7840 - val_loss: 1.1633 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4720 - accuracy: 0.7751 - val_loss: 1.1259 - val_accuracy: 0.5935\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4631 - accuracy: 0.7819 - val_loss: 1.0717 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4545 - accuracy: 0.7822 - val_loss: 1.0897 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4506 - accuracy: 0.7883 - val_loss: 1.0708 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4622 - accuracy: 0.7769 - val_loss: 1.1182 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4590 - accuracy: 0.7829 - val_loss: 1.1149 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4551 - accuracy: 0.7850 - val_loss: 1.1301 - val_accuracy: 0.6198\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4571 - accuracy: 0.7824 - val_loss: 1.1101 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4474 - accuracy: 0.7898 - val_loss: 1.1216 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4469 - accuracy: 0.7923 - val_loss: 1.1220 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4433 - accuracy: 0.7898 - val_loss: 1.1565 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4497 - accuracy: 0.7885 - val_loss: 1.0777 - val_accuracy: 0.6239\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4449 - accuracy: 0.7873 - val_loss: 1.1983 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4410 - accuracy: 0.7933 - val_loss: 1.1567 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4459 - accuracy: 0.7890 - val_loss: 1.0949 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4432 - accuracy: 0.7933 - val_loss: 1.1514 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4451 - accuracy: 0.7890 - val_loss: 1.1237 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4414 - accuracy: 0.7893 - val_loss: 1.1829 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4599 - accuracy: 0.7832 - val_loss: 1.1611 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4587 - accuracy: 0.7774 - val_loss: 1.0887 - val_accuracy: 0.6188\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4751 - accuracy: 0.7731 - val_loss: 1.0576 - val_accuracy: 0.5885\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4719 - accuracy: 0.7759 - val_loss: 1.0947 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4628 - accuracy: 0.7784 - val_loss: 1.0560 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4704 - accuracy: 0.7794 - val_loss: 1.0635 - val_accuracy: 0.5814\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4740 - accuracy: 0.7688 - val_loss: 1.0648 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4614 - accuracy: 0.7822 - val_loss: 1.0863 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4521 - accuracy: 0.7845 - val_loss: 1.0984 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4607 - accuracy: 0.7792 - val_loss: 1.1393 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4567 - accuracy: 0.7850 - val_loss: 1.1194 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4521 - accuracy: 0.7855 - val_loss: 1.0913 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4543 - accuracy: 0.7814 - val_loss: 1.1066 - val_accuracy: 0.6249\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4517 - accuracy: 0.7870 - val_loss: 1.0550 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4472 - accuracy: 0.7898 - val_loss: 1.0908 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4413 - accuracy: 0.7913 - val_loss: 1.1175 - val_accuracy: 0.6218\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4489 - accuracy: 0.7885 - val_loss: 1.0987 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4532 - accuracy: 0.7880 - val_loss: 1.1198 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4521 - accuracy: 0.7835 - val_loss: 1.0968 - val_accuracy: 0.5945\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4541 - accuracy: 0.7809 - val_loss: 1.1054 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4539 - accuracy: 0.7860 - val_loss: 1.1561 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4532 - accuracy: 0.7850 - val_loss: 1.1384 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4466 - accuracy: 0.7893 - val_loss: 1.1568 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4414 - accuracy: 0.7918 - val_loss: 1.1535 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4421 - accuracy: 0.7931 - val_loss: 1.1416 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4509 - accuracy: 0.7880 - val_loss: 1.1768 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4525 - accuracy: 0.7857 - val_loss: 1.1048 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4565 - accuracy: 0.7835 - val_loss: 1.1384 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4701 - accuracy: 0.7781 - val_loss: 1.1274 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4739 - accuracy: 0.7741 - val_loss: 1.1423 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4805 - accuracy: 0.7673 - val_loss: 1.1111 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4684 - accuracy: 0.7721 - val_loss: 1.0555 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4615 - accuracy: 0.7850 - val_loss: 1.1017 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4484 - accuracy: 0.7873 - val_loss: 1.1959 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4503 - accuracy: 0.7888 - val_loss: 1.0925 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4574 - accuracy: 0.7829 - val_loss: 1.1123 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4467 - accuracy: 0.7883 - val_loss: 1.1052 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4479 - accuracy: 0.7893 - val_loss: 1.1031 - val_accuracy: 0.6269\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4498 - accuracy: 0.7845 - val_loss: 1.0640 - val_accuracy: 0.6188\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4492 - accuracy: 0.7860 - val_loss: 1.1115 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4388 - accuracy: 0.7916 - val_loss: 1.1403 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4416 - accuracy: 0.7916 - val_loss: 1.1152 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4412 - accuracy: 0.7875 - val_loss: 1.1947 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4506 - accuracy: 0.7842 - val_loss: 1.1374 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4578 - accuracy: 0.7842 - val_loss: 1.1163 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4706 - accuracy: 0.7746 - val_loss: 1.0710 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5020 - accuracy: 0.7546 - val_loss: 1.0590 - val_accuracy: 0.5824\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4841 - accuracy: 0.7680 - val_loss: 1.0272 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4695 - accuracy: 0.7743 - val_loss: 1.0548 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4585 - accuracy: 0.7819 - val_loss: 0.9937 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4517 - accuracy: 0.7824 - val_loss: 1.1600 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4502 - accuracy: 0.7855 - val_loss: 1.0876 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4525 - accuracy: 0.7847 - val_loss: 1.1030 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4539 - accuracy: 0.7819 - val_loss: 1.1004 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4538 - accuracy: 0.7850 - val_loss: 1.0629 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4577 - accuracy: 0.7802 - val_loss: 1.0985 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4762 - accuracy: 0.7718 - val_loss: 1.0238 - val_accuracy: 0.5794\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4617 - accuracy: 0.7751 - val_loss: 1.0985 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4570 - accuracy: 0.7817 - val_loss: 1.1195 - val_accuracy: 0.6218\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4549 - accuracy: 0.7850 - val_loss: 1.0840 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4564 - accuracy: 0.7824 - val_loss: 1.1335 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4506 - accuracy: 0.7880 - val_loss: 1.1485 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4373 - accuracy: 0.7948 - val_loss: 1.1650 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4368 - accuracy: 0.7971 - val_loss: 1.1600 - val_accuracy: 0.6178\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4382 - accuracy: 0.7951 - val_loss: 1.1904 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4397 - accuracy: 0.7938 - val_loss: 1.1731 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4450 - accuracy: 0.7885 - val_loss: 1.1431 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4431 - accuracy: 0.7921 - val_loss: 1.1091 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4502 - accuracy: 0.7933 - val_loss: 1.1416 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4918 - accuracy: 0.7647 - val_loss: 1.1202 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4553 - accuracy: 0.7804 - val_loss: 1.1782 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4620 - accuracy: 0.7812 - val_loss: 1.0930 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4621 - accuracy: 0.7776 - val_loss: 1.0790 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4657 - accuracy: 0.7809 - val_loss: 1.1006 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4537 - accuracy: 0.7880 - val_loss: 1.1530 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4472 - accuracy: 0.7870 - val_loss: 1.0829 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4429 - accuracy: 0.7938 - val_loss: 1.1389 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4451 - accuracy: 0.7903 - val_loss: 1.1456 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4393 - accuracy: 0.7943 - val_loss: 1.1127 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4543 - accuracy: 0.7845 - val_loss: 1.1021 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4515 - accuracy: 0.7845 - val_loss: 1.1870 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4426 - accuracy: 0.7953 - val_loss: 1.1889 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4489 - accuracy: 0.7903 - val_loss: 1.1566 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4567 - accuracy: 0.7824 - val_loss: 1.1824 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4530 - accuracy: 0.7804 - val_loss: 1.1644 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4429 - accuracy: 0.7903 - val_loss: 1.2027 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4376 - accuracy: 0.7918 - val_loss: 1.1980 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4414 - accuracy: 0.7943 - val_loss: 1.1367 - val_accuracy: 0.6208\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4514 - accuracy: 0.7855 - val_loss: 1.2059 - val_accuracy: 0.6188\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4492 - accuracy: 0.7862 - val_loss: 1.1785 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4581 - accuracy: 0.7829 - val_loss: 1.1116 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4592 - accuracy: 0.7817 - val_loss: 1.1052 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4511 - accuracy: 0.7903 - val_loss: 1.1412 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4485 - accuracy: 0.7898 - val_loss: 1.1333 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4497 - accuracy: 0.7910 - val_loss: 1.1597 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4533 - accuracy: 0.7850 - val_loss: 1.2632 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4690 - accuracy: 0.7749 - val_loss: 1.1545 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4632 - accuracy: 0.7797 - val_loss: 1.1929 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4518 - accuracy: 0.7880 - val_loss: 1.1383 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4482 - accuracy: 0.7908 - val_loss: 1.1698 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4698 - accuracy: 0.7814 - val_loss: 1.1099 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4650 - accuracy: 0.7746 - val_loss: 1.0646 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4571 - accuracy: 0.7835 - val_loss: 1.1490 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4507 - accuracy: 0.7850 - val_loss: 1.0922 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4405 - accuracy: 0.7971 - val_loss: 1.2024 - val_accuracy: 0.6178\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4477 - accuracy: 0.7862 - val_loss: 1.1889 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4528 - accuracy: 0.7895 - val_loss: 1.1339 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4705 - accuracy: 0.7721 - val_loss: 1.1638 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4598 - accuracy: 0.7817 - val_loss: 1.1500 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4452 - accuracy: 0.7953 - val_loss: 1.1713 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4434 - accuracy: 0.7936 - val_loss: 1.0792 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4555 - accuracy: 0.7875 - val_loss: 1.1418 - val_accuracy: 0.5925\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4540 - accuracy: 0.7837 - val_loss: 1.0866 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4411 - accuracy: 0.7883 - val_loss: 1.1984 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4411 - accuracy: 0.7910 - val_loss: 1.1940 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4409 - accuracy: 0.7943 - val_loss: 1.1876 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4467 - accuracy: 0.7885 - val_loss: 1.1930 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4453 - accuracy: 0.7852 - val_loss: 1.1745 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4444 - accuracy: 0.7903 - val_loss: 1.2071 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4466 - accuracy: 0.7873 - val_loss: 1.2510 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4465 - accuracy: 0.7888 - val_loss: 1.1873 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4568 - accuracy: 0.7822 - val_loss: 1.2182 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4767 - accuracy: 0.7756 - val_loss: 1.1777 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4779 - accuracy: 0.7713 - val_loss: 1.1305 - val_accuracy: 0.5915\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4711 - accuracy: 0.7751 - val_loss: 1.0458 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5008 - accuracy: 0.7670 - val_loss: 1.0478 - val_accuracy: 0.5834\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5518 - accuracy: 0.7197 - val_loss: 1.0653 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4962 - accuracy: 0.7602 - val_loss: 1.0772 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4726 - accuracy: 0.7751 - val_loss: 1.0519 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4593 - accuracy: 0.7880 - val_loss: 1.0674 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4556 - accuracy: 0.7857 - val_loss: 1.1136 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4532 - accuracy: 0.7875 - val_loss: 1.0559 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4551 - accuracy: 0.7865 - val_loss: 1.1079 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4530 - accuracy: 0.7910 - val_loss: 1.0803 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4480 - accuracy: 0.7895 - val_loss: 1.1491 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4392 - accuracy: 0.7916 - val_loss: 1.1544 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4402 - accuracy: 0.7926 - val_loss: 1.1655 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4419 - accuracy: 0.7921 - val_loss: 1.0764 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4393 - accuracy: 0.7933 - val_loss: 1.1540 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4374 - accuracy: 0.7926 - val_loss: 1.1633 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4462 - accuracy: 0.7860 - val_loss: 1.2380 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4657 - accuracy: 0.7771 - val_loss: 1.1418 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4524 - accuracy: 0.7913 - val_loss: 1.0963 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4456 - accuracy: 0.7926 - val_loss: 1.1502 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4468 - accuracy: 0.7883 - val_loss: 1.1872 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4755 - accuracy: 0.7769 - val_loss: 1.1832 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4713 - accuracy: 0.7786 - val_loss: 1.1472 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4500 - accuracy: 0.7857 - val_loss: 1.1572 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4698 - accuracy: 0.7797 - val_loss: 1.0605 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4615 - accuracy: 0.7751 - val_loss: 1.0685 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4594 - accuracy: 0.7847 - val_loss: 1.1035 - val_accuracy: 0.5915\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4564 - accuracy: 0.7822 - val_loss: 1.1175 - val_accuracy: 0.5976\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4509 - accuracy: 0.7842 - val_loss: 1.1510 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4519 - accuracy: 0.7875 - val_loss: 1.1438 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4661 - accuracy: 0.7799 - val_loss: 1.0682 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4724 - accuracy: 0.7731 - val_loss: 1.0844 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4546 - accuracy: 0.7832 - val_loss: 1.1200 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4465 - accuracy: 0.7867 - val_loss: 1.2172 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4565 - accuracy: 0.7824 - val_loss: 1.2038 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4566 - accuracy: 0.7840 - val_loss: 1.1548 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4528 - accuracy: 0.7809 - val_loss: 1.1623 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4464 - accuracy: 0.7916 - val_loss: 1.2037 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4476 - accuracy: 0.7908 - val_loss: 1.0817 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4577 - accuracy: 0.7827 - val_loss: 1.1383 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4527 - accuracy: 0.7873 - val_loss: 1.1622 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4428 - accuracy: 0.7905 - val_loss: 1.1322 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4438 - accuracy: 0.7880 - val_loss: 1.2262 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4422 - accuracy: 0.7913 - val_loss: 1.2371 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4394 - accuracy: 0.7918 - val_loss: 1.0958 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4396 - accuracy: 0.7953 - val_loss: 1.1511 - val_accuracy: 0.6259\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4404 - accuracy: 0.7898 - val_loss: 1.1871 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4473 - accuracy: 0.7883 - val_loss: 1.0833 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4511 - accuracy: 0.7878 - val_loss: 1.2538 - val_accuracy: 0.5804\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4700 - accuracy: 0.7726 - val_loss: 1.1841 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4545 - accuracy: 0.7799 - val_loss: 1.1607 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4438 - accuracy: 0.7923 - val_loss: 1.1600 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4450 - accuracy: 0.7867 - val_loss: 1.1176 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4356 - accuracy: 0.7981 - val_loss: 1.1494 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4406 - accuracy: 0.7938 - val_loss: 1.1617 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4486 - accuracy: 0.7865 - val_loss: 1.1729 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4545 - accuracy: 0.7840 - val_loss: 1.1023 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4480 - accuracy: 0.7855 - val_loss: 1.1265 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4482 - accuracy: 0.7900 - val_loss: 1.1430 - val_accuracy: 0.6208\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4438 - accuracy: 0.7921 - val_loss: 1.1006 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4510 - accuracy: 0.7885 - val_loss: 1.1832 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4433 - accuracy: 0.7870 - val_loss: 1.1434 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4464 - accuracy: 0.7893 - val_loss: 1.1441 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4422 - accuracy: 0.7916 - val_loss: 1.1142 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4447 - accuracy: 0.7878 - val_loss: 1.1065 - val_accuracy: 0.6208\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4369 - accuracy: 0.7951 - val_loss: 1.1473 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4352 - accuracy: 0.7974 - val_loss: 1.1940 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4300 - accuracy: 0.7984 - val_loss: 1.1813 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4311 - accuracy: 0.7979 - val_loss: 1.2227 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4441 - accuracy: 0.7916 - val_loss: 1.2509 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4463 - accuracy: 0.7860 - val_loss: 1.2222 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4558 - accuracy: 0.7840 - val_loss: 1.0690 - val_accuracy: 0.5935\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4641 - accuracy: 0.7749 - val_loss: 1.1526 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4833 - accuracy: 0.7761 - val_loss: 1.1585 - val_accuracy: 0.5895\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4730 - accuracy: 0.7736 - val_loss: 1.0963 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4630 - accuracy: 0.7814 - val_loss: 1.1063 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4822 - accuracy: 0.7665 - val_loss: 1.0593 - val_accuracy: 0.5885\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4760 - accuracy: 0.7700 - val_loss: 1.0869 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4619 - accuracy: 0.7814 - val_loss: 1.0906 - val_accuracy: 0.6218\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4510 - accuracy: 0.7870 - val_loss: 1.0912 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4481 - accuracy: 0.7847 - val_loss: 1.1034 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4431 - accuracy: 0.7921 - val_loss: 1.1322 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4413 - accuracy: 0.7898 - val_loss: 1.1185 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4387 - accuracy: 0.7900 - val_loss: 1.2066 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4394 - accuracy: 0.7895 - val_loss: 1.1952 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4364 - accuracy: 0.7946 - val_loss: 1.2185 - val_accuracy: 0.5966\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4458 - accuracy: 0.7870 - val_loss: 1.1281 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4434 - accuracy: 0.7918 - val_loss: 1.1153 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4523 - accuracy: 0.7842 - val_loss: 1.1950 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4509 - accuracy: 0.7870 - val_loss: 1.2302 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4472 - accuracy: 0.7936 - val_loss: 1.0969 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4414 - accuracy: 0.7936 - val_loss: 1.1508 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4412 - accuracy: 0.7918 - val_loss: 1.1705 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4434 - accuracy: 0.7878 - val_loss: 1.1710 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4421 - accuracy: 0.7898 - val_loss: 1.1522 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4434 - accuracy: 0.7905 - val_loss: 1.2007 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4469 - accuracy: 0.7885 - val_loss: 1.2563 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4540 - accuracy: 0.7809 - val_loss: 1.2200 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4506 - accuracy: 0.7910 - val_loss: 1.1787 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4710 - accuracy: 0.7711 - val_loss: 1.2170 - val_accuracy: 0.5814\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4602 - accuracy: 0.7797 - val_loss: 1.1300 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4545 - accuracy: 0.7865 - val_loss: 1.1868 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4574 - accuracy: 0.7781 - val_loss: 1.1665 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4504 - accuracy: 0.7913 - val_loss: 1.2059 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4627 - accuracy: 0.7756 - val_loss: 1.1521 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4789 - accuracy: 0.7688 - val_loss: 1.1896 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4928 - accuracy: 0.7592 - val_loss: 1.0797 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4713 - accuracy: 0.7754 - val_loss: 1.1483 - val_accuracy: 0.5986\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4638 - accuracy: 0.7779 - val_loss: 1.1023 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4564 - accuracy: 0.7870 - val_loss: 1.1478 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4454 - accuracy: 0.7926 - val_loss: 1.1503 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4427 - accuracy: 0.7908 - val_loss: 1.2267 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4478 - accuracy: 0.7867 - val_loss: 1.1619 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4505 - accuracy: 0.7850 - val_loss: 1.1177 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4463 - accuracy: 0.7893 - val_loss: 1.1484 - val_accuracy: 0.6198\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4435 - accuracy: 0.7910 - val_loss: 1.1358 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4418 - accuracy: 0.7878 - val_loss: 1.2035 - val_accuracy: 0.6188\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4448 - accuracy: 0.7883 - val_loss: 1.0774 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4564 - accuracy: 0.7860 - val_loss: 1.1646 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4415 - accuracy: 0.7890 - val_loss: 1.1154 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4420 - accuracy: 0.7905 - val_loss: 1.1043 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4452 - accuracy: 0.7900 - val_loss: 1.1435 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4412 - accuracy: 0.7913 - val_loss: 1.1382 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4427 - accuracy: 0.7928 - val_loss: 1.1503 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4350 - accuracy: 0.7969 - val_loss: 1.1047 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4306 - accuracy: 0.7994 - val_loss: 1.2192 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4353 - accuracy: 0.7931 - val_loss: 1.1538 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4533 - accuracy: 0.7829 - val_loss: 1.1381 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4599 - accuracy: 0.7852 - val_loss: 1.1919 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4567 - accuracy: 0.7814 - val_loss: 1.1337 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4439 - accuracy: 0.7888 - val_loss: 1.1922 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4444 - accuracy: 0.7900 - val_loss: 1.1240 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4525 - accuracy: 0.7883 - val_loss: 1.1348 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4498 - accuracy: 0.7867 - val_loss: 1.0955 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4409 - accuracy: 0.7946 - val_loss: 1.1521 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4381 - accuracy: 0.7941 - val_loss: 1.1457 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4401 - accuracy: 0.7890 - val_loss: 1.1893 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4350 - accuracy: 0.7941 - val_loss: 1.1454 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4366 - accuracy: 0.7999 - val_loss: 1.2054 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4350 - accuracy: 0.7933 - val_loss: 1.2018 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4412 - accuracy: 0.7905 - val_loss: 1.1564 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4343 - accuracy: 0.7974 - val_loss: 1.2858 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4536 - accuracy: 0.7852 - val_loss: 1.2066 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4464 - accuracy: 0.7855 - val_loss: 1.2351 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4631 - accuracy: 0.7766 - val_loss: 1.1735 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4477 - accuracy: 0.7890 - val_loss: 1.1518 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4444 - accuracy: 0.7888 - val_loss: 1.2254 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4661 - accuracy: 0.7781 - val_loss: 1.1275 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4648 - accuracy: 0.7774 - val_loss: 1.1289 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4598 - accuracy: 0.7867 - val_loss: 1.1541 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4469 - accuracy: 0.7900 - val_loss: 1.0716 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4446 - accuracy: 0.7895 - val_loss: 1.1719 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4554 - accuracy: 0.7847 - val_loss: 1.1407 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4437 - accuracy: 0.7910 - val_loss: 1.2220 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4518 - accuracy: 0.7873 - val_loss: 1.1427 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4593 - accuracy: 0.7817 - val_loss: 1.1387 - val_accuracy: 0.6178\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4407 - accuracy: 0.7946 - val_loss: 1.1196 - val_accuracy: 0.5976\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4493 - accuracy: 0.7905 - val_loss: 1.0693 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4438 - accuracy: 0.7883 - val_loss: 1.1015 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4460 - accuracy: 0.7888 - val_loss: 1.1109 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4498 - accuracy: 0.7903 - val_loss: 1.2332 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4399 - accuracy: 0.7903 - val_loss: 1.1713 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4468 - accuracy: 0.7880 - val_loss: 1.0976 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4468 - accuracy: 0.7913 - val_loss: 1.1963 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4420 - accuracy: 0.7905 - val_loss: 1.1789 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4446 - accuracy: 0.7895 - val_loss: 1.1059 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4925 - accuracy: 0.7655 - val_loss: 1.1080 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4577 - accuracy: 0.7837 - val_loss: 1.1479 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4431 - accuracy: 0.7936 - val_loss: 1.1792 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4379 - accuracy: 0.7964 - val_loss: 1.1593 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4479 - accuracy: 0.7923 - val_loss: 1.1806 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4419 - accuracy: 0.7908 - val_loss: 1.1713 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4590 - accuracy: 0.7829 - val_loss: 1.1125 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4827 - accuracy: 0.7733 - val_loss: 1.0750 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4874 - accuracy: 0.7647 - val_loss: 1.1146 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4731 - accuracy: 0.7736 - val_loss: 1.1209 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4489 - accuracy: 0.7903 - val_loss: 1.0563 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4434 - accuracy: 0.7964 - val_loss: 1.1006 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4458 - accuracy: 0.7867 - val_loss: 1.1491 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4414 - accuracy: 0.7953 - val_loss: 1.1832 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4554 - accuracy: 0.7852 - val_loss: 1.1678 - val_accuracy: 0.6229\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4404 - accuracy: 0.7900 - val_loss: 1.1802 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4527 - accuracy: 0.7888 - val_loss: 1.1458 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4670 - accuracy: 0.7746 - val_loss: 1.0760 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4535 - accuracy: 0.7873 - val_loss: 1.1495 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4402 - accuracy: 0.7905 - val_loss: 1.1831 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4389 - accuracy: 0.7928 - val_loss: 1.1422 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4327 - accuracy: 0.7979 - val_loss: 1.1166 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4432 - accuracy: 0.7923 - val_loss: 1.1584 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4368 - accuracy: 0.7948 - val_loss: 1.1740 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4452 - accuracy: 0.7893 - val_loss: 1.1527 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4402 - accuracy: 0.8009 - val_loss: 1.2076 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4364 - accuracy: 0.7916 - val_loss: 1.1872 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4346 - accuracy: 0.8027 - val_loss: 1.1483 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4379 - accuracy: 0.7953 - val_loss: 1.1681 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4316 - accuracy: 0.8012 - val_loss: 1.1336 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4398 - accuracy: 0.7926 - val_loss: 1.2212 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4469 - accuracy: 0.7845 - val_loss: 1.1699 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4442 - accuracy: 0.7883 - val_loss: 1.1715 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4447 - accuracy: 0.7951 - val_loss: 1.1966 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4661 - accuracy: 0.7797 - val_loss: 1.1999 - val_accuracy: 0.5895\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4660 - accuracy: 0.7733 - val_loss: 1.1589 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4602 - accuracy: 0.7812 - val_loss: 1.1495 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4541 - accuracy: 0.7855 - val_loss: 1.1868 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4431 - accuracy: 0.7961 - val_loss: 1.1275 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4324 - accuracy: 0.7974 - val_loss: 1.1919 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4316 - accuracy: 0.7966 - val_loss: 1.2407 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4316 - accuracy: 0.7989 - val_loss: 1.2103 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4297 - accuracy: 0.7999 - val_loss: 1.1592 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4347 - accuracy: 0.7994 - val_loss: 1.1716 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4385 - accuracy: 0.7948 - val_loss: 1.1730 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4463 - accuracy: 0.7893 - val_loss: 1.1602 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4503 - accuracy: 0.7931 - val_loss: 1.2065 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4354 - accuracy: 0.7989 - val_loss: 1.1722 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4477 - accuracy: 0.7867 - val_loss: 1.1795 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4441 - accuracy: 0.7867 - val_loss: 1.2190 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4375 - accuracy: 0.7964 - val_loss: 1.1924 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4413 - accuracy: 0.7895 - val_loss: 1.2774 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4500 - accuracy: 0.7855 - val_loss: 1.2343 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4472 - accuracy: 0.7900 - val_loss: 1.2112 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4427 - accuracy: 0.7885 - val_loss: 1.2034 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4748 - accuracy: 0.7690 - val_loss: 1.1295 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4721 - accuracy: 0.7713 - val_loss: 1.1128 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4587 - accuracy: 0.7804 - val_loss: 1.1546 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4400 - accuracy: 0.7918 - val_loss: 1.2173 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4378 - accuracy: 0.7913 - val_loss: 1.1843 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4475 - accuracy: 0.7903 - val_loss: 1.1311 - val_accuracy: 0.5996\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4464 - accuracy: 0.7946 - val_loss: 1.1262 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4371 - accuracy: 0.7941 - val_loss: 1.2192 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4379 - accuracy: 0.7928 - val_loss: 1.2742 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4426 - accuracy: 0.7921 - val_loss: 1.2151 - val_accuracy: 0.5915\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4882 - accuracy: 0.7663 - val_loss: 1.1656 - val_accuracy: 0.5602\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4863 - accuracy: 0.7655 - val_loss: 1.1985 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4533 - accuracy: 0.7847 - val_loss: 1.2175 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4459 - accuracy: 0.7938 - val_loss: 1.1994 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4326 - accuracy: 0.7989 - val_loss: 1.1958 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4353 - accuracy: 0.7981 - val_loss: 1.2686 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4362 - accuracy: 0.7948 - val_loss: 1.1980 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4364 - accuracy: 0.7903 - val_loss: 1.2664 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4351 - accuracy: 0.7918 - val_loss: 1.2135 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4359 - accuracy: 0.7946 - val_loss: 1.1845 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4345 - accuracy: 0.7971 - val_loss: 1.2130 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4338 - accuracy: 0.7981 - val_loss: 1.2027 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4324 - accuracy: 0.7943 - val_loss: 1.2540 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4294 - accuracy: 0.8017 - val_loss: 1.2378 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4317 - accuracy: 0.7938 - val_loss: 1.2424 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4371 - accuracy: 0.7948 - val_loss: 1.2134 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4373 - accuracy: 0.7931 - val_loss: 1.1854 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4379 - accuracy: 0.7956 - val_loss: 1.2221 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4333 - accuracy: 0.7969 - val_loss: 1.2220 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4362 - accuracy: 0.7936 - val_loss: 1.1861 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4578 - accuracy: 0.7789 - val_loss: 1.2022 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4504 - accuracy: 0.7905 - val_loss: 1.1905 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4804 - accuracy: 0.7731 - val_loss: 1.1890 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4740 - accuracy: 0.7683 - val_loss: 1.1675 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4531 - accuracy: 0.7862 - val_loss: 1.1680 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4512 - accuracy: 0.7840 - val_loss: 1.1444 - val_accuracy: 0.6208\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4463 - accuracy: 0.7941 - val_loss: 1.1617 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4419 - accuracy: 0.7918 - val_loss: 1.1348 - val_accuracy: 0.5905\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4451 - accuracy: 0.7898 - val_loss: 1.1101 - val_accuracy: 0.5895\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4523 - accuracy: 0.7860 - val_loss: 1.1984 - val_accuracy: 0.5814\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4525 - accuracy: 0.7865 - val_loss: 1.1116 - val_accuracy: 0.6249\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4417 - accuracy: 0.7923 - val_loss: 1.1666 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4332 - accuracy: 0.8002 - val_loss: 1.2344 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4352 - accuracy: 0.7956 - val_loss: 1.2379 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4272 - accuracy: 0.7999 - val_loss: 1.2087 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4252 - accuracy: 0.8022 - val_loss: 1.2156 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4293 - accuracy: 0.8019 - val_loss: 1.2400 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4337 - accuracy: 0.7979 - val_loss: 1.2368 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4354 - accuracy: 0.7916 - val_loss: 1.2508 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4331 - accuracy: 0.7943 - val_loss: 1.2499 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4302 - accuracy: 0.8004 - val_loss: 1.3292 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4387 - accuracy: 0.7928 - val_loss: 1.2890 - val_accuracy: 0.6239\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4453 - accuracy: 0.7867 - val_loss: 1.2021 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4313 - accuracy: 0.7971 - val_loss: 1.1714 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4335 - accuracy: 0.7936 - val_loss: 1.1859 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4448 - accuracy: 0.7926 - val_loss: 1.1450 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4463 - accuracy: 0.7873 - val_loss: 1.2432 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4617 - accuracy: 0.7789 - val_loss: 1.1688 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4619 - accuracy: 0.7807 - val_loss: 1.1991 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4528 - accuracy: 0.7857 - val_loss: 1.1860 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4342 - accuracy: 0.8004 - val_loss: 1.2389 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4424 - accuracy: 0.7910 - val_loss: 1.2121 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4482 - accuracy: 0.7931 - val_loss: 1.2375 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4416 - accuracy: 0.7890 - val_loss: 1.2708 - val_accuracy: 0.6198\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4455 - accuracy: 0.7898 - val_loss: 1.2089 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4418 - accuracy: 0.7867 - val_loss: 1.2078 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4608 - accuracy: 0.7799 - val_loss: 1.2215 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4417 - accuracy: 0.7908 - val_loss: 1.1663 - val_accuracy: 0.6208\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4420 - accuracy: 0.7908 - val_loss: 1.1957 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 46us/sample - loss: 0.4439 - accuracy: 0.7931 - val_loss: 1.1890 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4365 - accuracy: 0.7931 - val_loss: 1.2513 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4389 - accuracy: 0.7941 - val_loss: 1.2231 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4391 - accuracy: 0.7923 - val_loss: 1.1896 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4472 - accuracy: 0.7908 - val_loss: 1.1503 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4426 - accuracy: 0.7905 - val_loss: 1.2254 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4425 - accuracy: 0.7913 - val_loss: 1.2224 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4508 - accuracy: 0.7878 - val_loss: 1.1318 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4630 - accuracy: 0.7817 - val_loss: 1.1845 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4701 - accuracy: 0.7789 - val_loss: 1.1768 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4488 - accuracy: 0.7893 - val_loss: 1.1411 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4502 - accuracy: 0.7900 - val_loss: 1.1728 - val_accuracy: 0.5986\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4416 - accuracy: 0.7913 - val_loss: 1.1276 - val_accuracy: 0.6188\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4329 - accuracy: 0.7961 - val_loss: 1.1080 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4411 - accuracy: 0.7867 - val_loss: 1.1954 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4373 - accuracy: 0.8002 - val_loss: 1.1608 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4614 - accuracy: 0.7759 - val_loss: 1.1768 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4570 - accuracy: 0.7771 - val_loss: 1.1097 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4362 - accuracy: 0.7938 - val_loss: 1.1765 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4356 - accuracy: 0.7991 - val_loss: 1.1345 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4410 - accuracy: 0.7948 - val_loss: 1.1406 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4546 - accuracy: 0.7822 - val_loss: 1.1254 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4440 - accuracy: 0.7898 - val_loss: 1.1846 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4453 - accuracy: 0.7870 - val_loss: 1.1987 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4374 - accuracy: 0.7916 - val_loss: 1.1830 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4299 - accuracy: 0.7999 - val_loss: 1.1471 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4329 - accuracy: 0.7953 - val_loss: 1.1697 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4362 - accuracy: 0.7943 - val_loss: 1.1903 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4447 - accuracy: 0.7941 - val_loss: 1.1841 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4431 - accuracy: 0.7916 - val_loss: 1.1636 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4415 - accuracy: 0.7948 - val_loss: 1.1825 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4402 - accuracy: 0.7928 - val_loss: 1.1022 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4325 - accuracy: 0.7999 - val_loss: 1.1841 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4429 - accuracy: 0.7890 - val_loss: 1.2205 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4388 - accuracy: 0.7941 - val_loss: 1.1902 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4363 - accuracy: 0.7959 - val_loss: 1.1844 - val_accuracy: 0.6229\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4344 - accuracy: 0.7943 - val_loss: 1.1273 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4310 - accuracy: 0.7979 - val_loss: 1.2453 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4309 - accuracy: 0.7951 - val_loss: 1.2157 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4463 - accuracy: 0.7895 - val_loss: 1.1727 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4539 - accuracy: 0.7840 - val_loss: 1.2085 - val_accuracy: 0.6239\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4489 - accuracy: 0.7842 - val_loss: 1.1316 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4684 - accuracy: 0.7766 - val_loss: 1.1570 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4629 - accuracy: 0.7817 - val_loss: 1.1528 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4413 - accuracy: 0.7900 - val_loss: 1.2318 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4391 - accuracy: 0.7921 - val_loss: 1.2476 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4360 - accuracy: 0.7918 - val_loss: 1.1711 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4374 - accuracy: 0.7880 - val_loss: 1.1838 - val_accuracy: 0.6229\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4327 - accuracy: 0.7905 - val_loss: 1.1843 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4348 - accuracy: 0.7961 - val_loss: 1.1813 - val_accuracy: 0.6188\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4351 - accuracy: 0.7994 - val_loss: 1.1956 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4362 - accuracy: 0.7964 - val_loss: 1.1498 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4440 - accuracy: 0.7883 - val_loss: 1.2356 - val_accuracy: 0.6208\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4454 - accuracy: 0.7862 - val_loss: 1.1878 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4539 - accuracy: 0.7845 - val_loss: 1.2182 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4538 - accuracy: 0.7862 - val_loss: 1.1677 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4333 - accuracy: 0.7956 - val_loss: 1.1952 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4346 - accuracy: 0.7999 - val_loss: 1.2327 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4276 - accuracy: 0.7989 - val_loss: 1.2749 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4423 - accuracy: 0.7941 - val_loss: 1.2098 - val_accuracy: 0.5925\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4560 - accuracy: 0.7824 - val_loss: 1.2469 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4636 - accuracy: 0.7814 - val_loss: 1.1971 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4462 - accuracy: 0.7938 - val_loss: 1.1671 - val_accuracy: 0.6188\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4367 - accuracy: 0.7986 - val_loss: 1.2252 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4350 - accuracy: 0.7938 - val_loss: 1.1928 - val_accuracy: 0.6178\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4345 - accuracy: 0.7941 - val_loss: 1.2499 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4391 - accuracy: 0.7953 - val_loss: 1.2025 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4364 - accuracy: 0.7910 - val_loss: 1.2438 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4302 - accuracy: 0.7926 - val_loss: 1.2434 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4397 - accuracy: 0.7964 - val_loss: 1.2127 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4304 - accuracy: 0.7999 - val_loss: 1.2906 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4367 - accuracy: 0.7890 - val_loss: 1.1791 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4373 - accuracy: 0.7953 - val_loss: 1.1944 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4414 - accuracy: 0.7931 - val_loss: 1.2052 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4395 - accuracy: 0.7910 - val_loss: 1.2336 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4448 - accuracy: 0.7910 - val_loss: 1.2421 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4533 - accuracy: 0.7885 - val_loss: 1.2135 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4389 - accuracy: 0.7916 - val_loss: 1.2307 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 44us/sample - loss: 0.4396 - accuracy: 0.7916 - val_loss: 1.1669 - val_accuracy: 0.6077\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4275 - accuracy: 0.7999 - val_loss: 1.2174 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4395 - accuracy: 0.7923 - val_loss: 1.2019 - val_accuracy: 0.6188\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4371 - accuracy: 0.7903 - val_loss: 1.1715 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4485 - accuracy: 0.7893 - val_loss: 1.2203 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4561 - accuracy: 0.7786 - val_loss: 1.2439 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4825 - accuracy: 0.7698 - val_loss: 1.1450 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4651 - accuracy: 0.7769 - val_loss: 1.1783 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4488 - accuracy: 0.7898 - val_loss: 1.1831 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4376 - accuracy: 0.7953 - val_loss: 1.1988 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4276 - accuracy: 0.7989 - val_loss: 1.2653 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4317 - accuracy: 0.8017 - val_loss: 1.2294 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4330 - accuracy: 0.7976 - val_loss: 1.2187 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4372 - accuracy: 0.7964 - val_loss: 1.2379 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4449 - accuracy: 0.7905 - val_loss: 1.1837 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4438 - accuracy: 0.7956 - val_loss: 1.1938 - val_accuracy: 0.6320\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4377 - accuracy: 0.7928 - val_loss: 1.0796 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4469 - accuracy: 0.7921 - val_loss: 1.1721 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4669 - accuracy: 0.7792 - val_loss: 1.1501 - val_accuracy: 0.5844\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4655 - accuracy: 0.7829 - val_loss: 1.2015 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4568 - accuracy: 0.7840 - val_loss: 1.1656 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4529 - accuracy: 0.7809 - val_loss: 1.2014 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4373 - accuracy: 0.7961 - val_loss: 1.1961 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4282 - accuracy: 0.8012 - val_loss: 1.1638 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4326 - accuracy: 0.7966 - val_loss: 1.1382 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4325 - accuracy: 0.8017 - val_loss: 1.1447 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4336 - accuracy: 0.7969 - val_loss: 1.2525 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4405 - accuracy: 0.7948 - val_loss: 1.1794 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4456 - accuracy: 0.7916 - val_loss: 1.2224 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4359 - accuracy: 0.7936 - val_loss: 1.2087 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4292 - accuracy: 0.8012 - val_loss: 1.2070 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4324 - accuracy: 0.7976 - val_loss: 1.1468 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4338 - accuracy: 0.7956 - val_loss: 1.2266 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4279 - accuracy: 0.7986 - val_loss: 1.2749 - val_accuracy: 0.6208\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4266 - accuracy: 0.7999 - val_loss: 1.2731 - val_accuracy: 0.6158\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4321 - accuracy: 0.7989 - val_loss: 1.1932 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4433 - accuracy: 0.7933 - val_loss: 1.2047 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4341 - accuracy: 0.7969 - val_loss: 1.1888 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4307 - accuracy: 0.7974 - val_loss: 1.2877 - val_accuracy: 0.6188\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4227 - accuracy: 0.8042 - val_loss: 1.1892 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4380 - accuracy: 0.7921 - val_loss: 1.1617 - val_accuracy: 0.6229\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4327 - accuracy: 0.7986 - val_loss: 1.2159 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4377 - accuracy: 0.7936 - val_loss: 1.1607 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4513 - accuracy: 0.7847 - val_loss: 1.1997 - val_accuracy: 0.5966\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4494 - accuracy: 0.7880 - val_loss: 1.2261 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4624 - accuracy: 0.7807 - val_loss: 1.1986 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4495 - accuracy: 0.7908 - val_loss: 1.1673 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4391 - accuracy: 0.7959 - val_loss: 1.1642 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4330 - accuracy: 0.8034 - val_loss: 1.2424 - val_accuracy: 0.6208\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4262 - accuracy: 0.7971 - val_loss: 1.2194 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4358 - accuracy: 0.7981 - val_loss: 1.2358 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4972 - accuracy: 0.7551 - val_loss: 1.1364 - val_accuracy: 0.5753\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4765 - accuracy: 0.7693 - val_loss: 1.0589 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4515 - accuracy: 0.7893 - val_loss: 1.2193 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4478 - accuracy: 0.7875 - val_loss: 1.1484 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4589 - accuracy: 0.7814 - val_loss: 1.1990 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4486 - accuracy: 0.7893 - val_loss: 1.1203 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4358 - accuracy: 0.7996 - val_loss: 1.1541 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4321 - accuracy: 0.7991 - val_loss: 1.1420 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4343 - accuracy: 0.7918 - val_loss: 1.1934 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4280 - accuracy: 0.8017 - val_loss: 1.2160 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4353 - accuracy: 0.7948 - val_loss: 1.1894 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4379 - accuracy: 0.7921 - val_loss: 1.2567 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4382 - accuracy: 0.7961 - val_loss: 1.1622 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4429 - accuracy: 0.7885 - val_loss: 1.1205 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4490 - accuracy: 0.7893 - val_loss: 1.2397 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4393 - accuracy: 0.7903 - val_loss: 1.1725 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4305 - accuracy: 0.7984 - val_loss: 1.2230 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4243 - accuracy: 0.8070 - val_loss: 1.2187 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4300 - accuracy: 0.8002 - val_loss: 1.2152 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4327 - accuracy: 0.7976 - val_loss: 1.1670 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4261 - accuracy: 0.7979 - val_loss: 1.1899 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4294 - accuracy: 0.7964 - val_loss: 1.1838 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4257 - accuracy: 0.8037 - val_loss: 1.2019 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4323 - accuracy: 0.7941 - val_loss: 1.1360 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4352 - accuracy: 0.7941 - val_loss: 1.2466 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4362 - accuracy: 0.7913 - val_loss: 1.2336 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4488 - accuracy: 0.7860 - val_loss: 1.2787 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4510 - accuracy: 0.7873 - val_loss: 1.2102 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4496 - accuracy: 0.7893 - val_loss: 1.2519 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4545 - accuracy: 0.7845 - val_loss: 1.1978 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4618 - accuracy: 0.7817 - val_loss: 1.1447 - val_accuracy: 0.5935\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4425 - accuracy: 0.7898 - val_loss: 1.2362 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4344 - accuracy: 0.7948 - val_loss: 1.2450 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4417 - accuracy: 0.7898 - val_loss: 1.1981 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4382 - accuracy: 0.7941 - val_loss: 1.2373 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4341 - accuracy: 0.7941 - val_loss: 1.2425 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4390 - accuracy: 0.7885 - val_loss: 1.2474 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 49us/sample - loss: 0.4390 - accuracy: 0.7888 - val_loss: 1.2517 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4273 - accuracy: 0.8014 - val_loss: 1.2489 - val_accuracy: 0.6218\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4372 - accuracy: 0.7951 - val_loss: 1.1561 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4360 - accuracy: 0.7928 - val_loss: 1.2105 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4282 - accuracy: 0.7989 - val_loss: 1.2718 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4383 - accuracy: 0.7903 - val_loss: 1.1270 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4438 - accuracy: 0.7938 - val_loss: 1.2162 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4518 - accuracy: 0.7837 - val_loss: 1.1767 - val_accuracy: 0.6188\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4436 - accuracy: 0.7953 - val_loss: 1.2305 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4499 - accuracy: 0.7870 - val_loss: 1.2445 - val_accuracy: 0.5865\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4515 - accuracy: 0.7870 - val_loss: 1.1939 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4558 - accuracy: 0.7799 - val_loss: 1.2049 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4354 - accuracy: 0.7981 - val_loss: 1.2185 - val_accuracy: 0.6208\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4431 - accuracy: 0.7916 - val_loss: 1.2076 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4447 - accuracy: 0.7941 - val_loss: 1.1534 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4396 - accuracy: 0.7971 - val_loss: 1.1649 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4345 - accuracy: 0.8007 - val_loss: 1.2224 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4318 - accuracy: 0.8007 - val_loss: 1.2120 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4301 - accuracy: 0.7971 - val_loss: 1.2584 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4317 - accuracy: 0.7989 - val_loss: 1.2230 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4267 - accuracy: 0.7991 - val_loss: 1.2643 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4286 - accuracy: 0.7999 - val_loss: 1.1973 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4372 - accuracy: 0.7926 - val_loss: 1.2252 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4360 - accuracy: 0.7959 - val_loss: 1.2501 - val_accuracy: 0.5976\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4415 - accuracy: 0.7867 - val_loss: 1.2341 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4411 - accuracy: 0.7873 - val_loss: 1.2478 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4491 - accuracy: 0.7898 - val_loss: 1.1983 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4380 - accuracy: 0.7941 - val_loss: 1.1524 - val_accuracy: 0.5956\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4529 - accuracy: 0.7840 - val_loss: 1.1840 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4339 - accuracy: 0.7971 - val_loss: 1.2725 - val_accuracy: 0.6229\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4352 - accuracy: 0.7994 - val_loss: 1.1644 - val_accuracy: 0.6107\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4672 - accuracy: 0.7764 - val_loss: 1.1602 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4500 - accuracy: 0.7867 - val_loss: 1.2229 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4561 - accuracy: 0.7862 - val_loss: 1.1656 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4409 - accuracy: 0.7959 - val_loss: 1.1289 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4454 - accuracy: 0.7964 - val_loss: 1.1879 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4382 - accuracy: 0.7976 - val_loss: 1.1822 - val_accuracy: 0.6208\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4326 - accuracy: 0.7979 - val_loss: 1.1831 - val_accuracy: 0.6249\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4464 - accuracy: 0.7908 - val_loss: 1.2333 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4365 - accuracy: 0.7943 - val_loss: 1.1819 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4441 - accuracy: 0.7865 - val_loss: 1.2187 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4256 - accuracy: 0.8032 - val_loss: 1.1938 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4290 - accuracy: 0.7999 - val_loss: 1.2033 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4271 - accuracy: 0.8017 - val_loss: 1.2853 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4308 - accuracy: 0.7994 - val_loss: 1.2639 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4297 - accuracy: 0.8032 - val_loss: 1.2491 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4307 - accuracy: 0.8007 - val_loss: 1.2455 - val_accuracy: 0.6198\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4276 - accuracy: 0.7976 - val_loss: 1.1938 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4417 - accuracy: 0.7936 - val_loss: 1.1809 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4491 - accuracy: 0.7786 - val_loss: 1.2012 - val_accuracy: 0.5935\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4526 - accuracy: 0.7878 - val_loss: 1.2504 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4402 - accuracy: 0.7969 - val_loss: 1.1813 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4323 - accuracy: 0.8002 - val_loss: 1.2124 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4276 - accuracy: 0.8057 - val_loss: 1.1576 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4267 - accuracy: 0.8022 - val_loss: 1.2465 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4295 - accuracy: 0.8024 - val_loss: 1.2605 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4347 - accuracy: 0.7951 - val_loss: 1.2429 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4355 - accuracy: 0.7941 - val_loss: 1.2105 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4391 - accuracy: 0.7921 - val_loss: 1.2080 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4346 - accuracy: 0.7991 - val_loss: 1.1718 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.5026 - accuracy: 0.7599 - val_loss: 1.0788 - val_accuracy: 0.5905\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.5083 - accuracy: 0.7602 - val_loss: 1.1285 - val_accuracy: 0.5854\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4722 - accuracy: 0.7751 - val_loss: 1.0949 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4384 - accuracy: 0.7976 - val_loss: 1.1454 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 46us/sample - loss: 0.4270 - accuracy: 0.7971 - val_loss: 1.1704 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4235 - accuracy: 0.8065 - val_loss: 1.2086 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4243 - accuracy: 0.8019 - val_loss: 1.1772 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4214 - accuracy: 0.8039 - val_loss: 1.2095 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4271 - accuracy: 0.7969 - val_loss: 1.1336 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4329 - accuracy: 0.7979 - val_loss: 1.1918 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4591 - accuracy: 0.7847 - val_loss: 1.1626 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4425 - accuracy: 0.7910 - val_loss: 1.1726 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4292 - accuracy: 0.8032 - val_loss: 1.2153 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4267 - accuracy: 0.7974 - val_loss: 1.2671 - val_accuracy: 0.6158\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4280 - accuracy: 0.8004 - val_loss: 1.2100 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4439 - accuracy: 0.7933 - val_loss: 1.2306 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4473 - accuracy: 0.7900 - val_loss: 1.2152 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4389 - accuracy: 0.7903 - val_loss: 1.2192 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4376 - accuracy: 0.7916 - val_loss: 1.1893 - val_accuracy: 0.6087\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4326 - accuracy: 0.7946 - val_loss: 1.2578 - val_accuracy: 0.6026\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4726 - accuracy: 0.7776 - val_loss: 1.0746 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4474 - accuracy: 0.7888 - val_loss: 1.1331 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4350 - accuracy: 0.7974 - val_loss: 1.1216 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4387 - accuracy: 0.7931 - val_loss: 1.2225 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4463 - accuracy: 0.7888 - val_loss: 1.2132 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4431 - accuracy: 0.7921 - val_loss: 1.2105 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4404 - accuracy: 0.7936 - val_loss: 1.2530 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4429 - accuracy: 0.7941 - val_loss: 1.2123 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4393 - accuracy: 0.7953 - val_loss: 1.2143 - val_accuracy: 0.6178\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4415 - accuracy: 0.7913 - val_loss: 1.1858 - val_accuracy: 0.6067\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4692 - accuracy: 0.7769 - val_loss: 1.1396 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4689 - accuracy: 0.7759 - val_loss: 1.1399 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4513 - accuracy: 0.7875 - val_loss: 1.2323 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4445 - accuracy: 0.7913 - val_loss: 1.1759 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4294 - accuracy: 0.7999 - val_loss: 1.2137 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4303 - accuracy: 0.7951 - val_loss: 1.2083 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4212 - accuracy: 0.8029 - val_loss: 1.1514 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4237 - accuracy: 0.8027 - val_loss: 1.2332 - val_accuracy: 0.5976\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4218 - accuracy: 0.8029 - val_loss: 1.2372 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4280 - accuracy: 0.7964 - val_loss: 1.1928 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4462 - accuracy: 0.7948 - val_loss: 1.2443 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4307 - accuracy: 0.7956 - val_loss: 1.1790 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4407 - accuracy: 0.7903 - val_loss: 1.2575 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4375 - accuracy: 0.7936 - val_loss: 1.2014 - val_accuracy: 0.6208\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4353 - accuracy: 0.7948 - val_loss: 1.2000 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4365 - accuracy: 0.7946 - val_loss: 1.2411 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4419 - accuracy: 0.7916 - val_loss: 1.1741 - val_accuracy: 0.6239\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4398 - accuracy: 0.7913 - val_loss: 1.2053 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4249 - accuracy: 0.8002 - val_loss: 1.1656 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4215 - accuracy: 0.8019 - val_loss: 1.2526 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4355 - accuracy: 0.7979 - val_loss: 1.1989 - val_accuracy: 0.6208\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4296 - accuracy: 0.7979 - val_loss: 1.1521 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4522 - accuracy: 0.7865 - val_loss: 1.1436 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4394 - accuracy: 0.7916 - val_loss: 1.1390 - val_accuracy: 0.6198\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4295 - accuracy: 0.7979 - val_loss: 1.2315 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4452 - accuracy: 0.7926 - val_loss: 1.1951 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4303 - accuracy: 0.7984 - val_loss: 1.2648 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4433 - accuracy: 0.7888 - val_loss: 1.2203 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4337 - accuracy: 0.7938 - val_loss: 1.2498 - val_accuracy: 0.6249\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4449 - accuracy: 0.7865 - val_loss: 1.1644 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4696 - accuracy: 0.7769 - val_loss: 1.1319 - val_accuracy: 0.5804\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4621 - accuracy: 0.7781 - val_loss: 1.2809 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4413 - accuracy: 0.7910 - val_loss: 1.2305 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4415 - accuracy: 0.7946 - val_loss: 1.2436 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4333 - accuracy: 0.7994 - val_loss: 1.2138 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4349 - accuracy: 0.7933 - val_loss: 1.2399 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4253 - accuracy: 0.8009 - val_loss: 1.2439 - val_accuracy: 0.6188\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4364 - accuracy: 0.7959 - val_loss: 1.2065 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4320 - accuracy: 0.8002 - val_loss: 1.2695 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4273 - accuracy: 0.8012 - val_loss: 1.2204 - val_accuracy: 0.6178\nEpoch 4/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4262 - accuracy: 0.8037 - val_loss: 1.2032 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4184 - accuracy: 0.8042 - val_loss: 1.2310 - val_accuracy: 0.6229\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4173 - accuracy: 0.8042 - val_loss: 1.1864 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4206 - accuracy: 0.8062 - val_loss: 1.2351 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4225 - accuracy: 0.8014 - val_loss: 1.3006 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4262 - accuracy: 0.7971 - val_loss: 1.2378 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4256 - accuracy: 0.8032 - val_loss: 1.2026 - val_accuracy: 0.6168\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4232 - accuracy: 0.8039 - val_loss: 1.2544 - val_accuracy: 0.6158\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4316 - accuracy: 0.7938 - val_loss: 1.2414 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4350 - accuracy: 0.7989 - val_loss: 1.1510 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4278 - accuracy: 0.8012 - val_loss: 1.2279 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4370 - accuracy: 0.7966 - val_loss: 1.1829 - val_accuracy: 0.6208\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4593 - accuracy: 0.7799 - val_loss: 1.2036 - val_accuracy: 0.6036\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4631 - accuracy: 0.7743 - val_loss: 1.1947 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4517 - accuracy: 0.7845 - val_loss: 1.1798 - val_accuracy: 0.5925\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4404 - accuracy: 0.7908 - val_loss: 1.1680 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4394 - accuracy: 0.7936 - val_loss: 1.2126 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4311 - accuracy: 0.7986 - val_loss: 1.1893 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4307 - accuracy: 0.7981 - val_loss: 1.2807 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4281 - accuracy: 0.7994 - val_loss: 1.1791 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4311 - accuracy: 0.7961 - val_loss: 1.2638 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4679 - accuracy: 0.7769 - val_loss: 1.1716 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4695 - accuracy: 0.7749 - val_loss: 1.1240 - val_accuracy: 0.5925\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4530 - accuracy: 0.7804 - val_loss: 1.1877 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4400 - accuracy: 0.7943 - val_loss: 1.1483 - val_accuracy: 0.6077\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4288 - accuracy: 0.8034 - val_loss: 1.1819 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4252 - accuracy: 0.8029 - val_loss: 1.2093 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4241 - accuracy: 0.8024 - val_loss: 1.1675 - val_accuracy: 0.6188\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4269 - accuracy: 0.8007 - val_loss: 1.2517 - val_accuracy: 0.6208\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4303 - accuracy: 0.8014 - val_loss: 1.1633 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4397 - accuracy: 0.7943 - val_loss: 1.1703 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4491 - accuracy: 0.7852 - val_loss: 1.2425 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4330 - accuracy: 0.8009 - val_loss: 1.2224 - val_accuracy: 0.5986\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4263 - accuracy: 0.8032 - val_loss: 1.1877 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4269 - accuracy: 0.8002 - val_loss: 1.2409 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4276 - accuracy: 0.8024 - val_loss: 1.2514 - val_accuracy: 0.6148\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4370 - accuracy: 0.7951 - val_loss: 1.1795 - val_accuracy: 0.6208\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 37us/sample - loss: 0.4272 - accuracy: 0.8014 - val_loss: 1.1986 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4309 - accuracy: 0.7974 - val_loss: 1.2405 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4500 - accuracy: 0.7923 - val_loss: 1.1968 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4505 - accuracy: 0.7860 - val_loss: 1.1623 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4555 - accuracy: 0.7865 - val_loss: 1.1652 - val_accuracy: 0.6016\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4469 - accuracy: 0.7883 - val_loss: 1.2308 - val_accuracy: 0.6006\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4589 - accuracy: 0.7779 - val_loss: 1.1871 - val_accuracy: 0.6107\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4374 - accuracy: 0.7936 - val_loss: 1.1675 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4330 - accuracy: 0.7956 - val_loss: 1.2415 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4280 - accuracy: 0.8004 - val_loss: 1.1964 - val_accuracy: 0.5915\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4263 - accuracy: 0.7979 - val_loss: 1.2329 - val_accuracy: 0.6067\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4242 - accuracy: 0.8024 - val_loss: 1.2401 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4403 - accuracy: 0.7971 - val_loss: 1.1751 - val_accuracy: 0.5956\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4453 - accuracy: 0.7921 - val_loss: 1.1949 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4329 - accuracy: 0.8012 - val_loss: 1.2375 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4286 - accuracy: 0.7994 - val_loss: 1.2324 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4220 - accuracy: 0.8062 - val_loss: 1.2127 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4259 - accuracy: 0.8027 - val_loss: 1.2673 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4406 - accuracy: 0.7956 - val_loss: 1.2175 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4270 - accuracy: 0.8017 - val_loss: 1.1617 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4472 - accuracy: 0.7852 - val_loss: 1.1712 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4471 - accuracy: 0.7908 - val_loss: 1.1459 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4426 - accuracy: 0.7895 - val_loss: 1.1640 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4363 - accuracy: 0.7959 - val_loss: 1.2228 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4290 - accuracy: 0.7999 - val_loss: 1.2046 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4240 - accuracy: 0.8034 - val_loss: 1.2313 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4320 - accuracy: 0.7981 - val_loss: 1.2174 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4487 - accuracy: 0.7860 - val_loss: 1.1631 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4485 - accuracy: 0.7875 - val_loss: 1.2288 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4307 - accuracy: 0.7996 - val_loss: 1.1761 - val_accuracy: 0.5945\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4262 - accuracy: 0.8019 - val_loss: 1.1951 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4299 - accuracy: 0.7979 - val_loss: 1.2543 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4421 - accuracy: 0.7921 - val_loss: 1.1836 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4358 - accuracy: 0.7971 - val_loss: 1.1606 - val_accuracy: 0.6178\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4377 - accuracy: 0.7959 - val_loss: 1.1921 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4293 - accuracy: 0.7981 - val_loss: 1.2203 - val_accuracy: 0.6127\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4279 - accuracy: 0.8009 - val_loss: 1.2435 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4383 - accuracy: 0.7996 - val_loss: 1.1707 - val_accuracy: 0.5986\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4366 - accuracy: 0.7964 - val_loss: 1.2097 - val_accuracy: 0.6057\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4316 - accuracy: 0.7956 - val_loss: 1.2437 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4323 - accuracy: 0.8002 - val_loss: 1.2042 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4247 - accuracy: 0.8022 - val_loss: 1.2153 - val_accuracy: 0.6188\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4338 - accuracy: 0.7961 - val_loss: 1.1833 - val_accuracy: 0.6127\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4449 - accuracy: 0.7893 - val_loss: 1.2089 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4544 - accuracy: 0.7837 - val_loss: 1.2264 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4391 - accuracy: 0.7913 - val_loss: 1.2095 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4254 - accuracy: 0.8014 - val_loss: 1.1934 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4209 - accuracy: 0.8012 - val_loss: 1.2302 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4326 - accuracy: 0.7984 - val_loss: 1.1533 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4266 - accuracy: 0.8009 - val_loss: 1.2232 - val_accuracy: 0.6026\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4335 - accuracy: 0.7964 - val_loss: 1.2563 - val_accuracy: 0.6178\nEpoch 2/5\n3953/3953 [==============================] - 0s 43us/sample - loss: 0.4483 - accuracy: 0.7895 - val_loss: 1.2673 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4336 - accuracy: 0.7999 - val_loss: 1.2487 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4253 - accuracy: 0.8004 - val_loss: 1.2376 - val_accuracy: 0.6168\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4325 - accuracy: 0.7941 - val_loss: 1.2436 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4274 - accuracy: 0.8039 - val_loss: 1.2307 - val_accuracy: 0.6138\nEpoch 2/5\n3953/3953 [==============================] - 0s 47us/sample - loss: 0.4294 - accuracy: 0.7964 - val_loss: 1.1913 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 42us/sample - loss: 0.4238 - accuracy: 0.8027 - val_loss: 1.2896 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 41us/sample - loss: 0.4238 - accuracy: 0.8009 - val_loss: 1.2519 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 39us/sample - loss: 0.4229 - accuracy: 0.8032 - val_loss: 1.2868 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4268 - accuracy: 0.7974 - val_loss: 1.2456 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 40us/sample - loss: 0.4351 - accuracy: 0.7943 - val_loss: 1.2199 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 38us/sample - loss: 0.4396 - accuracy: 0.7966 - val_loss: 1.2213 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4315 - accuracy: 0.7971 - val_loss: 1.2033 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4272 - accuracy: 0.7956 - val_loss: 1.1938 - val_accuracy: 0.6117\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4272 - accuracy: 0.8009 - val_loss: 1.3124 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4230 - accuracy: 0.8050 - val_loss: 1.1879 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4330 - accuracy: 0.7959 - val_loss: 1.2508 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4291 - accuracy: 0.7974 - val_loss: 1.1947 - val_accuracy: 0.6006\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4545 - accuracy: 0.7812 - val_loss: 1.1838 - val_accuracy: 0.6036\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4388 - accuracy: 0.7931 - val_loss: 1.1815 - val_accuracy: 0.6087\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4465 - accuracy: 0.7910 - val_loss: 1.1569 - val_accuracy: 0.6057\nEpoch 3/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4366 - accuracy: 0.7961 - val_loss: 1.2422 - val_accuracy: 0.6107\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4342 - accuracy: 0.7969 - val_loss: 1.1882 - val_accuracy: 0.5945\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.5082 - accuracy: 0.7574 - val_loss: 1.1298 - val_accuracy: 0.5966\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4892 - accuracy: 0.7668 - val_loss: 1.1202 - val_accuracy: 0.5966\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4804 - accuracy: 0.7693 - val_loss: 1.0811 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4560 - accuracy: 0.7817 - val_loss: 1.1535 - val_accuracy: 0.6097\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4347 - accuracy: 0.8027 - val_loss: 1.1420 - val_accuracy: 0.6218\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4265 - accuracy: 0.8022 - val_loss: 1.2009 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4220 - accuracy: 0.8039 - val_loss: 1.2143 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4268 - accuracy: 0.8009 - val_loss: 1.2318 - val_accuracy: 0.6117\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4264 - accuracy: 0.8037 - val_loss: 1.2469 - val_accuracy: 0.6178\nEpoch 4/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4332 - accuracy: 0.8009 - val_loss: 1.2532 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4280 - accuracy: 0.7989 - val_loss: 1.2069 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4251 - accuracy: 0.8032 - val_loss: 1.2007 - val_accuracy: 0.6016\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4315 - accuracy: 0.7976 - val_loss: 1.2151 - val_accuracy: 0.6148\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4386 - accuracy: 0.7916 - val_loss: 1.2379 - val_accuracy: 0.6168\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4536 - accuracy: 0.7865 - val_loss: 1.2590 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4361 - accuracy: 0.7938 - val_loss: 1.2047 - val_accuracy: 0.6239\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4316 - accuracy: 0.7994 - val_loss: 1.2016 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4244 - accuracy: 0.7984 - val_loss: 1.2358 - val_accuracy: 0.6016\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4240 - accuracy: 0.8047 - val_loss: 1.2497 - val_accuracy: 0.6198\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4209 - accuracy: 0.8027 - val_loss: 1.2406 - val_accuracy: 0.6239\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4241 - accuracy: 0.8067 - val_loss: 1.2414 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4272 - accuracy: 0.7991 - val_loss: 1.2022 - val_accuracy: 0.6168\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4270 - accuracy: 0.7991 - val_loss: 1.1979 - val_accuracy: 0.6178\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4353 - accuracy: 0.7953 - val_loss: 1.2422 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4236 - accuracy: 0.7986 - val_loss: 1.2389 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4256 - accuracy: 0.8017 - val_loss: 1.2147 - val_accuracy: 0.6006\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4386 - accuracy: 0.7928 - val_loss: 1.2874 - val_accuracy: 0.6047\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4271 - accuracy: 0.8014 - val_loss: 1.3401 - val_accuracy: 0.5996\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4188 - accuracy: 0.8042 - val_loss: 1.2899 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4242 - accuracy: 0.8017 - val_loss: 1.3786 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4333 - accuracy: 0.7951 - val_loss: 1.2541 - val_accuracy: 0.6097\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4265 - accuracy: 0.7991 - val_loss: 1.2507 - val_accuracy: 0.6057\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4387 - accuracy: 0.7936 - val_loss: 1.2820 - val_accuracy: 0.5986\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4416 - accuracy: 0.7903 - val_loss: 1.2696 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4399 - accuracy: 0.7966 - val_loss: 1.2291 - val_accuracy: 0.6158\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4354 - accuracy: 0.7971 - val_loss: 1.2459 - val_accuracy: 0.6087\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4432 - accuracy: 0.7948 - val_loss: 1.2102 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4410 - accuracy: 0.7900 - val_loss: 1.3052 - val_accuracy: 0.6036\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4384 - accuracy: 0.7959 - val_loss: 1.2821 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4589 - accuracy: 0.7865 - val_loss: 1.2778 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4513 - accuracy: 0.7867 - val_loss: 1.1404 - val_accuracy: 0.6047\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4545 - accuracy: 0.7875 - val_loss: 1.1616 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4494 - accuracy: 0.7910 - val_loss: 1.2319 - val_accuracy: 0.6026\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4448 - accuracy: 0.7943 - val_loss: 1.1937 - val_accuracy: 0.6138\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4283 - accuracy: 0.8002 - val_loss: 1.2413 - val_accuracy: 0.6097\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4252 - accuracy: 0.8027 - val_loss: 1.1739 - val_accuracy: 0.5996\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4467 - accuracy: 0.7908 - val_loss: 1.2298 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4325 - accuracy: 0.7979 - val_loss: 1.1845 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4290 - accuracy: 0.8009 - val_loss: 1.2463 - val_accuracy: 0.6148\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4304 - accuracy: 0.7989 - val_loss: 1.1563 - val_accuracy: 0.6127\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4403 - accuracy: 0.7918 - val_loss: 1.1525 - val_accuracy: 0.6148\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4412 - accuracy: 0.7908 - val_loss: 1.2804 - val_accuracy: 0.5945\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4481 - accuracy: 0.7867 - val_loss: 1.2328 - val_accuracy: 0.6006\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4339 - accuracy: 0.7969 - val_loss: 1.1926 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 45us/sample - loss: 0.4419 - accuracy: 0.7921 - val_loss: 1.1372 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4470 - accuracy: 0.7845 - val_loss: 1.2099 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4496 - accuracy: 0.7908 - val_loss: 1.1761 - val_accuracy: 0.5996\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4408 - accuracy: 0.7903 - val_loss: 1.1313 - val_accuracy: 0.6178\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4331 - accuracy: 0.7959 - val_loss: 1.2158 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4344 - accuracy: 0.7971 - val_loss: 1.1787 - val_accuracy: 0.6067\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4292 - accuracy: 0.7996 - val_loss: 1.1799 - val_accuracy: 0.6077\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4350 - accuracy: 0.7903 - val_loss: 1.1744 - val_accuracy: 0.6148\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4301 - accuracy: 0.7971 - val_loss: 1.1743 - val_accuracy: 0.6097\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4320 - accuracy: 0.7989 - val_loss: 1.2232 - val_accuracy: 0.6016\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4306 - accuracy: 0.8004 - val_loss: 1.1895 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4477 - accuracy: 0.7883 - val_loss: 1.2103 - val_accuracy: 0.6218\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4394 - accuracy: 0.7908 - val_loss: 1.2429 - val_accuracy: 0.6026\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4192 - accuracy: 0.8022 - val_loss: 1.2618 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4206 - accuracy: 0.8027 - val_loss: 1.2453 - val_accuracy: 0.6117\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4287 - accuracy: 0.7974 - val_loss: 1.2086 - val_accuracy: 0.6016\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4405 - accuracy: 0.7959 - val_loss: 1.2110 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4402 - accuracy: 0.7936 - val_loss: 1.2473 - val_accuracy: 0.6097\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4347 - accuracy: 0.7956 - val_loss: 1.2051 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4296 - accuracy: 0.8012 - val_loss: 1.2346 - val_accuracy: 0.6006\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4305 - accuracy: 0.7989 - val_loss: 1.1892 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4308 - accuracy: 0.7946 - val_loss: 1.1832 - val_accuracy: 0.6067\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4240 - accuracy: 0.7999 - val_loss: 1.3128 - val_accuracy: 0.6198\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4337 - accuracy: 0.7976 - val_loss: 1.2786 - val_accuracy: 0.6077\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4317 - accuracy: 0.8004 - val_loss: 1.2634 - val_accuracy: 0.5976\nEpoch 4/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4445 - accuracy: 0.7921 - val_loss: 1.2214 - val_accuracy: 0.6036\nEpoch 5/5\n3953/3953 [==============================] - 0s 33us/sample - loss: 0.4297 - accuracy: 0.8002 - val_loss: 1.2402 - val_accuracy: 0.6249\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4260 - accuracy: 0.8009 - val_loss: 1.2091 - val_accuracy: 0.6208\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4270 - accuracy: 0.8045 - val_loss: 1.2956 - val_accuracy: 0.5905\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4806 - accuracy: 0.7759 - val_loss: 1.3181 - val_accuracy: 0.6036\nEpoch 4/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4377 - accuracy: 0.7946 - val_loss: 1.1792 - val_accuracy: 0.6026\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4361 - accuracy: 0.7986 - val_loss: 1.2387 - val_accuracy: 0.6138\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4296 - accuracy: 0.8002 - val_loss: 1.2610 - val_accuracy: 0.6188\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4270 - accuracy: 0.7976 - val_loss: 1.2337 - val_accuracy: 0.6127\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4272 - accuracy: 0.7974 - val_loss: 1.2630 - val_accuracy: 0.6218\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4230 - accuracy: 0.8060 - val_loss: 1.2165 - val_accuracy: 0.6077\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4398 - accuracy: 0.7951 - val_loss: 1.2313 - val_accuracy: 0.5935\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4545 - accuracy: 0.7880 - val_loss: 1.1353 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4580 - accuracy: 0.7824 - val_loss: 1.2116 - val_accuracy: 0.5956\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4483 - accuracy: 0.7895 - val_loss: 1.2768 - val_accuracy: 0.5945\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4609 - accuracy: 0.7809 - val_loss: 1.2127 - val_accuracy: 0.5956\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4335 - accuracy: 0.7928 - val_loss: 1.1874 - val_accuracy: 0.6057\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4317 - accuracy: 0.8022 - val_loss: 1.1779 - val_accuracy: 0.6117\nEpoch 2/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4289 - accuracy: 0.8037 - val_loss: 1.2303 - val_accuracy: 0.6168\nEpoch 3/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4378 - accuracy: 0.7943 - val_loss: 1.1963 - val_accuracy: 0.6178\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4234 - accuracy: 0.8004 - val_loss: 1.1829 - val_accuracy: 0.6208\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4201 - accuracy: 0.8057 - val_loss: 1.2234 - val_accuracy: 0.6178\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4233 - accuracy: 0.8022 - val_loss: 1.2279 - val_accuracy: 0.6218\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4249 - accuracy: 0.8022 - val_loss: 1.2125 - val_accuracy: 0.6047\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4374 - accuracy: 0.7921 - val_loss: 1.1923 - val_accuracy: 0.5996\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4308 - accuracy: 0.7981 - val_loss: 1.2443 - val_accuracy: 0.6047\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4246 - accuracy: 0.7994 - val_loss: 1.2358 - val_accuracy: 0.6127\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4216 - accuracy: 0.8019 - val_loss: 1.3175 - val_accuracy: 0.6188\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4241 - accuracy: 0.8024 - val_loss: 1.2451 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4218 - accuracy: 0.8080 - val_loss: 1.2926 - val_accuracy: 0.6158\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4163 - accuracy: 0.8034 - val_loss: 1.2721 - val_accuracy: 0.6198\nEpoch 5/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4158 - accuracy: 0.8039 - val_loss: 1.3178 - val_accuracy: 0.6107\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4209 - accuracy: 0.8077 - val_loss: 1.3333 - val_accuracy: 0.6218\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4241 - accuracy: 0.8027 - val_loss: 1.2550 - val_accuracy: 0.6229\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4211 - accuracy: 0.8065 - val_loss: 1.2969 - val_accuracy: 0.6087\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4628 - accuracy: 0.7835 - val_loss: 1.1428 - val_accuracy: 0.6138\nEpoch 5/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4699 - accuracy: 0.7736 - val_loss: 1.2521 - val_accuracy: 0.5956\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4493 - accuracy: 0.7895 - val_loss: 1.2055 - val_accuracy: 0.6259\nEpoch 2/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4469 - accuracy: 0.7898 - val_loss: 1.2330 - val_accuracy: 0.6067\nEpoch 3/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4330 - accuracy: 0.8032 - val_loss: 1.2806 - val_accuracy: 0.6047\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4246 - accuracy: 0.8029 - val_loss: 1.2329 - val_accuracy: 0.6117\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4220 - accuracy: 0.8029 - val_loss: 1.2829 - val_accuracy: 0.6208\nTrain on 3953 samples, validate on 989 samples\nEpoch 1/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4198 - accuracy: 0.8009 - val_loss: 1.2663 - val_accuracy: 0.6107\nEpoch 2/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4136 - accuracy: 0.8098 - val_loss: 1.2502 - val_accuracy: 0.6138\nEpoch 3/5\n3953/3953 [==============================] - 0s 34us/sample - loss: 0.4186 - accuracy: 0.8077 - val_loss: 1.2208 - val_accuracy: 0.6057\nEpoch 4/5\n3953/3953 [==============================] - 0s 35us/sample - loss: 0.4348 - accuracy: 0.7928 - val_loss: 1.2758 - val_accuracy: 0.6087\nEpoch 5/5\n3953/3953 [==============================] - 0s 36us/sample - loss: 0.4261 - accuracy: 0.7981 - val_loss: 1.2792 - val_accuracy: 0.6097\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.figure(num=None, figsize=(16, 8), dpi=90, facecolor='w', edgecolor='k')\nplt.plot()\nplt.plot(train_acc)\nplt.plot(val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T16:10:31.708646Z","iopub.execute_input":"2021-09-08T16:10:31.709006Z","iopub.status.idle":"2021-09-08T16:10:31.991077Z","shell.execute_reply.started":"2021-09-08T16:10:31.708976Z","shell.execute_reply":"2021-09-08T16:10:31.990107Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x720 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"y_predict = np.round(model.predict(X_test_norm))\ny_predict = np.array([i[0] for i in y_predict.tolist()])\nsum(y_predict == y_test)/len(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T16:10:36.208341Z","iopub.execute_input":"2021-09-08T16:10:36.208726Z","iopub.status.idle":"2021-09-08T16:10:36.365537Z","shell.execute_reply.started":"2021-09-08T16:10:36.208692Z","shell.execute_reply":"2021-09-08T16:10:36.364473Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"0.6245954692556634"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntarget_names = ['negative', 'positive']\nC = confusion_matrix(y_test,y_predict) \nC = C / C.astype(np.float).sum(axis=1)*100\nsns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T16:10:45.610638Z","iopub.execute_input":"2021-09-08T16:10:45.611000Z","iopub.status.idle":"2021-09-08T16:10:45.824645Z","shell.execute_reply.started":"2021-09-08T16:10:45.610970Z","shell.execute_reply":"2021-09-08T16:10:45.823528Z"},"trusted":true},"execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXEAAAEMCAYAAAAyO4a7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxoElEQVR4nO3deVxU9f748dcMMIACguaCS5kWgpmCIGrhhqLeNBGXNEtp0dSUvPrDFkr9iqmppDeX4tpiVppZKldc0qumXs1UFLfEyjUXBAVxZIfh/P7gNleEwRlkBo6+nz3mEfM553w+n0PTm/d8zud8jkZRFAUhhBCqpK3qDgghhKg4CeJCCKFiEsSFEELFJIgLIYSKSRAXQggVkyAuhBAqZl/VHbCUc7foqu6CqIZubJtQ1V0Q1ZCTXa17Ot6SeJPz09R7aquiVBfEhRDCZjSaqu7BXUkQF0IIU+zsqroHdyVBXAghTJFMXAghVExT/ed+SBAXQghTtJKJCyGEeslwihBCqJgMpwghhIrZSRAXQgj1kkxcCCFUTMbEhRBCxSQTF0IIFZMphkIIoWJaue1eCCHUS8bEhRBCxWQ4RQghVEwubAohhIrJcIoQQqiYBHEhhFAxeSiEEEKomGTiQgihYnJhUwghVMxKUwzz8vKYNWsW+/btw9HREV9fX2bMmEFwcDA6nQ5HR0cAIiMj6dSpU7l1SRAXQghTrDScMm/ePBwdHdmyZQsajYbr168bty1cuBAvLy+z65IgLoQQpljhtvusrCzi4uLYtWsXmv/+kXjooYcqXJ8EcSGEMMWC4RS9Xo9ery9V7ubmhpubm/H9xYsXcXd3Z/Hixezfv5+aNWsyYcIEAgICgOIhFEVR8Pf3Z9KkSSWOLbOLZvdQCCEeNBqt2a/ly5fTvXv3Uq/ly5eXqNJgMHDx4kVatmzJ2rVriYyMJCIigszMTFasWMH69etZs2YNiqIQHR191y5KJi6EEKZYMCYeHh5OWFhYqfI7M2lPT0/s7e3p27cvAG3atMHDw4Nz587x5JNPAqDT6Rg2bBhjx469a7sSxIUQwgSNBUH8zmETU2rXrk379u3Zu3cvQUFBnDt3jrS0NOrVq8etW7dwdXVFURQ2bdqEj4/PXeuTIC6EECZY616f6dOnExUVxZw5c7C3t2fu3Lnk5+czevRoDAYDRUVFNG/enGnTpt21LgniQghhgp2ddaJ4kyZN+Prrr0uVx8XFWVyXBHEhhDDBkuGUqiJBXAghTFBBDJcgLoQQpkgmLoQQKiZBXAghVEwFMVyCuBBCmKK10uyUyiRBXAghTJDhFCGEUDEVxHAJ4kIIYYpWBVFcgrgQQpggwylCCKFiWis9nq0ySRAXQggTVJCISxAXQghTNJKJCyGEekkmLoQQKiYXNoUQQsVUEMMliAshhClabfV/lrwEcSGEMEEF1zUliFe1wd2eICq8M03q1SIlPZPX5qxn7/E/eekZPyKHPU392i78fPxPxsxdT3JapsX1PFy/Fr+tmkBmTr5x3w+/3csHX//HFqcnKuCdN6dy4JeD5OTkUueh2rz86nAGDOpPQX4Bb785hZMnkrhyJZnPvvyEdoH+Juv5dsVq1sdt4I/fz/C3Pj2ZMet/z2u8fPkKz4T0x9nZ2Vj28sgRjB77qlXPTW1kdoooV7B/M95/rTvDo9dw8NRlPOu4AtCpzSNMHxlM70lfcfpSGjHje7N8ykB6/n25RfXcrkHfORiKFKuej6gcr44KZ/r776HT6Th39jyvho/B26cFjz/+GH5t2/DC8KFMnvjOXeupW68uo0a/ws97fyEvL6/Mffbs3469vYQBU2RMXJRryktdmPX1bg4kXQbgyvVbAEQM6sDaXSdJOn8NgA++3s3ZHybxaEMPzl25YXY9Qp0ee7y58WeNRoNGo+Hin5do+YQPL454HgCtnd1d6+kR0g2Ak78mkZKSap3O3uesNTslLy+PWbNmsW/fPhwdHfH19WXGjBmcO3eOt99+m4yMDNzd3ZkzZw5NmzYtty4J4lVEq9XQtkVDNv78Oye+GY+Tzp74Pad4J3YbUDID+OuD9MSjdUsF8fLqyc0vNO73+6oJKMD2hLNExf6bNH2O1c9RVNzM6Dmsj9tAbm4e3j4t6NT5aau007tHKBqNhg4dA5k0+Q08PNyt0o5aWSsTnzdvHo6OjmzZsgWNRsP169cBmDZtGsOGDSM0NJR//etfTJ06la+++qrcumx26TUtLY3IyEheeOEFAE6dOsW3335rq+arnfoeNdE52NG/iw893viS9iP/SZvHPXl7eCe2HjjNwK5P0KpZPZx09rwzojNFRQo1HB0sqgcg7WY2T4/+FK+hH/HU6E9xraFj2XsDbH26wkLvTn2Lnw/uZNnXS+ke0hUHna5S6/dwd2fl6i/5cdu/WPX9crKzs3nnzSmV2sb9QKvVmv3S6/VcunSp1Euv15eoMysri7i4OCZMmGBM0B566CHS0tI4efIkffv2BaBv376cPHmS9PT08vtonVMv7b333sPf3994Qs2aNWPlypW2ar7ayckrzpI/WXeAq+mZpOlzWPj9Pnq1f4yfDp/j/S938u30wZz69g0uXM3gVnYel6+VHiYprx6ArNwCDv+ejKFIIfVGFhM/2kxIu+a4OFduUBCVz87Ojrb+vqRcTWX1qjWVWneNmjV4olVL7O3tqfNQHd55N5J9e/eTlZVVqe2onUZj/mv58uV079691Gv58pLXsi5evIi7uzuLFy9mwIABDB8+nISEBJKTk6lfvz52/x0qs7Ozo169eiQnJ5fbR5sNp6SkpPD888/z3XffAaDT6VQxB9NaMjJzuZR6E+W2a423//zPuAT+GZcAwGONa/P2i5349Vzpcc271XOnvzapYXU2UcxgMHDp4iWrtvFXRlgkF79LsGR2Snh4OGFhYaXK3dzcSrw3GAxcvHiRli1b8tZbb3H06FHGjBnDRx99VKE+2iyK3nkFXK/Xo5QXbR4AX/14lNfD2lHXvQbuLk5EDOrA5n1/4OhgR8umdQFoUs+NJf+vL0vWHiAjM9eiegDa+TTi8SZ10GigtpszH0b0ZlfiefRZZc9WEFUrLS2dzZu2kp2VjcFgYO+efWzetJX2HdoBkJ+fb5xpUlBQQF5ensn/jwoLC8nLy8NgKMJgKCIvL4/CwuJvbseOnuD8uQsUFRWRkZHBB7M+JCDQH1dXF9ucqEpYkom7ubnRuHHjUq87g7inpyf29vbGYZM2bdrg4eGBk5MTKSkpGAwGoDjYp6am4unpWW4fbZaJh4SEMHXqVLKysli7di0rV65k4MCBtmq+Wpr91W7q1HLm2Nfjyc0vZO3OX5nzzX9w0tnz5XsDaNbQg1s5+Xy9+QjTv/jJeNzkF4J4+smH6f/2ynLrAXjU053pI4Op614TfXYeOw6dJXxG5X41F5VHo9Hw/ao1zJz+AUVFCp4NG/Dm25PoGtwZgNBnBnPlSvHX67Gj3gBg07/jaNSoIZ/9cxmHDx3h46XFGd2nsV8Q+/Fnxro3xm9mzOsjGTv+NS5fusxb//iY9PQbuNSsSYenApkzb4aNz7b6s8aTfWrXrk379u3Zu3cvQUFBnDt3jrS0NJo2bYqPjw8bNmwgNDSUDRs24OPjQ+3atcutT6PYMB1ev349O3bsQFEUgoODCQ0NtbgO527RVuiZULsb2yZUdRdENeRkV+uejm+7aLfZ+x6O6Gz2vhcvXiQqKoqMjAzs7e35+9//TpcuXThz5gxvv/02er0eNzc35syZQ7Nmzcqty2ZB/PLlyzRq1Oie65EgLsoiQVyU5V6DuP8S8+9sPjSu0z21VVE2GxMfOnQoL730EuvXrzd595gQQlQnf91sZc6rqtgsiO/cuZPw8HC2bdtGly5dmDJlComJibZqXgghLGbJhc2qYrMgbmdnR7du3Vi4cCE//vgjGo2GYcOG2ap5IYSwmBoycZvedp+RkcGGDRtYt24dmZmZvPHGG7ZsXgghLCKrGN5m/PjxHDp0iB49ehAVFYW/v+klNIUQojpQw01xNgviPXv2JCYmBicnJ1s1KYQQ98Qa88Qrm9WDeH5+PjqdjpCQEBRFISen5Op5ty9KL4QQ1YkKYrj1g/iQIUNYt24dfn5+aDQaFEUp8e+kpCRrd0EIISpExsSBdevWAcVLzwohhJpU5awTc9lsiuHMmTPNKhNCiOpCDfPEbXZhMyEhoVTZwYMHbdW8EEJYTGtX/ZfLtnoQ37x5M5s3b+by5ctMmPC/9S0yMzNlpooQolpTwWiK9YP4o48+SteuXTl+/Dhdu3Y1lru4uNCxY0drNy+EEBWmhjFxqwdxb29vvL29CQ4Oxt3d3drNCSFEpZEgfhsXFxe+++47kpKSSqxiOHv2bFt1QQghLKKCGYa2m50ydepUDh8+zM6dO2natCknTpyQMXEhRLWmtdOa/aqyPtqqoePHjzNnzhxcXV0ZPXo0K1eu5PTp07ZqXgghLCZTDG/j6OgIFC9Jm5OTg6urK2lpabZqXgghLCZj4repVasWN2/epFOnTowaNQoPDw/q169vq+aFEMJictv9bZYuXYqdnR0TJ05k/fr1ZGZm0r9/f1s1L4QQFrNWIh4cHIxOpzOOUERGRtKpUydatGiBl5cXWm3xSPfcuXNp0aJFuXWZDOJdunQx66vEzp07zeq0nZ0dAFqtVoK3EEIVrDmcsnDhQry8vEqVr1q1ipo1a5pdj8kgPm/evIr1zIQOHTqU+oW4urri6+vL5MmTqVu3bqW2J4QQ98pOzcMpgYGBldrQCy+8gF6vZ+DAgQDExcVhZ2eHs7MzU6ZMITY2tlLbE0KIe6XRKGbvq9fr0ev1pcrd3Nxwc3MrVR4ZGYmiKPj7+zNp0iTjPsOHD8dgMNC5c2ciIiLQ6XTl91FRlLv2Mj8/nyVLlrBhwwYyMjI4dOgQe/bs4fz587z44otmneDgwYP5/vvvS5QNHDiQNWvW0KdPHzZu3GhWPc7dos3aTzxYbmybcPedxAPHya7WPR0/YNNxs/ftdmYnixcvLlU+fvx4IiIiSpQlJyfj6elJfn4+M2fOJCsri5iYGGN5ZmYmkydPxsvLi4kTJ5bbrlkXNmfNmkVKSgoxMTGMGjUKgMcff5zZs2ebHcT1ej0ZGRnGW+9v3LhBZmYmAA4ODmbVIYQQtqS1IBMPDw8nLCysVHlZWbinpycAOp2OYcOGMXbs2BLlLi4uDB48mGXLlt21XbOC+LZt29i6dSs1atQwXjWtX78+KSkp5hwOFH9FCA0NpUuXLgDs3r2bkSNHkpWVRdu2bc2uRwghbMWSEXFTwyZ3ys7OxmAw4OrqiqIobNq0CR8fH27evImjoyNOTk4UFhayZcsWfHx87lqfWUHcwcEBg8FQoiw9Pd2iBa1efPFFAgICjGuIDxs2DG9vb6D4lnwhhKhu7LTmZ+LmSktLIyIiAoPBQFFREc2bN2fatGmcPXuWqVOnotFoKCwsxM/Pr8Ty3aaYFcR79+7NW2+9xTvvvANAamoqs2bNok+fPhZ1vnHjxhgMBp544gmLjhNCiKpgjRmGTZo0IS4urlR5vXr1iI+Pt7g+s9ZOmThxIo0bN6Zfv37o9Xp69epFvXr1GDdunNkN7dq1iz59+hgH+I8fP86YMWMs7rAQQtiKVqOY/aoqZmXiOp2OqKgooqKiSE9Px8PDw+JJ8AsXLuSHH34wXhh98skn+fPPPy3vsRBC2Ej1nyVuwW3358+fZ/PmzaSmplKvXj3+9re/0bRpU4sau/OGnrvNfxRCiKpUlRm2ucwaTomPjycsLIzffvsNZ2dnfv/9d8LCwiwav6lZsybXr183ZvD79+/H1dW1Yr0WQggbuG+Wov3HP/7B0qVLadeunbEsISGBN998k2effdashiIjIxk1ahSXLl1i+PDhnD9/nk8++aRivRZCCBuwU0EmblYQz8rKwtfXt0RZmzZtyM7ONruh1q1b89VXX3H48GEA/Pz8zJpTKYQQVcWS2+6rilnDKS+//DLz5883PhszNzeXBQsW8PLLL1vUmKurKx07diQwMBAHBwdycnIs77EQQtiIVmP+q6qYtRStoihcv36dr7/+Gjc3N/R6PYqiULduXUaPHm1WQ1u3buX999/n2rVrxjo1Gg1JSUmVcBpCCFH51JCJ22wp2nnz5vGPf/wDX19f4637QghRnalgJVrbLUVbq1YtWSNFCKEqGlScid8pKSmJhIQEbty4we2r15pzbz9ASEgIK1eu5JlnnjE+kgjA2dnZgu4KIYTtWGPtlMpmVhD/7rvvmD17Nk8//TS7d++mc+fO7N27l+7du5vd0IIFCwCIjo5Go9HImLgQotpTwcPuzQvin332GZ999hkBAQG0a9eOJUuWsGvXLjZt2mR2Q6dOnapwJ4UQoircN3dspqWlERAQUHyAVktRURFdunThp59+smrnhBCiKmkseFUVszLxBg0acOnSJRo3bkzTpk3Zvn07Hh4e8kQeIcR97b4ZThk5ciRnzpyhcePGvP7660yYMIGCggKioqKs3T8hhKgy982FzQEDBhh/7tKlCwcOHKCgoEBmlggh7mtaFUwxrNBdNzqdDgcHB3lCjxDivnbfrGJoyu3zxYUQ4n6j6tvuzWHp032EEEJNrHXbfXBwMDqdznjjY2RkJJ06deLIkSNMnTqVvLw8GjVqxLx586hTp065dd1TEBdCiPuZNTPxhQsX4uXlZXxfVFTE5MmTmT17NgEBAXz88cfExMQwe/bscuspN4gPGzbMZLZdVFRUgW7fu7VfP1Ul7Yrqbejmi1XdBVENxfWtdU/H2/KhECdOnMDR0dF4T87QoUPp3r37vQXxwYMHl3vwc889Z2E3hRBCPSyZ+aHX69Hr9aXK3dzcynwATmRkJIqi4O/vz6RJk0hOTqZhw4bG7bVr16aoqIiMjAzc3d1NtltuEA8LC7PgFIQQ4v5iyXDK8uXLWbx4cany8ePHExERUaJsxYoVeHp6kp+fz8yZM4mOjiYkJKRCfZQxcSGEMMGS65rh4eFlJr5lZeGenp5A8XTtYcOGMXbsWEaMGMGVK1eM+6Snp6PVasvNwkGCuBBCmGTJAlimhk3ulJ2djcFgwNXVFUVR2LRpEz4+PrRq1Yrc3FwSEhIICAhg1apV9O7d+671SRAXQggTrDHDMC0tjYiICAwGA0VFRTRv3pxp06ah1WqZO3cu06ZNKzHF8G4kiAshhAnWWDulSZMmxMXFlbmtbdu2xMfHW1SfWRdf8/PzWbBgAd27d8ff3x+APXv28M0331jUmBBCqIkalqI1K4jPmjWL33//nZiYGOO88ccff5xvv/3Wqp0TQoiqpNUoZr+qilnDKdu2bWPr1q3UqFHD+KT6+vXrk5KSYtXOCSFEVVLDwiJmBXEHBwcMBkOJsvT09LtOfRFCCDW7bx7P1rt3b9566y0uXiy+tTk1NZXo6Gj69Olj1c4JIURVUsNwillBfOLEiTRu3Jh+/fqh1+vp1asX9erVY9y4cdbunxBCVBmtBa+qYtZwik6nIyoqiqioKNLT0/Hw8JBlaIUQ9737Zj3xv4ZR/pKVlWX8uUmTJpXbIyGEqCaqMsM2l1lBPCQkBI1GU+JJPn9l4klJSdbpmRBCVLH7JhM/depUiffXrl1j8eLFxnVvhRDifqSGTLxCfaxbty7vvvsu8+fPr+z+CCFEtaGG2SkVXjvl7Nmz5OTkVGZfhBCiWlHDPHGzgvidj2nLycnh9OnTMsVQCHFfU8MkPLOC+J2PaXN2dsbb25umTZtao09CCFEtaLkPMnGDwcAvv/zCjBkz0Ol0tuiTEEJUC/dFJm5nZ8fevXvl5h4hxANHDVHPrNkp4eHhLFq0iIKCAmv3Rwghqg07jWL2q6qUm4lv2LCBvn378s0333D9+nWWLVtG7dq1S2TlO3futHYfhRCiSqh+dsrUqVPp27evWc95E0KI+40ahlPKDeJ/3WYfGBhok84IIUR1Yu3b7hcvXsyiRYuIj4/Hy8uLFi1a4OXlZXz4zty5c2nRokW5dZQbxIuKivjll19KrJlyp44dO1ag60IIUf1Z87b7X3/9lSNHjtCoUaMS5atWraJmzZpm11NuEM/Pz+fdd981GcQ1Gg3bt283uzEhhFATrZVm5eXn5xMdHc2HH37IiBEj7qmucoO4s7OzBGkhxAPLkqnVer0evV5fqtzNzQ03N7cSZR999BH9+vWjcePGpfYfPnw4BoOBzp07ExERcdf7cyq8dooQQtzvLMnDly9fzuLFi0uVjx8/noiICOP7xMRETpw4QWRkZKl9d+7ciaenJ5mZmUyePJklS5YwceLEcts168KmEEI8iDQWhPHw8HDCwsJKld+ZhR88eJAzZ87QvXt3AK5evcqrr77K7NmzCQoKAsDFxYXBgwezbNmyu7ZbbhBPTEw0+wSEEOJ+Y8mQeFnDJmV57bXXeO2114zvg4ODiY2NpX79+uTm5uLk5ERhYSFbtmzBx8fnrvXJcIoQQpigteFM8bNnzzJ16lQ0Gg2FhYX4+fkxYcKEux4nQVwIIUyw1uyU2+3YscP4c3x8vMXHSxAXQggT1LDunwRxIYQwwZILm1VFgrgQQpggmbgQQqiYZOJCCKFi1lw7pbJIEBdCCBNsMTvlXkkQF0IIE9TwWEoJ4kIIYUL1D+ESxIUQwiTJxIUQQsWqfwiXIC6EECbZSSYuhBDqJfPEhRBCxVSQiEsQF0IIUyQTF2a5dimVOSNn0qazH8OjXuKPxN9Zu+R7bqTeQKvV0rz1YwyMeA73uu6ljr2Rks7sV2aUKMvPzSd0dBjdnuvBv1f8yL9XbjFuU4oUCgsKmbHmA1xquVj71EQFvN/xUbzcnTH898la6bmFjNv5B63q1CS6Q1PyDEXGfZeeSOanSxll1vOomxPjWzeisasjl27lsfjYZc7pcwGw12oY+YQnHRq4YaeBUzey+eT4FdJzC61+fmoimbgwyw8Lv+PhFo8Y3zd4pAFjPhhHrYfcKcwvYNOyDXz/0SpGvT+m1LEe9Wszd+MC4/u05Ou8P+L/aN3ZD4CQF3oT8kJv4/bNyzdy9thpCeDV3NITyWy7eKNUeXpuISO3/3bX4+01Gt4JeJj4c2lsvpBOr4c9eCfgYV7/6Q8KFYVnH61DCw9nJuz6g+zCIl5v3ZBRT3gy59BFa5yOaqkhE1fD0gD3tcM7EnB2cebxti2MZa613aj1kLvxvcZOy/XL18yq7+C/99P8yceo06BOqW2KopDw7/2069n+nvstqrdWdWpip9UQfy6NwiKFjefT0WjgyYdqAlDP2YEj1zK5mW+goEhhz5WbPOzqVMW9rn60Go3Zr6oimXgVys3KYfOXGxn34Rvs2/RziW03UtKZM2oWedm5aLQahkwadtf6FEXh4NYD9Hyxd5nbzx4/za0bt2jT2bcyui+saLh3fUb41OdyZh4rfkvlRFoWALUc7fgyxJs8QxH7r+pZ8VsKeYbSDzRv4urI+f8OnfzlvD6Xh10dSbyWybaLNxj5hCcejvZkFRjo0sidw6m3bHJuaqKGLNdmQTwtLY3Zs2eTnJzMihUrOHXqFImJiTz//PO26kK1s2nZBtr/rSPudT1KbfOoX5sP1seQpc9i38a91H+4wV3rO3v8DLdu6PHt4lfm9gNb9tOmsx+OzpJxVWfLk65y8VYehYpCp4a1eLfdw0zcfYZLmXlM3H2Gy5l51HV2YIJvY15p6cknx6+UqsPZXkt2gaFEWXZhEc72dgAkZ+VzPaeAZSHeGIoULtzKZemJZJucn5qo4Y5Nm/2hee+99/D390ev1wPQrFkzVq5caavmq51Lpy/y++FTdB0UXO5+Nd1qEtirPZ9N+ScGg6HcfQ9u3U+bTmUH6fzcfI7sTiSwZ4d76rewvj8ycsg1FFFYpPDTpQyS0rPxr+dCRl4hlzLzUIDUnAKWJ12lo2fZT1fPKSyihoNdibIa9lpyCos/Q6+1aoiDnZYXtyQx5MeT/HJVz9TAR8qq6gGnseBVNWwWxFNSUnj++eexsyv+YOl0OrRaNXxZsY7TR/8gPSWd6c+/x5RBb/PT6m0c+88RYkZ/UGrfIkMRmRm3yM3KLaOmYvl5+RzZfZh2vcoe7z625wg1XGvwmO/jlXYOwjZKD5b8r9xU6Lh4K49H7hjjfsTViT9v5QHFM1d2XLxBZoGheMz8XBpeHjVwvSPwP+isHcIXL15MixYt+P333wE4cuQI/fr1o1evXrzyyiukpaXdtQ6bDafY25dsSq/XoyimPp73v6f6BNG2m7/x/U+rt5N+NY3Bfx/K0f8coUFTT+o2qku2Pou4T9bQ+LEm1HSrabK+43uO4uxSg8d9vcrcfnDrftqFtFfF18MHWU17LY971ODXtCwMikJQw1o8Ubsmn/+aTKs6NUnJzudaTgEPOTkwwrs+B1LKHsc+kZZFkaLQ99E6/HghnZ4PFw/ZHb9ePLZ++mYO3Rq7cyItizxDEX9rWoe03AJuFZT/be9Bo9FYL9H89ddfOXLkCI0aNQKgqKiIyZMnM3v2bAICAvj444+JiYlh9uzZ5dZjsyAeEhLC1KlTycrKYu3ataxcuZKBAwfaqvlqR+ekQ+ek+997Z0fsdQ64uLty83oG/4pdS2bGLRydHXmsjRevRI8y7rt6wbcAPDfxf9cTDmzdT7uQwDKDdMa1DP5I/J1BE4ZY8YxEZbDTanihRT0auzhSpMClzDxmJ1zgSlY+AfVcmejXGBcHO27lG/jlqp5vTqUYj50S+AhJ6dn8cPoahYrC7IQ/Gd+6EcO96/+3nj8p/G/i9OXJq4xs5cnH3bxw0Gq4cCuXDxL+rKrTrrYsSXn0er1xuPh2bm5uuLmVHPbKz88nOjqaDz/8kBEjRgBw4sQJHB0dCQgIAGDo0KF07979rkFco9gwHV6/fj07duxAURSCg4MJDQ21uI7Nl7ZZoWdC7f555O4XfsWDJ65vq3s6/mjaAbP33b1yP4sXLy5VPn78eCIiIkqUzZs3j4YNG/LCCy8QHBxMbGws586dY82aNSxdutS4X5s2bdi1axfu7u4m27VZJn758mX69etHv379bNWkEELcGwuGH8PDwwkLCytVfmcWnpiYyIkTJ4iMjLzn7oENg/jQoUNp3rw5AwYMoFevXjg6OtqqaSGEqBBLhlPKGjYpy8GDBzlz5gzdu3cH4OrVq7z66qsMHz6cK1f+N100PT0drVZbbhYONpydsnPnTsLDw9m2bRtdunRhypQpJCYm2qp5IYSogMqfn/Laa6+xZ88eduzYwY4dO2jQoAGff/45I0eOJDc3l4SEBABWrVpF795l37h3O5tl4nZ2dnTr1o1u3bqRkZHB/PnzGTZsGElJSbbqghBCWMSWt9NrtVrmzp3LtGnTyMvLo1GjRsybN++ux9n0tvuMjAw2bNjAunXryMzM5I033rBl80IIYSHrB/EdO3YYf27bti3x8fEWHW+zID5+/HgOHTpEjx49iIqKwt/f/+4HCSFEFVLDKoY2C+I9e/YkJiYGJydZt0MIoQ7VP4TbIIjn5+ej0+kICQlBURRycnJKbHd2drZ2F4QQomJUcIez1YP4kCFDWLduHX5+fmg0GhRFKfFvubAphKiuZDgFWLduHQCnTp2ydlNCCFGp1BDEbTZPfObMmWaVCSFEdaHRaMx+VRWbXdj8awL77Q4ePGir5oUQogKqfyZu9SC+efNmNm/ezOXLl5kwYYKxPDMzU2aqCCGqteofwm0QxB999FG6du3K8ePH6dq1q7HcxcWFjh07Wrt5IYSoMDWMiVs9iHt7e+Pt7U1wcPBdF3IRQojqRA0PUbF6EF++fDnh4eEl1si93ZtvvmntLgghRIVIJg7GJWdr1Khh7aaEEKKSSRBn6NChQPHaKUIIoSYqGE2x3TzxZcuWcetW8UNdJ0+eTO/evdmzZ4+tmhdCiAqw9vPu753NgvjatWtxdXXll19+IT09nVmzZjF//nxbNS+EEBbTWPBPVbHpQyEA9u/fz7PPPkvbtm2x4TOahRDCYmqYnWKzTNzJyYmlS5eyceNGnn76aRRFoaCgwFbNCyGExdSQidssiM+ePZtr164RGRlJ3bp1uXjxIs8++6ytmhdCCIupIYhrFBuPaWRnZwMVn3K4+dK2yuyOuE/880iDqu6CqIbi+ra6p+P/zDpj9r4P12x+T21VlM3GxP/8808iIyNJSkpCo9HQsmVL5s2bR5MmTWzVBSGEsIg1M+zXX3+dS5cuodVqqVGjBlOmTMHHx4fg4GB0Op3xHpvIyEg6depksh6bBfFp06bx3HPPMXDgQKB4tsrUqVNZtmyZrboghBAWsWYQnzNnDq6urgBs27aNqKgo4/MXFi5ciJeXl1n12GxMPD09nUGDBhnX3h04cCDp6em2al4IISxmzfXE/wrgULyqa0VnwtgsE9dqtZw9e5ZmzZoBcO7cOeO0QyGEqI4sycT1ej16vb5UuZubG25ubmUe8+6777J3714UReGzzz4zlkdGRqIoCv7+/kyaNMnk8WDDC5u7d+/mrbfewsfHB0VR+O2335g7dy5BQUEW1SMXNkVZ5MKmKMu9XthMzr5g9r4/fL6exYsXlyofP348ERER5R4bFxfHxo0b+fTTT0lOTsbT05P8/HxmzpxJVlYWMTExJo+16eyU9PR0jh49CkCbNm2oXbu2xXVIEBdlkSAuynLPQTznT7P3rVngbnEmfrvWrVuza9cuPDw8jGW//fYbY8eOZceOHSaPs9lwihBCqI0lwynmBmuArKws9Ho9np6eAOzYsYNatWrh6OjIrVu3cHV1RVEUNm3ahI+PT7l12SyIb926lSlTptCqVSsURSEqKooZM2bQo0cPW3VBCCEsorXS7JScnBwmTJhATk4OWq2WWrVqERsbS1paGhERERgMBoqKimjevDnTpk0rty6bBfEFCxawatUqHn30UQDOnz/P2LFjJYgLIaovK80wfOihh1i9enWZ2+Li4iyqy2ZB3NHR0RjAAZo2bSoPShZCVGtqeLKPzeaJd+/enU8++YRr166RmppKbGws3bt3Jzc3l5ycHFt1QwghzCZrp9zG29vbdCc0GpKSksyqR2aniLLI7BRRlnudnXI994rZ+z7k1PCe2qoomw2nnDp1ylZNCSFEpVDDeuIyxVAIIUyw1uyUyiRBXAghTJFMXAgh1EsNs1MkiAshhAnVP4RLEBdCCJMkExdCCDWTMXEhhFAvmZ0ihBBqJpm4EEKoV/UP4RLEhRDCJLmwKYQQKiZBXAghVEwNa6fY9BmbQgghKpfN1hMXQghR+SSICyGEikkQF0IIFZMgLoQQKiZBXAghVEyCuBBCqJgEcSGEUDEJ4kIIoWISxIUQQsUkiN8nkpKS2LRpU4my0NBQcnNzq6hHwta+/fZbvvzyS0A+Dw8Sue3+PrF27Vp27tzJwoULq7orohqQz8ODQzJxK2rRogWxsbEMHDiQ7t27s2XLFuO2o0ePMnz4cAYMGMCAAQPYuXOncds333xDz549GThwIAsXLqR9+/YAFBYW8uqrrzJgwAD69OnDO++8Q35+Pjdu3GDhwoX8/PPPhIaG8v777xvbz8rK4l//+hfjxo0z1l9YWEhQUBAXL14EYOnSpQwaNIiwsDDGjBnDtWvXbPDbEVD832jhwoWEhobSq1evEp+R3bt3079/f5599lnCw8O5cOECAGfPnmXIkCH069ePvn378vnnnwOwaNEi5syZI5+HB40irMbLy0v5+uuvFUVRlISEBCUoKEhRFEW5efOmEhoaqqSkpCiKoigpKSlKp06dlJs3bypJSUlKUFCQkpaWpiiKosyYMUMJDAxUFEVRioqKlPT0dOPPkydPVlauXKkoiqKsWbNGiYiIKNV+Zmamkp2drQQGBhrr3L59uzJ8+HBFURQlLi5Oee+99xSDwaAoiqKsWLFCmTRpktV+J6IkLy8vZdGiRYqiKMqZM2eUwMBA5fr168r169eV9u3bK3/88YeiKIqyevVqZdCgQYqiFH8mYmNjjXVkZGQoiqIoCxcuVD744ANFUeTz8CCRpWit7JlnngHA19eX1NRU8vLySExM5NKlS4waNcq4n0aj4cKFCyQmJtKlSxdq164NwKBBg4iPjwegqKiIL774gt27d1NUVMTNmzdxcnK6ax+cnZ3p0aMHGzZsYMSIEaxbt44BAwYAsGPHDk6cOEFYWBgABoMBFxeXSv0diPINHjwYgGbNmtGyZUuOHDmCRqPB29ubxx57DICBAwcyffp0MjMzadeuHfPmzSMnJ4f27dvToUMHi9qTz8P9RYK4lTk6OgJgZ2cHFH91VRSFFi1asGLFilL7JyYmmqwrPj6eQ4cOsWLFClxcXIiNjeX8+fNm9SMsLIxZs2bx7LPPcuDAAebOnQuAoiiMHTuWQYMGWXhmoqr06tULX19f9u7dy6effsqaNWuIiYmxqA75PNw/ZEy8Cvj5+XHhwgV++eUXY9mxY8dQFIXAwEB2795Neno6AOvWrTPuc+vWLTw8PHBxceHWrVts2LDBuO2vMlMCAgLIzMxk/vz59OjRA2dnZwCCg4NZuXIlN2/eBCA/P59Tp05V6vmK8q1ZswaA8+fPc/LkSXx9ffH19eXUqVOcOXMGKP4ctGzZEhcXFy5cuEDdunUZMGAA48aN4/jx46XqlM/Dg0My8SpQq1YtPv74Y+bNm8esWbMoKCigSZMmxMbG4u3tzciRIxk6dCguLi506NABV1dXAPr378/27dvp3bs3derUwd/fn7y8PAA6duzIF198Qb9+/QgMDOS9994r1W7//v356KOPSnwD6N+/PxkZGbz44otAcSb2/PPP4+3tbYPfhIDiIYv+/fuTk5NDdHQ0derUAWDu3LlERkZSWFhI7dq1mTdvHgCbN28mPj4eBwcHNBoNUVFRpeqUz8ODQ6YYVkOZmZnGcchFixZx4cIFi78uC3Vo0aIFhw8fpmbNmlXdFaFSkolXQx9++CGHDx82ZujR0dFV3SUhRDUlmbgQQqiYXNgUQggVkyAuhBAqJkFcCCFUTIK4sJm3336bBQsWAJCQkECvXr1s0m6LFi2M645UltvPxZbHCnEnCeKihODgYFq3bo2fnx9PPfUUb7/9NllZWZXeTkBAQInFnkxZu3Ytzz//fKW3/5fhw4fz/fffW61+IaxNgrgoJTY2lsTERNatW8eJEyf45JNPSu1TWFhYBT0TQtxJgrgwqX79+nTq1Ik//vgDwLjeS8+ePenZsycAP/30E6GhoQQEBDB06NASt2ifPHmSsLAw/Pz8+Pvf/268uxRg//79dO7c2fg+OTmZ8ePH06FDB9q3b090dDRnzpxh2rRpHDlyBD8/PwICAoDiW8HnzJlD165deeqpp5g6dWqJhx189tlnBAUFERQUxA8//FDh83/jjTd4+umn8ff354UXXjD+Hv5y48YNXn75Zfz8/HjxxRe5fPmycduZM2d4+eWXCQwMpFevXqUe0CBEZZEgLkxKTk5m9+7d+Pj4GMu2bdvG6tWr2bRpEydPniQqKoro6Gj279/PkCFDeP3118nPzyc/P59x48YRGhrKgQMH6N27N1u3bi2zHYPBwOjRo2nYsCE7duxg9+7dPPPMMzRv3pzp06fj6+tLYmIiCQkJAMTExHDu3Dni4uLYunUrqampLFmyBCheg/uLL77giy++YOvWrezbt6/C59+5c2e2bNnCvn37aNmyJZGRkSW2x8fH8/rrr7N//368vb2N27Ozs3nllVfo27cvP//8MwsWLGD69OmcPn26wn0RwhQJ4qKUcePGERAQwLBhw2jXrh1jxowxbnvttddwd3fHycmJ7777jiFDhtCmTRvs7OwICwvDwcGBI0eOcPToUQoKCggPD8fBwYHevXvz5JNPltnesWPHSE1N5c0336RGjRo4Ojoas+47KYrC6tWriYqKwt3dHRcXF0aPHs3GjRuB4nVFBgwYgJeXFzVq1GD8+PEV/j0MGjQIFxcXdDodERERnDp1qsSiUl27dqVdu3bodDomTpzIkSNHSE5OZufOnTRq1IiBAwdib29Py5Yt6dWrFz/++GOF+yKEKXLbvShlyZIlPPXUU2Vu8/T0NP585coV4uLi+Oabb4xlBQUFpKamotFoqF+/PhqNxritYcOGZdaZnJxMw4YNsbe/+8cxPT2dnJwc4/rXUBzYi4qKAEhNTaVVq1bGbY0aNbprnWUxGAwsWLCAH3/8kfT0dLTa4nznxo0bxgXJGjRoYNy/Zs2a1KpVi9TUVC5fvsyxY8dK/CEyGAz069evQn0RojwSxIVFbg/Knp6ejBkzhrFjx5ba78CBA6SkpKAoivGYK1eu0KRJk1L7enp6kpycTGFhYalAfnt7AB4eHjg5ObFx40bq169fqq569eqRnJxsfH/lyhXLTvC/4uPj2b59O8uWLaNx48bcunWLdu3acfsqFVevXjX+nJWVxc2bN6lXrx6enp60a9eOZcuWVahtISwhwymiwgYPHsyqVas4evQoiqKQnZ3Nzp07yczMxNfXF3t7e7766isKCgrYunVrmeteA7Ru3Zq6devy4Ycfkp2dTV5eHocOHQKgTp06pKSkkJ+fD4BWq2Xw4MHMmjWLtLQ0AFJSUvjPf/4DQO/evVm3bh2nT58mJyeHxYsX3/U8CgsLycvLM74KCgrIyspCp9Ph4eFBTk4O8+fPL3Xcrl27SEhIID8/n48++og2bdrg6elJ165dOX/+PHFxcRQUFFBQUMCxY8eMa4MLUZkkiIsKe/LJJ5kxYwbR0dG0a9eOnj17snbtWgB0Oh2LFi1i3bp1BAYGsmnTJkJCQsqsx87OjtjYWC5cuEC3bt3o3LkzmzdvBqBDhw489thjBAUFGR8YPXnyZB555BGee+452rZty0svvcS5c+cA6NKlC+Hh4YSHhxMSEmLWo8v+7//+j9atWxtf77zzDv3796dhw4Z06tSJPn364OvrW+q4vn37smTJEtq3b8+vv/5qXO/bxcWFzz//nE2bNtGpUyeCgoKIiYkx/iESojLJKoZCCKFikokLIYSKSRAXQggVkyAuhBAqJkFcCCFUTIK4EEKomARxIYRQMQniQgihYhLEhRBCxSSICyGEiv1/GMX1VI8qPnwAAAAASUVORK5CYII=\n"},"metadata":{}}]}]}